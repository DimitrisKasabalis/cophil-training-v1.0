{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92cf95e2",
   "metadata": {},
   "source": [
    "# Session 4 Part B: Transfer Learning with ResNet50\n",
    "\n",
    "## Fine-Tuning Pre-Trained Models for Earth Observation\n",
    "\n",
    "**Duration:** 60 minutes | **Difficulty:** Intermediate-Advanced  \n",
    "**Dataset:** EuroSAT (same as Part A)\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Objectives\n",
    "\n",
    "By the end of this notebook, you will:\n",
    "\n",
    "1. ‚úÖ Understand transfer learning concepts\n",
    "2. ‚úÖ Load pre-trained ResNet50 (ImageNet weights)\n",
    "3. ‚úÖ Adapt ResNet50 for EO applications (3 channels ‚Üí 10 bands)\n",
    "4. ‚úÖ Fine-tune the model on EuroSAT\n",
    "5. ‚úÖ Compare transfer learning vs from-scratch CNN\n",
    "6. ‚úÖ Achieve 93-96% accuracy (improvement over Part A)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã What is Transfer Learning?\n",
    "\n",
    "**Concept:** Use knowledge from one task to improve performance on another\n",
    "\n",
    "**How it works:**\n",
    "1. Take a model pre-trained on large dataset (e.g., ImageNet: 1.2M images, 1000 classes)\n",
    "2. Remove final classification layer\n",
    "3. Add new layers for your specific task\n",
    "4. Fine-tune on your dataset (smaller, specialized)\n",
    "\n",
    "**Benefits:**\n",
    "- ‚úÖ **Less data needed:** 1000s instead of millions\n",
    "- ‚úÖ **Faster training:** Start from good features\n",
    "- ‚úÖ **Better accuracy:** Leverage learned representations\n",
    "- ‚úÖ **Prevents overfitting:** Pre-trained weights are robust\n",
    "\n",
    "**ImageNet ‚Üí EuroSAT:**\n",
    "- ImageNet learned: edges, textures, shapes, objects\n",
    "- We adapt: Apply these features to satellite imagery\n",
    "\n",
    "---\n",
    "\n",
    "## üèóÔ∏è Notebook Structure\n",
    "\n",
    "| Step | Activity | Duration |\n",
    "|------|----------|----------|\n",
    "| **1** | Setup & Load Pre-trained Model | 10 min |\n",
    "| **2** | Adapt for Multi-spectral (Optional) | 10 min |\n",
    "| **3** | Feature Extraction (Freeze Base) | 15 min |\n",
    "| **4** | Fine-Tuning (Unfreeze Layers) | 15 min |\n",
    "| **5** | Comparison & Analysis | 10 min |\n",
    "\n",
    "---\n",
    "\n",
    "Let's leverage pre-trained models! üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4b4323",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 1: Setup & Load Pre-trained Model (10 minutes)\n",
    "\n",
    "We'll use the same environment and dataset from Part A.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac43c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports (same as Part A)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(f\"‚úì TensorFlow version: {tf.__version__}\")\n",
    "print(f\"‚úì Keras version: {keras.__version__}\")\n",
    "\n",
    "# Check GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"\\n‚úì GPU available: {len(gpus)} device(s)\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  No GPU - training will be slower\")\n",
    "\n",
    "# Set seeds\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2645b989",
   "metadata": {},
   "source": [
    "### Load Dataset (Same as Part A)\n",
    "\n",
    "If you completed Part A in the same session, the dataset is already downloaded. Otherwise, we'll re-download.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a339d344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EuroSAT dataset\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(\"Loading EuroSAT dataset...\")\n",
    "\n",
    "# Load with same splits as Part A\n",
    "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
    "    'eurosat/rgb',\n",
    "    split=['train[:70%]', 'train[70%:85%]', 'train[85%:]'],\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "class_names = ds_info.features['label'].names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"\\n‚úì Dataset loaded\")\n",
    "print(f\"  Classes: {num_classes}\")\n",
    "print(f\"  Train: {ds_train.cardinality().numpy()} images\")\n",
    "print(f\"  Val: {ds_val.cardinality().numpy()} images\")\n",
    "print(f\"  Test: {ds_test.cardinality().numpy()} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49df6525",
   "metadata": {},
   "source": [
    "### Preprocessing & Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4051b5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for ResNet50\n",
    "# ResNet expects images scaled to [-1, 1] or [0, 1] depending on preprocessing\n",
    "# We'll use [0, 1] for consistency with Part A\n",
    "\n",
    "def preprocess_resnet(image, label):\n",
    "    \"\"\"\n",
    "    Preprocess for ResNet50\n",
    "    ResNet was trained on ImageNet with specific preprocessing\n",
    "    \"\"\"\n",
    "    # Convert to float and normalize\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    \n",
    "    # ResNet50 expects 224x224 images (ImageNet size)\n",
    "    # Resize EuroSAT (64x64) to 224x224\n",
    "    image = tf.image.resize(image, [224, 224])\n",
    "    \n",
    "    return image, label\n",
    "\n",
    "# Apply preprocessing\n",
    "ds_train = ds_train.map(preprocess_resnet, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.map(preprocess_resnet, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.map(preprocess_resnet, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Data augmentation (same as Part A)\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "    layers.RandomRotation(0.25),\n",
    "    layers.RandomBrightness(0.1),\n",
    "], name='augmentation')\n",
    "\n",
    "def augment(image, label):\n",
    "    return data_augmentation(image, training=True), label\n",
    "\n",
    "ds_train = ds_train.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Batch and prefetch\n",
    "BATCH_SIZE = 32\n",
    "ds_train = ds_train.shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "ds_val = ds_val.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "ds_test = ds_test.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"\\n‚úì Data prepared for ResNet50\")\n",
    "print(f\"  Image size: 224√ó224 (ResNet50 standard)\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c0ffbdf",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 2: Load Pre-trained ResNet50\n",
    "\n",
    "ResNet50 architecture:\n",
    "- 50 layers deep\n",
    "- Skip connections (residual blocks)\n",
    "- ~25 million parameters\n",
    "- Pre-trained on ImageNet (1.2M images, 1000 classes)\n",
    "\n",
    "We'll load it **without the top classification layer** (include_top=False).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008aba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet50\n",
    "print(\"Loading pre-trained ResNet50...\")\n",
    "\n",
    "base_model = ResNet50(\n",
    "    include_top=False,           # Exclude ImageNet classifier\n",
    "    weights='imagenet',           # Use ImageNet pre-trained weights\n",
    "    input_shape=(224, 224, 3),   # EuroSAT RGB\n",
    "    pooling='avg'                # Global average pooling\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úì ResNet50 loaded\")\n",
    "print(f\"  Total parameters: {base_model.count_params():,}\")\n",
    "print(f\"  Trainable: {base_model.trainable}\")\n",
    "print(f\"  Output shape: {base_model.output_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43f97a6",
   "metadata": {},
   "source": [
    "### Freeze Base Model\n",
    "\n",
    "For **feature extraction**, we freeze all ResNet50 layers initially. This means:\n",
    "- Pre-trained weights don't change\n",
    "- Only train the new classification head\n",
    "- Much faster training\n",
    "- Prevents destroying good features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a65fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "print(\"‚úì Base model frozen\")\n",
    "print(f\"  Trainable parameters: {sum([tf.keras.backend.count_params(w) for w in base_model.trainable_weights]):,}\")\n",
    "print(f\"  Non-trainable parameters: {sum([tf.keras.backend.count_params(w) for w in base_model.non_trainable_weights]):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fcb1a4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 3: Feature Extraction - Train Classification Head (15 minutes)\n",
    "\n",
    "Now we add our custom classification layers on top of frozen ResNet50.\n",
    "\n",
    "**Architecture:**\n",
    "```\n",
    "Input (224√ó224√ó3)\n",
    "    ‚Üì\n",
    "ResNet50 Base (frozen) ‚Üí 2048 features\n",
    "    ‚Üì\n",
    "Dense(512, ReLU) + Dropout\n",
    "    ‚Üì\n",
    "Dense(10, Softmax)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6100a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build complete model with custom head\n",
    "inputs = keras.Input(shape=(224, 224, 3))\n",
    "\n",
    "# ResNet50 base\n",
    "x = base_model(inputs, training=False)\n",
    "\n",
    "# Custom classification head\n",
    "x = layers.Dense(512, activation='relu', name='fc1')(x)\n",
    "x = layers.Dropout(0.5, name='dropout1')(x)\n",
    "outputs = layers.Dense(num_classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "# Create model\n",
    "model_feature_extraction = keras.Model(inputs, outputs, name='ResNet50_FeatureExtraction')\n",
    "\n",
    "print(\"‚úì Model with custom head created\")\n",
    "model_feature_extraction.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585eb644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model_feature_extraction.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\n‚úì Model compiled for feature extraction\")\n",
    "print(\"  Only training the classification head (~500K parameters)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450ac689",
   "metadata": {},
   "source": [
    "### Train Classification Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffbf38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks\n",
    "callbacks_fe = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint('resnet50_feature_extraction.h5', monitor='val_accuracy', \n",
    "                    save_best_only=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7, verbose=1)\n",
    "]\n",
    "\n",
    "# Train\n",
    "print(\"Training classification head (feature extraction)...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "history_fe = model_feature_extraction.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=20,  # Fewer epochs needed\n",
    "    callbacks=callbacks_fe,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n‚úì Feature extraction training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e55077",
   "metadata": {},
   "source": [
    "### Evaluate Feature Extraction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618053ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss_fe, test_acc_fe = model_feature_extraction.evaluate(ds_test, verbose=0)\n",
    "\n",
    "print(f\"\\nüìä Feature Extraction Results:\")\n",
    "print(f\"   Test Accuracy: {test_acc_fe*100:.2f}%\")\n",
    "print(f\"   Test Loss: {test_loss_fe:.4f}\")\n",
    "\n",
    "if test_acc_fe > 0.92:\n",
    "    print(\"\\nüéâ Excellent! Already beating from-scratch CNN!\")\n",
    "    print(\"   Transfer learning is working well\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2685f5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 4: Fine-Tuning - Unfreeze Some Layers (15 minutes)\n",
    "\n",
    "Now we'll **fine-tune** by unfreezing the last few layers of ResNet50.\n",
    "\n",
    "**Strategy:**\n",
    "1. Unfreeze last 20 layers (out of 175)\n",
    "2. Use very low learning rate (1e-5)\n",
    "3. Allow model to adapt to satellite imagery\n",
    "\n",
    "**Why this works:**\n",
    "- Early layers (edges, textures) are general ‚Üí keep frozen\n",
    "- Later layers (objects, semantics) need adaptation ‚Üí unfreeze\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f514b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfreeze the base model\n",
    "base_model.trainable = True\n",
    "\n",
    "# But keep early layers frozen\n",
    "print(f\"Total layers in ResNet50: {len(base_model.layers)}\")\n",
    "\n",
    "# Freeze all layers except last 20\n",
    "for layer in base_model.layers[:-20]:\n",
    "    layer.trainable = False\n",
    "\n",
    "print(f\"\\n‚úì Fine-tuning configuration:\")\n",
    "print(f\"  Frozen layers: {len([l for l in base_model.layers if not l.trainable])}\")\n",
    "print(f\"  Trainable layers: {len([l for l in base_model.layers if l.trainable])}\")\n",
    "\n",
    "# Count trainable parameters\n",
    "trainable_params = sum([tf.keras.backend.count_params(w) for w in model_feature_extraction.trainable_weights])\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b28cade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompile with lower learning rate\n",
    "model_feature_extraction.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),  # Much lower!\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"‚úì Model recompiled for fine-tuning\")\n",
    "print(\"  Learning rate: 1e-5 (100x smaller)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845a597b",
   "metadata": {},
   "source": [
    "### Fine-Tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d5a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callbacks for fine-tuning\n",
    "callbacks_ft = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint('resnet50_finetuned.h5', monitor='val_accuracy', \n",
    "                    save_best_only=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-8, verbose=1)\n",
    "]\n",
    "\n",
    "# Continue training (fine-tuning)\n",
    "print(\"Fine-tuning model...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "history_ft = model_feature_extraction.fit(\n",
    "    ds_train,\n",
    "    validation_data=ds_val,\n",
    "    epochs=30,  # More epochs for fine-tuning\n",
    "    callbacks=callbacks_ft,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"\\n‚úì Fine-tuning complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f52101d",
   "metadata": {},
   "source": [
    "### Evaluate Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979a4fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "test_loss_ft, test_acc_ft = model_feature_extraction.evaluate(ds_test, verbose=0)\n",
    "\n",
    "print(f\"\\nüìä Fine-Tuned Model Results:\")\n",
    "print(f\"   Test Accuracy: {test_acc_ft*100:.2f}%\")\n",
    "print(f\"   Test Loss: {test_loss_ft:.4f}\")\n",
    "\n",
    "# Compare with feature extraction\n",
    "improvement = (test_acc_ft - test_acc_fe) * 100\n",
    "print(f\"\\n   Improvement: +{improvement:.2f}% over feature extraction\")\n",
    "\n",
    "if test_acc_ft > 0.94:\n",
    "    print(\"\\nüéâ Outstanding! >94% accuracy achieved!\")\n",
    "    print(\"   Transfer learning + fine-tuning is very effective\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad00cd9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Step 5: Comparison & Analysis (10 minutes)\n",
    "\n",
    "Let's compare all three approaches:\n",
    "1. **From-Scratch CNN** (Part A)\n",
    "2. **Transfer Learning - Feature Extraction**\n",
    "3. **Transfer Learning - Fine-Tuned**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4235d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary comparison\n",
    "# Note: Load Part A results if available, otherwise use typical values\n",
    "\n",
    "# Typical results (you can update with your actual Part A results)\n",
    "from_scratch_acc = 0.90  # Update with your Part A result\n",
    "\n",
    "comparison_data = {\n",
    "    'Method': [\n",
    "        'From-Scratch CNN\\n(Part A)',\n",
    "        'ResNet50\\nFeature Extraction',\n",
    "        'ResNet50\\nFine-Tuned'\n",
    "    ],\n",
    "    'Test Accuracy': [\n",
    "        from_scratch_acc * 100,\n",
    "        test_acc_fe * 100,\n",
    "        test_acc_ft * 100\n",
    "    ],\n",
    "    'Trainable Params': [\n",
    "        '~300K',\n",
    "        '~500K',\n",
    "        '~5M'\n",
    "    ],\n",
    "    'Training Time': [\n",
    "        '~15 min',\n",
    "        '~5 min',\n",
    "        '~10 min'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "print(df_comparison.to_string(index=False))\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdc8743",
   "metadata": {},
   "source": [
    "### Visualize Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3b3d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "methods = ['From-Scratch\\nCNN', 'ResNet50\\nFeature Ext.', 'ResNet50\\nFine-Tuned']\n",
    "accuracies = [from_scratch_acc * 100, test_acc_fe * 100, test_acc_ft * 100]\n",
    "colors = ['steelblue', 'orange', 'green']\n",
    "\n",
    "bars = ax.bar(methods, accuracies, color=colors, edgecolor='black', linewidth=2, alpha=0.8)\n",
    "\n",
    "ax.set_ylabel('Test Accuracy (%)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('EuroSAT Classification: Model Comparison', fontsize=14, fontweight='bold')\n",
    "ax.set_ylim(85, 100)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.3,\n",
    "            f'{acc:.2f}%',\n",
    "            ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Add baseline reference\n",
    "ax.axhline(y=90, color='red', linestyle='--', linewidth=2, alpha=0.5, label='90% threshold')\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Transfer learning provides significant improvement!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f2038e",
   "metadata": {},
   "source": [
    "### Confusion Matrix (Fine-Tuned Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d72bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for confusion matrix\n",
    "print(\"Generating predictions...\")\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "for images, labels in ds_test:\n",
    "    predictions = model_feature_extraction.predict(images, verbose=0)\n",
    "    y_true.extend(labels.numpy())\n",
    "    y_pred.extend(np.argmax(predictions, axis=1))\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
    "            xticklabels=class_names, yticklabels=class_names,\n",
    "            cbar_kws={'label': 'Count'}, ax=ax)\n",
    "\n",
    "ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "ax.set_ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Confusion Matrix - ResNet50 Fine-Tuned', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úì Confusion matrix for fine-tuned model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75016a8",
   "metadata": {},
   "source": [
    "### Per-Class Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad3dd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "print(\"\\nüìä Per-Class Metrics (Fine-Tuned Model):\")\n",
    "print(\"=\" * 80)\n",
    "print(report_df[:-3].round(3))  # Exclude averages\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Identify best and worst\n",
    "metrics_df = report_df[:-3]\n",
    "best_class = metrics_df['f1-score'].idxmax()\n",
    "worst_class = metrics_df['f1-score'].idxmin()\n",
    "\n",
    "print(f\"\\n‚ú® Best: {best_class} (F1={metrics_df.loc[best_class, 'f1-score']:.3f})\")\n",
    "print(f\"‚ö†Ô∏è  Worst: {worst_class} (F1={metrics_df.loc[worst_class, 'f1-score']:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec6d3cc",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéâ Transfer Learning Lab Complete!\n",
    "\n",
    "## Summary\n",
    "\n",
    "You've successfully:\n",
    "\n",
    "‚úÖ **Loaded** pre-trained ResNet50 (25M parameters from ImageNet)  \n",
    "‚úÖ **Feature Extraction:** Trained custom classifier head (92-93% accuracy)  \n",
    "‚úÖ **Fine-Tuned:** Adapted ResNet50 to satellite imagery (93-96% accuracy)  \n",
    "‚úÖ **Compared:** Demonstrated transfer learning superiority  \n",
    "‚úÖ **Achieved:** State-of-art results on EuroSAT  \n",
    "\n",
    "---\n",
    "\n",
    "## Key Insights\n",
    "\n",
    "### Why Transfer Learning Works\n",
    "\n",
    "1. **Pre-trained features are universal**\n",
    "   - Edges, textures, patterns learned on ImageNet\n",
    "   - Apply to satellite imagery without retraining\n",
    "\n",
    "2. **Less data required**\n",
    "   - ImageNet: 1.2M images\n",
    "   - EuroSAT: 27K images\n",
    "   - Transfer learning bridges the gap\n",
    "\n",
    "3. **Faster convergence**\n",
    "   - Start from good weights\n",
    "   - 5-15 min vs 15-30 min from scratch\n",
    "\n",
    "4. **Better accuracy**\n",
    "   - +3-6% improvement\n",
    "   - Critical for real-world applications\n",
    "\n",
    "### When to Use Transfer Learning\n",
    "\n",
    "‚úÖ **Use transfer learning when:**\n",
    "- Limited training data (<10K images)\n",
    "- Similar task (image classification)\n",
    "- Time/compute constrained\n",
    "- Need best accuracy\n",
    "\n",
    "‚ùå **Train from scratch when:**\n",
    "- Very different domain (medical, satellite with many bands)\n",
    "- Abundant data (>100K images)\n",
    "- Specific architectural requirements\n",
    "- Learning about CNNs (educational)\n",
    "\n",
    "---\n",
    "\n",
    "## Comparison Summary\n",
    "\n",
    "| Metric | From-Scratch | Feature Extraction | Fine-Tuned |\n",
    "|--------|--------------|-------------------|------------|\n",
    "| **Accuracy** | 90-92% | 92-93% | 93-96% |\n",
    "| **Training Time** | 15-20 min | 5-10 min | 10-15 min |\n",
    "| **Parameters Trained** | ~300K | ~500K | ~5M |\n",
    "| **Data Efficiency** | Needs more | Good | Best |\n",
    "| **Overfitting Risk** | Higher | Low | Medium |\n",
    "\n",
    "---\n",
    "\n",
    "## Philippine Applications\n",
    "\n",
    "**Transfer learning is ideal for:**\n",
    "\n",
    "1. **Mangrove Mapping**\n",
    "   - Limited labeled data\n",
    "   - High accuracy needed\n",
    "   - ResNet50 ‚Üí Fine-tune on Palawan mangroves\n",
    "\n",
    "2. **Rice Paddy Detection**\n",
    "   - Seasonal patterns\n",
    "   - VGG16 ‚Üí Fine-tune on Central Luzon\n",
    "\n",
    "3. **Informal Settlement Detection**\n",
    "   - Urban patterns similar to ImageNet\n",
    "   - ResNet50 ‚Üí Fine-tune on Metro Manila\n",
    "\n",
    "4. **Disaster Damage Assessment**\n",
    "   - Limited post-disaster data\n",
    "   - Transfer from pre-trained ‚Üí Quick deployment\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "### Continue to Part C: U-Net Segmentation\n",
    "- Pixel-level land cover classification\n",
    "- Encoder-decoder architecture\n",
    "- Palawan forest boundaries\n",
    "\n",
    "### Experiments to Try\n",
    "\n",
    "**Easy:**\n",
    "1. Unfreeze different numbers of layers (10, 30, 50)\n",
    "2. Try different learning rates (1e-4, 1e-6)\n",
    "3. Compare ResNet50 vs VGG16\n",
    "\n",
    "**Medium:**\n",
    "4. Use different pre-trained models (EfficientNet, MobileNet)\n",
    "5. Multi-spectral adaptation (10 bands)\n",
    "6. Apply to Palawan dataset\n",
    "\n",
    "**Advanced:**\n",
    "7. Progressive unfreezing (unfreeze layers gradually)\n",
    "8. Discriminative learning rates (different LR per layer)\n",
    "9. Ensemble multiple fine-tuned models\n",
    "\n",
    "---\n",
    "\n",
    "## Save Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058ae63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save fine-tuned model\n",
    "model_feature_extraction.save('resnet50_eurosat_finetuned_final.h5')\n",
    "print(\"‚úì Fine-tuned model saved\")\n",
    "\n",
    "# Save training histories\n",
    "import pickle\n",
    "with open('transfer_learning_history.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'feature_extraction': history_fe.history,\n",
    "        'fine_tuning': history_ft.history\n",
    "    }, f)\n",
    "print(\"‚úì Training histories saved\")\n",
    "\n",
    "# Export results\n",
    "results = pd.DataFrame({\n",
    "    'Method': ['From-Scratch', 'Feature Extraction', 'Fine-Tuned'],\n",
    "    'Test_Accuracy': [from_scratch_acc, test_acc_fe, test_acc_ft]\n",
    "})\n",
    "results.to_csv('transfer_learning_comparison.csv', index=False)\n",
    "print(\"‚úì Comparison results saved\")\n",
    "\n",
    "print(\"\\nüéä All done! Ready for U-Net segmentation (Part C)...\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
