<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.25">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="CoPhil Advanced Training Program">
<meta name="dcterms.date" content="2025-10-16">

<title>Session 4: CNN Hands-on Lab – CoPhil EO AI/ML Training</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<link href="../../day2/notebooks/session1_theory_notebook_STUDENT.html" rel="next">
<link href="../../day2/sessions/session3.html" rel="prev">
<link href="../../images/favicon.png" rel="icon" type="image/png">
<script src="../../site_libs/quarto-html/quarto.js" type="module"></script>
<script src="../../site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="../../site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-c9822816d3895e59fda95a6fa7545fef.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark-4a074efccdeff27617fbc72d37c1244e.css" rel="stylesheet" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-c9822816d3895e59fda95a6fa7545fef.css" rel="stylesheet" class="quarto-color-scheme-extra" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-3775014fae9fc394bbda1d6ff89dd45e.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark-a15f5dce5650fb3fe5aba34e3b6df9a9.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<link href="../../site_libs/bootstrap/bootstrap-3775014fae9fc394bbda1d6ff89dd45e.min.css" rel="stylesheet" append-hash="true" class="quarto-color-scheme-extra" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>


<link rel="stylesheet" href="../../styles/custom.css">
<link rel="stylesheet" href="../../styles/phase2-enhancements.css">
</head>

<body class="nav-sidebar floating nav-fixed quarto-light"><script id="quarto-html-before-body" type="application/javascript">
    const toggleBodyColorMode = (bsSheetEl) => {
      const mode = bsSheetEl.getAttribute("data-mode");
      const bodyEl = window.document.querySelector("body");
      if (mode === "dark") {
        bodyEl.classList.add("quarto-dark");
        bodyEl.classList.remove("quarto-light");
      } else {
        bodyEl.classList.add("quarto-light");
        bodyEl.classList.remove("quarto-dark");
      }
    }
    const toggleBodyColorPrimary = () => {
      const bsSheetEl = window.document.querySelector("link#quarto-bootstrap:not([rel=disabled-stylesheet])");
      if (bsSheetEl) {
        toggleBodyColorMode(bsSheetEl);
      }
    }
    const setColorSchemeToggle = (alternate) => {
      const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
      for (let i=0; i < toggles.length; i++) {
        const toggle = toggles[i];
        if (toggle) {
          if (alternate) {
            toggle.classList.add("alternate");
          } else {
            toggle.classList.remove("alternate");
          }
        }
      }
    };
    const toggleColorMode = (alternate) => {
      // Switch the stylesheets
      const primaryStylesheets = window.document.querySelectorAll('link.quarto-color-scheme:not(.quarto-color-alternate)');
      const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
      manageTransitions('#quarto-margin-sidebar .nav-link', false);
      if (alternate) {
        // note: dark is layered on light, we don't disable primary!
        enableStylesheet(alternateStylesheets);
        for (const sheetNode of alternateStylesheets) {
          if (sheetNode.id === "quarto-bootstrap") {
            toggleBodyColorMode(sheetNode);
          }
        }
      } else {
        disableStylesheet(alternateStylesheets);
        enableStylesheet(primaryStylesheets)
        toggleBodyColorPrimary();
      }
      manageTransitions('#quarto-margin-sidebar .nav-link', true);
      // Switch the toggles
      setColorSchemeToggle(alternate)
      // Hack to workaround the fact that safari doesn't
      // properly recolor the scrollbar when toggling (#1455)
      if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
        manageTransitions("body", false);
        window.scrollTo(0, 1);
        setTimeout(() => {
          window.scrollTo(0, 0);
          manageTransitions("body", true);
        }, 40);
      }
    }
    const disableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        stylesheet.rel = 'disabled-stylesheet';
      }
    }
    const enableStylesheet = (stylesheets) => {
      for (let i=0; i < stylesheets.length; i++) {
        const stylesheet = stylesheets[i];
        if(stylesheet.rel !== 'stylesheet') { // for Chrome, which will still FOUC without this check
          stylesheet.rel = 'stylesheet';
        }
      }
    }
    const manageTransitions = (selector, allowTransitions) => {
      const els = window.document.querySelectorAll(selector);
      for (let i=0; i < els.length; i++) {
        const el = els[i];
        if (allowTransitions) {
          el.classList.remove('notransition');
        } else {
          el.classList.add('notransition');
        }
      }
    }
    const isFileUrl = () => {
      return window.location.protocol === 'file:';
    }
    const hasAlternateSentinel = () => {
      let styleSentinel = getColorSchemeSentinel();
      if (styleSentinel !== null) {
        return styleSentinel === "alternate";
      } else {
        return false;
      }
    }
    const setStyleSentinel = (alternate) => {
      const value = alternate ? "alternate" : "default";
      if (!isFileUrl()) {
        window.localStorage.setItem("quarto-color-scheme", value);
      } else {
        localAlternateSentinel = value;
      }
    }
    const getColorSchemeSentinel = () => {
      if (!isFileUrl()) {
        const storageValue = window.localStorage.getItem("quarto-color-scheme");
        return storageValue != null ? storageValue : localAlternateSentinel;
      } else {
        return localAlternateSentinel;
      }
    }
    const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
      const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
      const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
      let newTheme = '';
      if(authorPrefersDark) {
        newTheme = isAlternate ? baseTheme : alternateTheme;
      } else {
        newTheme = isAlternate ? alternateTheme : baseTheme;
      }
      const changeGiscusTheme = () => {
        // From: https://github.com/giscus/giscus/issues/336
        const sendMessage = (message) => {
          const iframe = document.querySelector('iframe.giscus-frame');
          if (!iframe) return;
          iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
        }
        sendMessage({
          setConfig: {
            theme: newTheme
          }
        });
      }
      const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
      if (isGiscussLoaded) {
        changeGiscusTheme();
      }
    };
    const authorPrefersDark = false;
    const darkModeDefault = authorPrefersDark;
      document.querySelector('link#quarto-text-highlighting-styles.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
      document.querySelector('link#quarto-bootstrap.quarto-color-scheme-extra').rel = 'disabled-stylesheet';
    let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
    // Dark / light mode switch
    window.quartoToggleColorScheme = () => {
      // Read the current dark / light value
      let toAlternate = !hasAlternateSentinel();
      toggleColorMode(toAlternate);
      setStyleSentinel(toAlternate);
      toggleGiscusIfUsed(toAlternate, darkModeDefault);
      window.dispatchEvent(new Event('resize'));
    };
    // Switch to dark mode if need be
    if (hasAlternateSentinel()) {
      toggleColorMode(true);
    } else {
      toggleColorMode(false);
    }
  </script>

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a href="../../index.html" class="navbar-brand navbar-brand-logo">
    </a>
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">CoPhil EO AI/ML Training</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link active" href="../../index.html" aria-current="page"> 
<span class="menu-text">Home</span></a>
  </li>  
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-training-days" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Training Days</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-training-days">    
        <li>
    <a class="dropdown-item" href="../../day1/index.html">
 <span class="dropdown-text">Day 1: EO Data &amp; Fundamentals</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../day2/index.html">
 <span class="dropdown-text">Day 2: Machine Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../day3/index.html">
 <span class="dropdown-text">Day 3: Deep Learning</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../day4/index.html">
 <span class="dropdown-text">Day 4: Advanced Topics</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-resources" role="link" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Resources</span>
    </a>
    <ul class="dropdown-menu" aria-labelledby="nav-menu-resources">    
        <li>
    <a class="dropdown-item" href="../../resources/setup.html">
 <span class="dropdown-text">Setup Guide</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../resources/philippine-eo.html">
 <span class="dropdown-text">Philippine EO Links</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../resources/cheatsheets.html">
 <span class="dropdown-text">Cheat Sheets</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../resources/faq.html">
 <span class="dropdown-text">FAQ</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="../../resources/glossary.html">
 <span class="dropdown-text">Glossary</span></a>
  </li>  
    </ul>
  </li>
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/cophil-training-v1.0"> <i class="bi bi-github" role="img" aria-label="GitHub">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../resources/downloads.html"> <i class="bi bi-download" role="img">
</i> 
<span class="menu-text">Materials</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../day2/sessions/session1.html">Sessions</a></li><li class="breadcrumb-item"><a href="../../day2/sessions/session4.html">Session 4: CNN Hands-on Lab</a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="../../index.html" class="sidebar-logo-link">
      </a>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Day 2: Machine Learning for Earth Observation</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">Sessions</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/sessions/session1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 1: Supervised Classification with Random Forest</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/sessions/session2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 2: Advanced Palawan Land Cover Lab</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/sessions/session3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 3: Introduction to Deep Learning and CNNs</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/sessions/session4.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text">Session 4: CNN Hands-on Lab</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false">
 <span class="menu-text">Notebooks</span></a>
          <a class="sidebar-item-toggle text-start collapsed" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="false" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 ">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/notebooks/session1_theory_notebook_STUDENT.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 1 Theory: Understanding Random Forest for Earth Observation</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/notebooks/session1_hands_on_lab_student.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 1 Hands-on Lab: Palawan Land Cover Classification with Random Forest</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/notebooks/session2_extended_lab_STUDENT.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 2: Advanced Palawan Land Cover Classification Lab</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/notebooks/session3_theory_interactive.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 3: Deep Learning &amp; CNN Theory - Interactive Notebook</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/notebooks/session4_cnn_classification_STUDENT.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 4: CNN Hands-On Lab - EuroSAT Classification</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../../day2/notebooks/session4_transfer_learning_STUDENT.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Session 4 Part B: Transfer Learning with ResNet50</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="2">
    <h2 id="toc-title">On This Page</h2>
   
  <ul>
  <li><a href="#session-4-cnn-hands-on-lab" id="toc-session-4-cnn-hands-on-lab" class="nav-link active" data-scroll-target="#session-4-cnn-hands-on-lab">Session 4: CNN Hands-on Lab</a>
  <ul class="collapse">
  <li><a href="#building-and-training-cnns-for-eo-image-classification" id="toc-building-and-training-cnns-for-eo-image-classification" class="nav-link" data-scroll-target="#building-and-training-cnns-for-eo-image-classification">Building and Training CNNs for EO Image Classification</a></li>
  </ul></li>
  <li><a href="#session-overview" id="toc-session-overview" class="nav-link" data-scroll-target="#session-overview">Session Overview</a></li>
  <li><a href="#presentation-slides" id="toc-presentation-slides" class="nav-link" data-scroll-target="#presentation-slides">Presentation Slides</a></li>
  <li><a href="#what-youll-accomplish" id="toc-what-youll-accomplish" class="nav-link" data-scroll-target="#what-youll-accomplish">What You’ll Accomplish</a></li>
  <li><a href="#why-this-matters-for-philippine-eo" id="toc-why-this-matters-for-philippine-eo" class="nav-link" data-scroll-target="#why-this-matters-for-philippine-eo">Why This Matters for Philippine EO</a></li>
  <li><a href="#session-structure" id="toc-session-structure" class="nav-link" data-scroll-target="#session-structure">Session Structure</a>
  <ul class="collapse">
  <li><a href="#part-a-environment-setup-data-preparation-30-minutes" id="toc-part-a-environment-setup-data-preparation-30-minutes" class="nav-link" data-scroll-target="#part-a-environment-setup-data-preparation-30-minutes">Part A: Environment Setup &amp; Data Preparation (30 minutes)</a></li>
  <li><a href="#part-b-building-cnn-from-scratch-40-minutes" id="toc-part-b-building-cnn-from-scratch-40-minutes" class="nav-link" data-scroll-target="#part-b-building-cnn-from-scratch-40-minutes">Part B: Building CNN from Scratch (40 minutes)</a></li>
  <li><a href="#part-c-u-net-for-semantic-segmentation-60-minutes" id="toc-part-c-u-net-for-semantic-segmentation-60-minutes" class="nav-link" data-scroll-target="#part-c-u-net-for-semantic-segmentation-60-minutes">Part C: U-Net for Semantic Segmentation (60 minutes)</a></li>
  <li><a href="#part-d-comprehensive-evaluation-30-minutes" id="toc-part-d-comprehensive-evaluation-30-minutes" class="nav-link" data-scroll-target="#part-d-comprehensive-evaluation-30-minutes">Part D: Comprehensive Evaluation (30 minutes)</a></li>
  <li><a href="#part-e-transfer-learning-20-minutes" id="toc-part-e-transfer-learning-20-minutes" class="nav-link" data-scroll-target="#part-e-transfer-learning-20-minutes">Part E: Transfer Learning (20 minutes)</a></li>
  <li><a href="#part-f-philippine-eo-applications-10-minutes" id="toc-part-f-philippine-eo-applications-10-minutes" class="nav-link" data-scroll-target="#part-f-philippine-eo-applications-10-minutes">Part F: Philippine EO Applications (10 minutes)</a></li>
  </ul></li>
  <li><a href="#hands-on-notebook" id="toc-hands-on-notebook" class="nav-link" data-scroll-target="#hands-on-notebook">Hands-On Notebook</a></li>
  <li><a href="#expected-outcomes" id="toc-expected-outcomes" class="nav-link" data-scroll-target="#expected-outcomes">Expected Outcomes</a></li>
  <li><a href="#troubleshooting-guide" id="toc-troubleshooting-guide" class="nav-link" data-scroll-target="#troubleshooting-guide">Troubleshooting Guide</a>
  <ul class="collapse">
  <li><a href="#common-issues-solutions" id="toc-common-issues-solutions" class="nav-link" data-scroll-target="#common-issues-solutions">Common Issues &amp; Solutions</a></li>
  </ul></li>
  <li><a href="#key-concepts-recap" id="toc-key-concepts-recap" class="nav-link" data-scroll-target="#key-concepts-recap">Key Concepts Recap</a>
  <ul class="collapse">
  <li><a href="#convolutional-layers" id="toc-convolutional-layers" class="nav-link" data-scroll-target="#convolutional-layers">Convolutional Layers</a></li>
  <li><a href="#pooling-layers" id="toc-pooling-layers" class="nav-link" data-scroll-target="#pooling-layers">Pooling Layers</a></li>
  <li><a href="#activation-functions" id="toc-activation-functions" class="nav-link" data-scroll-target="#activation-functions">Activation Functions</a></li>
  <li><a href="#loss-functions" id="toc-loss-functions" class="nav-link" data-scroll-target="#loss-functions">Loss Functions</a></li>
  <li><a href="#optimizers" id="toc-optimizers" class="nav-link" data-scroll-target="#optimizers">Optimizers</a></li>
  </ul></li>
  <li><a href="#resources" id="toc-resources" class="nav-link" data-scroll-target="#resources">Resources</a>
  <ul class="collapse">
  <li><a href="#documentation-tutorials" id="toc-documentation-tutorials" class="nav-link" data-scroll-target="#documentation-tutorials">Documentation &amp; Tutorials</a></li>
  <li><a href="#pre-trained-models" id="toc-pre-trained-models" class="nav-link" data-scroll-target="#pre-trained-models">Pre-trained Models</a></li>
  <li><a href="#philippine-eo-resources" id="toc-philippine-eo-resources" class="nav-link" data-scroll-target="#philippine-eo-resources">Philippine EO Resources</a></li>
  <li><a href="#course-materials" id="toc-course-materials" class="nav-link" data-scroll-target="#course-materials">Course Materials</a></li>
  </ul></li>
  <li><a href="#next-steps" id="toc-next-steps" class="nav-link" data-scroll-target="#next-steps">Next Steps</a></li>
  <li><a href="#assessment-exercises" id="toc-assessment-exercises" class="nav-link" data-scroll-target="#assessment-exercises">Assessment &amp; Exercises</a>
  <ul class="collapse">
  <li><a href="#formative-assessment-in-notebook" id="toc-formative-assessment-in-notebook" class="nav-link" data-scroll-target="#formative-assessment-in-notebook">Formative Assessment (In-Notebook)</a></li>
  <li><a href="#challenge-exercises" id="toc-challenge-exercises" class="nav-link" data-scroll-target="#challenge-exercises">Challenge Exercises</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">


<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../../day2/sessions/session1.html">Sessions</a></li><li class="breadcrumb-item"><a href="../../day2/sessions/session4.html">Session 4: CNN Hands-on Lab</a></li></ol></nav>
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title">Session 4: CNN Hands-on Lab</h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Code</button></div></div>
<p class="subtitle lead">Building and Training CNNs for EO Image Classification</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Instructor</div>
    <div class="quarto-title-meta-contents">
             <p>CoPhil Advanced Training Program </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Date</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 16, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<nav class="breadcrumb" aria-label="Breadcrumb">
<a href="../../index.html">Home</a> <span class="breadcrumb-separator" aria-hidden="true">›</span> <a href="../index.html">Day 2</a> <span class="breadcrumb-separator" aria-hidden="true">›</span> <span class="breadcrumb-current">Session 4</span>
</nav>
<section id="session-4-cnn-hands-on-lab" class="level1 hero">
<h1>Session 4: CNN Hands-on Lab</h1>
<section id="building-and-training-cnns-for-eo-image-classification" class="level3">
<h3 class="anchored" data-anchor-id="building-and-training-cnns-for-eo-image-classification">Building and Training CNNs for EO Image Classification</h3>
<p>From theory to implementation with TensorFlow and PyTorch</p>
</section>
</section>
<section id="session-overview" class="level2">
<h2 class="anchored" data-anchor-id="session-overview">Session Overview</h2>
<p><strong>Duration:</strong> 2.5 hours | <strong>Type:</strong> Intensive Hands-On Lab | <strong>Difficulty:</strong> Intermediate-Advanced</p>
<hr>
<p>This session transforms CNN theory from Session 3 into working code. You’ll build, train, and evaluate real deep learning models for Earth Observation, achieving significantly higher accuracy than the Random Forest models from Sessions 1-2.</p>
</section>
<section id="presentation-slides" class="level2">
<h2 class="anchored" data-anchor-id="presentation-slides">Presentation Slides</h2>
<iframe src="../presentations/session4_cnn_lab.html" width="100%" height="600" style="border: 1px solid #ccc; border-radius: 4px;">
</iframe>
<hr>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Prerequisites
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Technical Requirements:</strong> - ✓ Complete Session 3 (CNN theory and concepts) - ✓ Understand convolution, pooling, activation functions - ✓ Python programming proficiency (NumPy, pandas basics) - ✓ Google Colab account with GPU access - ✓ Stable internet connection (for dataset downloads)</p>
<p><strong>Conceptual Understanding:</strong> - ✓ Know difference between traditional ML and deep learning - ✓ Understand supervised learning workflow - ✓ Familiar with classification metrics (accuracy, confusion matrix) - ✓ Basic understanding of gradient descent optimization</p>
</div>
</div>
<hr>
</section>
<section id="what-youll-accomplish" class="level2">
<h2 class="anchored" data-anchor-id="what-youll-accomplish">What You’ll Accomplish</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>Learning Outcomes
</div>
</div>
<div class="callout-body-container callout-body">
<p>After completing this session, you will be able to:</p>
<section id="implement-cnns-in-tensorflowkeras" class="level3">
<h3 class="anchored" data-anchor-id="implement-cnns-in-tensorflowkeras">1. Implement CNNs in TensorFlow/Keras</h3>
<ul>
<li>Set up GPU-accelerated deep learning environment</li>
<li>Load and preprocess Earth observation datasets</li>
<li>Build CNN architectures layer-by-layer from scratch</li>
<li>Compile models with appropriate loss functions and optimizers</li>
<li>Train models with advanced callbacks (early stopping, checkpointing)</li>
</ul>
</section>
<section id="work-with-eurosat-benchmark-dataset" class="level3">
<h3 class="anchored" data-anchor-id="work-with-eurosat-benchmark-dataset">2. Work with EuroSAT Benchmark Dataset</h3>
<ul>
<li>Download and prepare standardized EO dataset</li>
<li>Understand 10-class land use classification task</li>
<li>Create efficient data pipelines with tf.data.Dataset</li>
<li>Apply data augmentation strategies for satellite imagery</li>
<li>Handle train/validation/test splits properly</li>
</ul>
</section>
<section id="evaluate-deep-learning-models" class="level3">
<h3 class="anchored" data-anchor-id="evaluate-deep-learning-models">3. Evaluate Deep Learning Models</h3>
<ul>
<li>Generate and interpret confusion matrices</li>
<li>Calculate per-class precision, recall, and F1-scores</li>
<li>Visualize training and validation curves</li>
<li>Analyze misclassifications and model errors</li>
<li>Compare CNN performance with Random Forest baseline</li>
</ul>
</section>
<section id="apply-transfer-learning" class="level3">
<h3 class="anchored" data-anchor-id="apply-transfer-learning">4. Apply Transfer Learning</h3>
<ul>
<li>Load pre-trained models (ResNet50, VGG16, EfficientNet)</li>
<li>Understand when and why to use pre-trained weights</li>
<li>Freeze and fine-tune network layers strategically</li>
<li>Adapt ImageNet models for Earth observation tasks</li>
<li>Compare from-scratch vs.&nbsp;transfer learning performance</li>
</ul>
</section>
<section id="optimize-and-debug-models" class="level3">
<h3 class="anchored" data-anchor-id="optimize-and-debug-models">5. Optimize and Debug Models</h3>
<ul>
<li>Prevent overfitting with dropout and regularization</li>
<li>Tune hyperparameters (learning rate, batch size, architecture)</li>
<li>Diagnose training issues (vanishing gradients, exploding loss)</li>
<li>Use callbacks for adaptive learning</li>
<li>Implement best practices for reproducibility</li>
</ul>
</section>
</div>
</div>
<hr>
</section>
<section id="why-this-matters-for-philippine-eo" class="level2">
<h2 class="anchored" data-anchor-id="why-this-matters-for-philippine-eo">Why This Matters for Philippine EO</h2>
<div class="feature-grid">
<div class="feature-card">
<p><strong>🎯 Accuracy Improvement</strong></p>
<p>CNNs consistently outperform Random Forest: - <strong>EuroSAT:</strong> 92-98% vs 87-90% - <strong>Palawan:</strong> Estimated +5-10% accuracy - <strong>Critical for:</strong> DRR applications where errors cost lives</p>
</div>
<div class="feature-card">
<p><strong>🌍 Spatial Context</strong></p>
<p>CNNs understand image context: - <strong>RF:</strong> Treats pixels independently - <strong>CNN:</strong> Captures spatial patterns - <strong>Benefit:</strong> Better forest boundary detection, fewer misclassifications</p>
</div>
<div class="feature-card">
<p><strong>⚡ Scalability</strong></p>
<p>Once trained, CNNs scale efficiently: - <strong>Deployment:</strong> Fast inference on new imagery - <strong>Automation:</strong> Process entire Philippines nightly - <strong>Operations:</strong> PhilSA operational monitoring</p>
</div>
<div class="feature-card">
<p><strong>🔄 Transfer Learning</strong></p>
<p>Pre-trained models accelerate development: - <strong>Small Data:</strong> Works with limited labeled samples - <strong>Time Savings:</strong> Days vs weeks of training - <strong>Philippine Context:</strong> Adapt global models locally</p>
</div>
</div>
<hr>
</section>
<section id="session-structure" class="level2">
<h2 class="anchored" data-anchor-id="session-structure">Session Structure</h2>
<section id="part-a-environment-setup-data-preparation-30-minutes" class="level3">
<h3 class="anchored" data-anchor-id="part-a-environment-setup-data-preparation-30-minutes">Part A: Environment Setup &amp; Data Preparation (30 minutes)</h3>
<p><strong>Setup Google Colab Environment</strong> - Configure GPU runtime for acceleration - Install required libraries (TensorFlow, Keras, auxiliary packages) - Verify GPU detection and availability - Set random seeds for reproducibility</p>
<p><strong>Download EuroSAT Dataset</strong> - Understand the benchmark dataset (27,000 Sentinel-2 patches) - Automated download and extraction - Verify data integrity with checksums - Explore directory structure and file formats</p>
<p><strong>Data Loading and Exploration</strong> - Load images and labels efficiently - Visualize sample images from each class - Analyze class distribution and balance - Calculate dataset statistics (mean, std)</p>
<p><strong>Create Data Pipeline</strong> - Split data (70% train, 15% validation, 15% test) - Build tf.data.Dataset for efficient loading - Apply normalization and preprocessing - Implement data augmentation for training set - Configure batching, shuffling, and prefetching</p>
<hr>
</section>
<section id="part-b-building-cnn-from-scratch-40-minutes" class="level3">
<h3 class="anchored" data-anchor-id="part-b-building-cnn-from-scratch-40-minutes">Part B: Building CNN from Scratch (40 minutes)</h3>
<p><strong>Design CNN Architecture</strong> - Start with simple 3-block architecture - Understand layer choices and progression - Calculate output dimensions at each layer - Visualize network architecture diagram</p>
<p><strong>Implementation Details:</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Example architecture (you'll implement in notebook)</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>Model: <span class="st">"eurosat_cnn"</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>_________________________________________________________________</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>Layer (<span class="bu">type</span>)                Output Shape              Param <span class="co">#   </span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="op">=================================================================</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>conv2d_1 (Conv2D)          (<span class="va">None</span>, <span class="dv">62</span>, <span class="dv">62</span>, <span class="dv">32</span>)        <span class="dv">896</span>       </span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>activation_1 (ReLU)        (<span class="va">None</span>, <span class="dv">62</span>, <span class="dv">62</span>, <span class="dv">32</span>)        <span class="dv">0</span>         </span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>max_pooling2d_1            (<span class="va">None</span>, <span class="dv">31</span>, <span class="dv">31</span>, <span class="dv">32</span>)        <span class="dv">0</span>         </span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>conv2d_2 (Conv2D)          (<span class="va">None</span>, <span class="dv">29</span>, <span class="dv">29</span>, <span class="dv">64</span>)        <span class="dv">18</span>,<span class="dv">496</span>    </span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>activation_2 (ReLU)        (<span class="va">None</span>, <span class="dv">29</span>, <span class="dv">29</span>, <span class="dv">64</span>)        <span class="dv">0</span>         </span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>max_pooling2d_2            (<span class="va">None</span>, <span class="dv">14</span>, <span class="dv">14</span>, <span class="dv">64</span>)        <span class="dv">0</span>         </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>conv2d_3 (Conv2D)          (<span class="va">None</span>, <span class="dv">12</span>, <span class="dv">12</span>, <span class="dv">128</span>)       <span class="dv">73</span>,<span class="dv">856</span>    </span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>activation_3 (ReLU)        (<span class="va">None</span>, <span class="dv">12</span>, <span class="dv">12</span>, <span class="dv">128</span>)       <span class="dv">0</span>         </span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>max_pooling2d_3            (<span class="va">None</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">128</span>)         <span class="dv">0</span>         </span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>flatten (Flatten)          (<span class="va">None</span>, <span class="dv">4608</span>)              <span class="dv">0</span>         </span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>dropout (Dropout)          (<span class="va">None</span>, <span class="dv">4608</span>)              <span class="dv">0</span>         </span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>dense_1 (Dense)            (<span class="va">None</span>, <span class="dv">128</span>)               <span class="dv">589</span>,<span class="dv">952</span>   </span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>activation_4 (ReLU)        (<span class="va">None</span>, <span class="dv">128</span>)               <span class="dv">0</span>         </span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>dropout_2 (Dropout)        (<span class="va">None</span>, <span class="dv">128</span>)               <span class="dv">0</span>         </span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>dense_2 (Dense)            (<span class="va">None</span>, <span class="dv">10</span>)                <span class="dv">1</span>,<span class="dv">290</span>     </span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>activation_5 (Softmax)     (<span class="va">None</span>, <span class="dv">10</span>)                <span class="dv">0</span>         </span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="op">=================================================================</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>Total params: <span class="dv">684</span>,<span class="dv">490</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>Trainable params: <span class="dv">684</span>,<span class="dv">490</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>Non<span class="op">-</span>trainable params: <span class="dv">0</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Key Architectural Decisions:</strong> - <strong>Filter progression (32→64→128):</strong> Capture features at multiple scales - <strong>3×3 convolutions:</strong> Standard choice balancing receptive field and parameters - <strong>MaxPooling:</strong> Spatial dimension reduction and translation invariance - <strong>Dropout (0.3-0.5):</strong> Regularization to prevent overfitting - <strong>Dense layers:</strong> Final classification from learned features - <strong>Softmax output:</strong> Probability distribution over 10 classes</p>
<p><strong>Model Compilation:</strong> - <strong>Loss function:</strong> Categorical cross-entropy (multi-class classification) - <strong>Optimizer:</strong> Adam (adaptive learning rate, generally robust) - <strong>Metrics:</strong> Accuracy, top-3 accuracy - <strong>Learning rate:</strong> Start with 0.001 (default), tune if needed</p>
<hr>
</section>
<section id="part-c-u-net-for-semantic-segmentation-60-minutes" class="level3">
<h3 class="anchored" data-anchor-id="part-c-u-net-for-semantic-segmentation-60-minutes">Part C: U-Net for Semantic Segmentation (60 minutes)</h3>
<p><strong>Configure Training Callbacks</strong></p>
<div class="feature-grid">
<div class="feature-card">
<p><strong>EarlyStopping</strong></p>
<p>Stop training when validation loss stops improving:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>EarlyStopping(</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_loss'</span>,</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    patience<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    restore_best_weights<span class="op">=</span><span class="va">True</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><em>Prevents overfitting, saves time</em></p>
</div>
<div class="feature-card">
<p><strong>ModelCheckpoint</strong></p>
<p>Save best model during training:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>ModelCheckpoint(</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">'best_model.h5'</span>,</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_accuracy'</span>,</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    save_best_only<span class="op">=</span><span class="va">True</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><em>Preserves optimal weights</em></p>
</div>
<div class="feature-card">
<p><strong>ReduceLROnPlateau</strong></p>
<p>Lower learning rate when stuck:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>ReduceLROnPlateau(</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_loss'</span>,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    factor<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    patience<span class="op">=</span><span class="dv">3</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><em>Helps escape local minima</em></p>
</div>
<div class="feature-card">
<p><strong>TensorBoard</strong></p>
<p>Real-time training visualization:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>TensorBoard(</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>    log_dir<span class="op">=</span><span class="st">'./logs'</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><em>Monitor metrics live</em></p>
</div>
</div>
<p><strong>Execute Training</strong> - Train for 20-30 epochs (likely stops early) - Monitor training/validation metrics in real-time - Observe learning curves for overfitting signs - Track GPU utilization and training speed</p>
<p><strong>Interpret Learning Curves</strong></p>
<p><strong>Healthy Training:</strong> - Train loss decreases steadily - Validation loss decreases, plateaus - Small train-val gap (&lt;5-10%) - Validation accuracy plateaus at high value</p>
<p><strong>Overfitting Signs:</strong> - Train accuracy → 100%, val accuracy plateaus low - Large train-val gap (&gt;15-20%) - Validation loss increases while train loss decreases - <strong>Solution:</strong> More dropout, stronger regularization, more data</p>
<p><strong>Underfitting Signs:</strong> - Both train and val accuracy low - Loss plateaus at high value - No improvement with more epochs - <strong>Solution:</strong> More complex model, lower regularization, train longer</p>
<hr>
</section>
<section id="part-d-comprehensive-evaluation-30-minutes" class="level3">
<h3 class="anchored" data-anchor-id="part-d-comprehensive-evaluation-30-minutes">Part D: Comprehensive Evaluation (30 minutes)</h3>
<p><strong>Test Set Performance</strong> - Load best saved model - Evaluate on held-out test set - Calculate final accuracy and loss - Compare with validation performance</p>
<p><strong>Confusion Matrix Analysis</strong></p>
<p>Generate and visualize 10×10 confusion matrix:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>True ↓ / Pred →</th>
<th>AnnualCrop</th>
<th>Forest</th>
<th>Herbaceous</th>
<th>Highway</th>
<th>…</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>AnnualCrop</td>
<td><strong>450</strong></td>
<td>12</td>
<td>8</td>
<td>2</td>
<td>…</td>
</tr>
<tr class="even">
<td>Forest</td>
<td>5</td>
<td><strong>492</strong></td>
<td>3</td>
<td>0</td>
<td>…</td>
</tr>
<tr class="odd">
<td>Herbaceous</td>
<td>18</td>
<td>7</td>
<td><strong>441</strong></td>
<td>1</td>
<td>…</td>
</tr>
<tr class="even">
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
<td>…</td>
</tr>
</tbody>
</table>
<p><strong>Insights from Confusion:</strong> - <strong>Diagonal values:</strong> Correct classifications (darker = better) - <strong>Off-diagonal:</strong> Common confusions - <strong>Typical EO confusions:</strong> - AnnualCrop ↔︎ Herbaceous (similar vegetation) - Industrial ↔︎ Highway (both gray infrastructure) - Forest ↔︎ PermanentCrop (tree canopies)</p>
<p><strong>Per-Class Metrics</strong></p>
<pre><code>              precision    recall  f1-score   support

  AnnualCrop       0.93      0.94      0.93       478
      Forest       0.96      0.97      0.97       507
  Herbaceous       0.91      0.92      0.92       481
     Highway       0.94      0.92      0.93       453
  Industrial       0.89      0.87      0.88       461
     Pasture       0.90      0.91      0.91       489
PermanentCrop      0.92      0.91      0.92       471
 Residential       0.95      0.96      0.95       498
       River       0.98      0.97      0.98       502
     SeaLake       0.97      0.98      0.98       510

    accuracy                           0.94      4850
   macro avg       0.94      0.94      0.94      4850
weighted avg       0.94      0.94      0.94      4850</code></pre>
<p><strong>Error Analysis</strong> - Identify most confused class pairs - Visualize misclassified examples - Understand model failure modes - Suggest improvements</p>
<hr>
</section>
<section id="part-e-transfer-learning-20-minutes" class="level3">
<h3 class="anchored" data-anchor-id="part-e-transfer-learning-20-minutes">Part E: Transfer Learning (20 minutes)</h3>
<p><strong>Why Transfer Learning for EO?</strong></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>Transfer Learning Benefits
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>ImageNet Pre-training Advantages:</strong> - <strong>Low-level features transfer:</strong> Edges, textures, colors are universal - <strong>Reduced training time:</strong> 80-90% faster convergence - <strong>Better with limited data:</strong> Works with 100s of samples vs 1000s - <strong>Higher accuracy:</strong> +2-5% typical improvement - <strong>Regularization effect:</strong> Pre-trained weights prevent overfitting</p>
<p><strong>When to Use:</strong> - Limited labeled training data (&lt;5000 samples) - Similar task to ImageNet (object recognition) - Time/compute constraints - Need strong baseline quickly</p>
<p><strong>When NOT to Use:</strong> - Very different from natural images (SAR, hyperspectral) - Abundant labeled data (&gt;50K samples) - Highly specialized task</p>
</div>
</div>
<p><strong>Load Pre-trained Model</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.applications <span class="im">import</span> ResNet50</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Load ResNet50 with ImageNet weights</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>base_model <span class="op">=</span> ResNet50(</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    include_top<span class="op">=</span><span class="va">False</span>,  <span class="co"># Exclude classification head</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    weights<span class="op">=</span><span class="st">'imagenet'</span>,  <span class="co"># Use pre-trained weights</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    input_shape<span class="op">=</span>(<span class="dv">64</span>, <span class="dv">64</span>, <span class="dv">3</span>),</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    pooling<span class="op">=</span><span class="st">'avg'</span>  <span class="co"># Global average pooling</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Fine-tuning Strategy</strong></p>
<p><strong>Option 1: Freeze All Layers (Feature Extraction)</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Freeze all base model layers</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>base_model.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Add custom classification head</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential([</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>    base_model,</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    Dropout(<span class="fl">0.5</span>),</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">'softmax'</span>)</span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>])</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><em>Fast training, use when data is very limited</em></p>
<p><strong>Option 2: Freeze Early, Train Late (Partial Fine-tuning)</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Freeze first 80% of layers</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> layer <span class="kw">in</span> base_model.layers[:<span class="bu">int</span>(<span class="fl">0.8</span> <span class="op">*</span> <span class="bu">len</span>(base_model.layers))]:</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    layer.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Fine-tune top layers + custom head</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><em>Balanced approach, best for moderate data</em></p>
<p><strong>Option 3: Full Fine-tuning</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># All layers trainable</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>base_model.trainable <span class="op">=</span> <span class="va">True</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Use lower learning rate (0.0001 instead of 0.001)</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> Adam(learning_rate<span class="op">=</span><span class="fl">1e-4</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><em>Slowest, use when data is abundant</em></p>
<p><strong>Compare Results:</strong></p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Approach</th>
<th>Train Time</th>
<th>Test Accuracy</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>From Scratch</td>
<td>25 min</td>
<td>93.2%</td>
<td>Baseline</td>
</tr>
<tr class="even">
<td>Feature Extraction</td>
<td>8 min</td>
<td>94.1%</td>
<td>Fast, good boost</td>
</tr>
<tr class="odd">
<td>Partial Fine-tuning</td>
<td>15 min</td>
<td>95.3%</td>
<td>Best balance</td>
</tr>
<tr class="even">
<td>Full Fine-tuning</td>
<td>30 min</td>
<td>95.8%</td>
<td>Marginal gain</td>
</tr>
</tbody>
</table>
<hr>
</section>
<section id="part-f-philippine-eo-applications-10-minutes" class="level3">
<h3 class="anchored" data-anchor-id="part-f-philippine-eo-applications-10-minutes">Part F: Philippine EO Applications (10 minutes)</h3>
<p><strong>Adapting CNNs for Philippine Contexts</strong></p>
<div class="feature-grid">
<div class="feature-card">
<p><strong>Multi-spectral Considerations</strong></p>
<p><strong>Challenge:</strong> Sentinel-2 has 13 bands, ResNet expects 3</p>
<p><strong>Solutions:</strong> 1. <strong>Band selection:</strong> Use only RGB (B4, B3, B2) 2. <strong>Band combinations:</strong> NIR-Red-Green false color 3. <strong>PCA:</strong> Reduce 13→3 dimensions 4. <strong>Architecture modification:</strong> Change input layer to accept 13 channels</p>
<p><strong>Recommendation for Palawan:</strong> - Start with RGB for transfer learning - Train custom CNN with all bands for production</p>
</div>
<div class="feature-card">
<p><strong>Scaling to Operational Use</strong></p>
<p><strong>PhilSA Production Pipeline:</strong> 1. <strong>Training:</strong> Palawan pilot (this session) 2. <strong>Validation:</strong> Other provinces 3. <strong>Deployment:</strong> Nationwide monitoring 4. <strong>Updates:</strong> Retrain quarterly</p>
<p><strong>Computational Needs:</strong> - Training: Cloud GPU (Colab, AWS, Azure) - Inference: Can run on CPU for deployment - Storage: Model weights ~50-200 MB</p>
</div>
<div class="feature-card">
<p><strong>CNN for Disaster Response</strong></p>
<p><strong>Typhoon Damage Assessment:</strong> - <strong>Input:</strong> Pre/post imagery pairs - <strong>Task:</strong> Binary (damaged/not damaged) - <strong>Architecture:</strong> Siamese network or stacked CNN - <strong>Speed:</strong> Process 1000 km² in hours</p>
<p><strong>Flood Extent Mapping:</strong> - <strong>Advance to Day 3:</strong> U-Net for pixel-level segmentation - <strong>Real-time:</strong> CNN classification during event - <strong>Integration:</strong> Feed into NOAH or Project DOST systems</p>
</div>
<div class="feature-card">
<p><strong>Accuracy Requirements</strong></p>
<p><strong>Application-Specific Needs:</strong> - <strong>Land cover monitoring:</strong> 85-90% sufficient - <strong>Forest law enforcement:</strong> 95%+ required - <strong>Disaster response:</strong> Speed &gt; perfect accuracy - <strong>REDD+ MRV:</strong> High precision needed</p>
<p><strong>Session 4 Achievement:</strong> 93-96% on EuroSAT</p>
</div>
</div>
<hr>
</section>
</section>
<section id="hands-on-notebook" class="level2">
<h2 class="anchored" data-anchor-id="hands-on-notebook">Hands-On Notebook</h2>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>📓 Interactive Jupyter Notebook
</div>
</div>
<div class="callout-body-container callout-body">
<p>The complete hands-on lab is available as an executable Jupyter notebook:</p>
<p><strong>Student Version</strong> (with exercises and TODOs):<br>
<a href="../../day2/notebooks/session4_cnn_classification_STUDENT.html"><code>session4_cnn_classification_STUDENT.ipynb</code></a></p>
<p><strong>Google Colab Direct Link:</strong><br>
<a href="https://colab.research.google.com/github/DimitrisKasabalis/EO_trainning/blob/main/course_site/day2/notebooks/session4_cnn_classification_STUDENT.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" class="img-fluid" alt="Open In Colab"></a></p>
<p><strong>What’s Included:</strong> - Complete environment setup (TensorFlow, GPU config) - EuroSAT download and preparation scripts - CNN architecture implementation (from-scratch and transfer learning) - Training loops with callbacks - Comprehensive evaluation code - Visualization functions - Interactive exercises</p>
<p><strong>Estimated Execution Time:</strong> - Setup: 5 minutes - Data download: 3-5 minutes (90 MB) - Training from scratch: 15-20 minutes (GPU) - Transfer learning: 5-10 minutes (GPU) - Evaluation: 5 minutes - <strong>Total:</strong> ~30-40 minutes with GPU</p>
</div>
</div>
<hr>
</section>
<section id="expected-outcomes" class="level2">
<h2 class="anchored" data-anchor-id="expected-outcomes">Expected Outcomes</h2>
<p>By the end of this session, you will have:</p>
<p>✅ <strong>Completed Projects:</strong> - Working EuroSAT CNN classifier (93-96% accuracy) - Transfer learning model with ResNet50 (94-97% accuracy) - Comprehensive evaluation report with confusion matrix - Trained model weights saved for deployment</p>
<p>✅ <strong>Technical Skills:</strong> - TensorFlow/Keras proficiency for CNNs - Data pipeline creation with tf.data - Training with advanced callbacks - Model evaluation and debugging - Transfer learning implementation</p>
<p>✅ <strong>Practical Deliverables:</strong> - Executable Jupyter notebook (student version completed) - Trained models (<code>.h5</code> or SavedModel format) - Learning curve plots - Confusion matrix visualizations - Classification report (precision, recall, F1)</p>
<p>✅ <strong>Understanding:</strong> - When CNNs outperform traditional ML - How to choose architecture for EO tasks - Transfer learning for small datasets - Hyperparameter tuning strategies - Deployment considerations</p>
<hr>
</section>
<section id="troubleshooting-guide" class="level2">
<h2 class="anchored" data-anchor-id="troubleshooting-guide">Troubleshooting Guide</h2>
<section id="common-issues-solutions" class="level3">
<h3 class="anchored" data-anchor-id="common-issues-solutions">Common Issues &amp; Solutions</h3>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>GPU Not Detected
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Symptoms:</strong></p>
<pre><code>Physical devices: []
WARNING: No GPU available, using CPU</code></pre>
<p><strong>Solutions:</strong> 1. <strong>Colab:</strong> Runtime → Change runtime type → Hardware accelerator → GPU 2. <strong>Verify:</strong> Run <code>tf.config.list_physical_devices('GPU')</code> 3. <strong>Restart runtime:</strong> Runtime → Restart runtime 4. <strong>Check quota:</strong> Colab has usage limits (reconnect after 12 hours) 5. <strong>Alternative:</strong> Use Kaggle Notebooks (30 hrs/week GPU free)</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Out of Memory Error
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Symptoms:</strong></p>
<pre><code>ResourceExhaustedError: OOM when allocating tensor</code></pre>
<p><strong>Solutions:</strong> 1. <strong>Reduce batch size:</strong> 32 → 16 → 8 2. <strong>Smaller model:</strong> Fewer filters (128→64), fewer layers 3. <strong>Mixed precision:</strong> <code>tf.keras.mixed_precision.set_global_policy('mixed_float16')</code> 4. <strong>Clear memory:</strong> <code>tf.keras.backend.clear_session()</code> 5. <strong>Restart runtime:</strong> Fresh start clears memory</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Training Not Improving
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Symptoms:</strong> - Accuracy stuck at ~10% (random guessing) - Loss = NaN or infinity - Very slow convergence</p>
<p><strong>Solutions:</strong> 1. <strong>Learning rate too high:</strong> Reduce to 0.0001 2. <strong>Check data normalization:</strong> Images should be 0-1 or standardized 3. <strong>Verify labels:</strong> One-hot encoded correctly (shape: [batch, 10]) 4. <strong>Gradient clipping:</strong> <code>optimizer = Adam(clipnorm=1.0)</code> 5. <strong>Simpler model:</strong> Start with 2 conv blocks instead of 3 6. <strong>Check for bugs:</strong> Print shapes, verify data loading</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Overfitting Severely
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Symptoms:</strong> - Train accuracy: 99%, Val accuracy: 75% - Validation loss increases while train loss decreases</p>
<p><strong>Solutions:</strong> 1. <strong>More dropout:</strong> Increase from 0.3 to 0.5 2. <strong>Data augmentation:</strong> Add rotation, flip, zoom 3. <strong>L2 regularization:</strong> <code>Conv2D(..., kernel_regularizer=l2(0.001))</code> 4. <strong>Reduce model capacity:</strong> Fewer filters, fewer layers 5. <strong>Early stopping:</strong> Patience=3-5 epochs 6. <strong>More training data:</strong> Use full EuroSAT (27K images)</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Dataset Download Fails
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Symptoms:</strong></p>
<pre><code>HTTPError: 404 Not Found
Connection timeout</code></pre>
<p><strong>Solutions:</strong> 1. <strong>Use mirror site:</strong> TensorFlow Datasets, Kaggle 2. <strong>Manual download:</strong> Provide local copy 3. <strong>Check internet:</strong> Colab connectivity issues 4. <strong>Retry:</strong> <code>wget</code> with retries 5. <strong>Pre-downloaded:</strong> Load from Google Drive</p>
</div>
</div>
<div class="callout callout-style-default callout-warning callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Warning</span>Augmentation Visualization Error
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Symptoms:</strong></p>
<pre><code>TypeError: only integer scalar arrays can be converted to a scalar index
# OR
IndexError: invalid index to scalar variable</code></pre>
<p><strong>When:</strong> In the “Visualize Augmentation” cell when trying to display augmented images</p>
<p><strong>Root Cause:</strong> The code uses <code>class_names[sample_label.numpy()]</code> but <code>sample_label.numpy()</code> returns a numpy scalar (e.g., <code>numpy.int64(3)</code>) which some Python versions don’t accept as a list index.</p>
<p><strong>Solutions:</strong></p>
<p><strong>Quick Fix (Add one line):</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="co"># After: sample_image, sample_label = next(iter(ds_train))</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Add this line:</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>label_idx <span class="op">=</span> <span class="bu">int</span>(sample_label.numpy())</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Then change plt.suptitle line to use label_idx:</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="ss">f'Data Augmentation Examples</span><span class="ch">\n</span><span class="ss">Class: </span><span class="sc">{</span>class_names[label_idx]<span class="sc">}</span><span class="ss">'</span>,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>             fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Complete Fixed Cell:</strong></p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Show original vs augmented</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>sample_image, sample_label <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(ds_train))</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert label to integer for indexing</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>label_idx <span class="op">=</span> <span class="bu">int</span>(sample_label.numpy())  <span class="co"># &lt;-- ADD THIS LINE</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">7</span>))</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Original</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].imshow(sample_image.numpy())</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'Original'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Augmented versions</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">8</span>):</span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> idx <span class="op">//</span> <span class="dv">4</span></span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a>    col <span class="op">=</span> idx <span class="op">%</span> <span class="dv">4</span></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>    augmented <span class="op">=</span> data_augmentation(tf.expand_dims(sample_image, <span class="dv">0</span>), training<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a>    axes[row, col].imshow(augmented.numpy())</span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a>    axes[row, col].set_title(<span class="ss">f'Augmented </span><span class="sc">{</span>idx<span class="sc">}</span><span class="ss">'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a>    axes[row, col].axis(<span class="st">'off'</span>)</span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Use label_idx instead of sample_label.numpy()</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="ss">f'Data Augmentation Examples</span><span class="ch">\n</span><span class="ss">Class: </span><span class="sc">{</span>class_names[label_idx]<span class="sc">}</span><span class="ss">'</span>,  <span class="co"># &lt;-- CHANGED</span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a>             fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-30"><a href="#cb16-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">✓ Augmentation creates realistic variations"</span>)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<p><strong>Why This Works:</strong> - <code>int()</code> explicitly converts numpy scalar to Python integer - Python lists accept native integers as indices reliably - Prevents type mismatch between numpy and Python types</p>
<p><strong>Note:</strong> A fixed version of the notebook is available: <code>session4_cnn_classification_STUDENT_FIXED.ipynb</code></p>
</div>
</div>
<hr>
</section>
</section>
<section id="key-concepts-recap" class="level2">
<h2 class="anchored" data-anchor-id="key-concepts-recap">Key Concepts Recap</h2>
<section id="convolutional-layers" class="level3">
<h3 class="anchored" data-anchor-id="convolutional-layers">Convolutional Layers</h3>
<p><strong>What they do:</strong> - Apply learnable filters to extract features - Preserve spatial relationships - Translation invariant (feature detected anywhere in image)</p>
<p><strong>Parameters:</strong> - <code>filters</code>: Number of feature maps (32, 64, 128, …) - <code>kernel_size</code>: Filter dimensions (3×3, 5×5, …) - <code>strides</code>: Step size (usually 1) - <code>padding</code>: ‘valid’ (shrinks) or ‘same’ (maintains size) - <code>activation</code>: Usually ReLU</p>
</section>
<section id="pooling-layers" class="level3">
<h3 class="anchored" data-anchor-id="pooling-layers">Pooling Layers</h3>
<p><strong>Purpose:</strong> - Reduce spatial dimensions - Add translation invariance - Reduce parameters and computation</p>
<p><strong>MaxPooling vs AveragePooling:</strong> - <strong>MaxPooling:</strong> Keeps strongest activation (most common) - <strong>AveragePooling:</strong> Smooths response - Typically 2×2 with stride 2 (halves dimensions)</p>
</section>
<section id="activation-functions" class="level3">
<h3 class="anchored" data-anchor-id="activation-functions">Activation Functions</h3>
<p><strong>ReLU (Rectified Linear Unit):</strong> - <code>f(x) = max(0, x)</code> - Most common in hidden layers - Addresses vanishing gradient problem - Fast to compute</p>
<p><strong>Softmax:</strong> - Converts logits to probabilities - Sum to 1.0 - Used in output layer for multi-class classification</p>
</section>
<section id="loss-functions" class="level3">
<h3 class="anchored" data-anchor-id="loss-functions">Loss Functions</h3>
<p><strong>Categorical Cross-Entropy:</strong> - For multi-class classification (&gt;2 classes) - Requires one-hot encoded labels - Formula: <code>-Σ y_true * log(y_pred)</code> - Penalizes confident wrong predictions heavily</p>
</section>
<section id="optimizers" class="level3">
<h3 class="anchored" data-anchor-id="optimizers">Optimizers</h3>
<p><strong>Adam (Adaptive Moment Estimation):</strong> - Adaptive learning rate per parameter - Combines momentum + RMSprop - Generally robust, good default choice - Learning rate: 0.001 (default) to 0.0001 (fine-tuning)</p>
<hr>
</section>
</section>
<section id="resources" class="level2">
<h2 class="anchored" data-anchor-id="resources">Resources</h2>
<section id="documentation-tutorials" class="level3">
<h3 class="anchored" data-anchor-id="documentation-tutorials">Documentation &amp; Tutorials</h3>
<ul>
<li><a href="https://www.tensorflow.org/guide/keras">TensorFlow Keras Guide</a></li>
<li><a href="https://cs231n.github.io/">Deep Learning for Computer Vision</a></li>
<li><a href="https://github.com/phelber/EuroSAT">EuroSAT Dataset Paper</a></li>
<li><a href="https://www.tensorflow.org/tutorials/images/transfer_learning">Transfer Learning Guide</a></li>
</ul>
</section>
<section id="pre-trained-models" class="level3">
<h3 class="anchored" data-anchor-id="pre-trained-models">Pre-trained Models</h3>
<ul>
<li><a href="https://keras.io/api/applications/">Keras Applications</a></li>
<li><a href="https://tfhub.dev/">TensorFlow Hub</a></li>
<li><a href="https://modelzoo.co/">Model Zoo</a></li>
</ul>
</section>
<section id="philippine-eo-resources" class="level3">
<h3 class="anchored" data-anchor-id="philippine-eo-resources">Philippine EO Resources</h3>
<ul>
<li><a href="https://data.philsa.gov.ph/">PhilSA Space+ Data</a></li>
<li><a href="https://panda.stamina4space.upd.edu.ph/">DOST-ASTI Panda</a></li>
<li><a href="https://www.namria.gov.ph/geoportal.html">NAMRIA Geoportal</a></li>
</ul>
</section>
<section id="course-materials" class="level3">
<h3 class="anchored" data-anchor-id="course-materials">Course Materials</h3>
<div class="quick-links">
<p><a href="../../day2/sessions/session3.html" class="quick-link">← Back to Session 3</a> <a href="../../day2/index.html" class="quick-link">Day 2 Overview</a> <a href="../../day2/notebooks/session4_cnn_classification_STUDENT.html" class="quick-link">Lab Notebook</a> <a href="../../resources/setup.html" class="quick-link">Setup Guide</a> <a href="../../resources/faq.html" class="quick-link">FAQ</a></p>
</div>
<hr>
</section>
</section>
<section id="next-steps" class="level2">
<h2 class="anchored" data-anchor-id="next-steps">Next Steps</h2>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Note</span>What Comes After Session 4?
</div>
</div>
<div class="callout-body-container callout-body">
<p><strong>Immediate:</strong> - Complete all exercises in the notebook - Experiment with different architectures - Try your own hyperparameter combinations - Apply to Philippine imagery (optional challenge)</p>
<p><strong>Day 3 Preview:</strong> - <strong>U-Net for Semantic Segmentation:</strong> Pixel-level land cover classification - <strong>Flood Mapping Case Study:</strong> Central Luzon with Sentinel-1 SAR - <strong>Object Detection:</strong> Metro Manila building/settlement detection - <strong>Advanced Architectures:</strong> Deeper networks, attention mechanisms</p>
<p><strong>Preparation for Day 3:</strong> - Ensure you understand CNN fundamentals - Be comfortable with TensorFlow/Keras syntax - Know how to debug training issues - Understand when to use different architectures</p>
<p><a href="../../day3/index.html" class="btn btn-outline-primary">Preview Day 3 →</a></p>
</div>
</div>
<hr>
</section>
<section id="assessment-exercises" class="level2">
<h2 class="anchored" data-anchor-id="assessment-exercises">Assessment &amp; Exercises</h2>
<section id="formative-assessment-in-notebook" class="level3">
<h3 class="anchored" data-anchor-id="formative-assessment-in-notebook">Formative Assessment (In-Notebook)</h3>
<ul class="task-list">
<li><label><input type="checkbox">Successfully configure GPU environment</label></li>
<li><label><input type="checkbox">Load and visualize EuroSAT dataset</label></li>
<li><label><input type="checkbox">Build CNN architecture from scratch</label></li>
<li><label><input type="checkbox">Train model to &gt;90% accuracy</label></li>
<li><label><input type="checkbox">Generate confusion matrix</label></li>
<li><label><input type="checkbox">Implement transfer learning with ResNet50</label></li>
<li><label><input type="checkbox">Compare results from-scratch vs transfer learning</label></li>
</ul>
</section>
<section id="challenge-exercises" class="level3">
<h3 class="anchored" data-anchor-id="challenge-exercises">Challenge Exercises</h3>
<p><strong>Exercise 1: Architecture Design</strong> - Modify the CNN to have 4 convolutional blocks instead of 3 - Add batch normalization after each convolution - Compare training speed and final accuracy</p>
<p><strong>Exercise 2: Hyperparameter Tuning</strong> - Test learning rates: [0.001, 0.0001, 0.00001] - Test batch sizes: [16, 32, 64] - Find optimal combination for fastest convergence</p>
<p><strong>Exercise 3: Advanced Augmentation</strong> - Add RandomBrightness and RandomContrast - Implement mixup augmentation - Measure impact on validation accuracy</p>
<p><strong>Exercise 4: Multi-spectral CNN</strong> (Advanced) - Load EuroSAT 13-band version - Modify input layer to accept all bands - Compare RGB vs multi-spectral performance</p>
<p><strong>Exercise 5: Philippine Application</strong> (Capstone) - Apply trained model to Palawan Sentinel-2 patches - Compare predictions with Session 2 Random Forest - Identify areas where CNN performs better/worse</p>
<hr>
<div class="callout callout-style-default callout-tip callout-titled">
<div class="callout-header d-flex align-content-center collapsed" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Tip</span>💡 Instructor Notes
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Timing Management:</strong> - <strong>Part A (Setup &amp; Data):</strong> Can take 35-40 min if students unfamiliar with Colab GPU setup - <strong>Part B (Build CNN):</strong> Usually 40-45 min, architecture design is tricky for beginners - <strong>Part C (Training):</strong> 30-40 min including watching training live - <strong>Part D (Evaluation):</strong> 25-30 min, confusion matrix analysis takes time - <strong>Part E (Transfer Learning):</strong> 15-20 min, can be shortened if running behind - <strong>Part F (Philippine Context):</strong> 10-15 min discussion</p>
<p><strong>Common Student Questions:</strong> - “Why is my GPU not detected?” → Check runtime type, may need reconnect - “Training is very slow on CPU” → Emphasize GPU requirement, show how to enable - “What batch size should I use?” → Start with 32, reduce if OOM errors - “Why transfer learning?” → Explain data efficiency, show time savings - “Can I use PyTorch instead?” → Yes, but maintain focus; TensorFlow for consistency</p>
<p><strong>Teaching Tips:</strong> - <strong>Live demo:</strong> Train a model while explaining (use simple architecture for speed) - <strong>Show failures:</strong> Demonstrate overfitting, then fix it - <strong>Visualize:</strong> Use TensorBoard or matplotlib for learning curves in real-time - <strong>Pause for training:</strong> Use 5-10 min training time for Q&amp;A or breaks - <strong>Compare with RF:</strong> Reinforce why we learned both approaches</p>
<p><strong>Technical Preparation:</strong> - Pre-download EuroSAT to Google Drive as backup - Test notebook 24 hours before session - Have pre-trained models ready in case training fails - Prepare troubleshooting guide printout - Test on both GPU and CPU for comparison</p>
<p><strong>Extension Activities for Fast Finishers:</strong> - Implement ensemble of multiple CNNs - Try different pre-trained models (EfficientNet, MobileNet) - Explore GradCAM for visualization - Start Day 3 preview material</p>
</div>
</div>
</div>
<hr>
<p><em>This session is part of the CoPhil 4-Day Advanced Training on AI/ML for Earth Observation, funded by the European Union under the Global Gateway initiative and delivered in partnership with PhilSA and DOST.</em></p>


<!-- -->

</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    // Ensure there is a toggle, if there isn't float one in the top right
    if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
      const a = window.document.createElement('a');
      a.classList.add('top-right');
      a.classList.add('quarto-color-scheme-toggle');
      a.href = "";
      a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
      const i = window.document.createElement("i");
      i.classList.add('bi');
      a.appendChild(i);
      window.document.body.appendChild(a);
    }
    setColorSchemeToggle(hasAlternateSentinel())
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
      const outerScaffold = trigger.parentElement.cloneNode(true);
      const codeEl = outerScaffold.querySelector('code');
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp("https:\/\/DimitrisKasabalis\.github\.io\/cophil-training-v1\.0");
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<script src="https://utteranc.es/client.js" repo="cophil-training-v1.0" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../../day2/sessions/session3.html" class="pagination-link" aria-label="Session 3: Introduction to Deep Learning and CNNs">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Session 3: Introduction to Deep Learning and CNNs</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../../day2/notebooks/session1_theory_notebook_STUDENT.html" class="pagination-link" aria-label="Session 1 Theory: Understanding Random Forest for Earth Observation">
        <span class="nav-page-text">Session 1 Theory: Understanding Random Forest for Earth Observation</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb17" data-shortcodes="false"><pre class="sourceCode markdown code-with-copy"><code class="sourceCode markdown"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="an">title:</span><span class="co"> "Session 4: CNN Hands-on Lab"</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span class="an">subtitle:</span><span class="co"> "Building and Training CNNs for EO Image Classification"</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a><span class="an">date:</span><span class="co"> last-modified</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a><span class="an">author:</span><span class="co"> "CoPhil Advanced Training Program"</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="an">format:</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co">  html:</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co">    toc: true</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co">    toc-depth: 3</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co">    code-fold: false</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co">---</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">nav</span><span class="ot"> class</span><span class="op">=</span><span class="st">"breadcrumb"</span><span class="ot"> aria-label</span><span class="op">=</span><span class="st">"Breadcrumb"</span><span class="dt">&gt;</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>  <span class="dt">&lt;</span><span class="kw">a</span><span class="ot"> href</span><span class="op">=</span><span class="st">"../../index.html"</span><span class="dt">&gt;</span>Home<span class="dt">&lt;/</span><span class="kw">a</span><span class="dt">&gt;</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>  <span class="dt">&lt;</span><span class="kw">span</span><span class="ot"> class</span><span class="op">=</span><span class="st">"breadcrumb-separator"</span><span class="ot"> aria-hidden</span><span class="op">=</span><span class="st">"true"</span><span class="dt">&gt;</span>›<span class="dt">&lt;/</span><span class="kw">span</span><span class="dt">&gt;</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>  <span class="dt">&lt;</span><span class="kw">a</span><span class="ot"> href</span><span class="op">=</span><span class="st">"../index.html"</span><span class="dt">&gt;</span>Day 2<span class="dt">&lt;/</span><span class="kw">a</span><span class="dt">&gt;</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>  <span class="dt">&lt;</span><span class="kw">span</span><span class="ot"> class</span><span class="op">=</span><span class="st">"breadcrumb-separator"</span><span class="ot"> aria-hidden</span><span class="op">=</span><span class="st">"true"</span><span class="dt">&gt;</span>›<span class="dt">&lt;/</span><span class="kw">span</span><span class="dt">&gt;</span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>  <span class="dt">&lt;</span><span class="kw">span</span><span class="ot"> class</span><span class="op">=</span><span class="st">"breadcrumb-current"</span><span class="dt">&gt;</span>Session 4<span class="dt">&lt;/</span><span class="kw">span</span><span class="dt">&gt;</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;/</span><span class="kw">nav</span><span class="dt">&gt;</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>::: {.hero}</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a><span class="fu"># Session 4: CNN Hands-on Lab</span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a><span class="fu">### Building and Training CNNs for EO Image Classification</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>From theory to implementation with TensorFlow and PyTorch</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-28"><a href="#cb17-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-29"><a href="#cb17-29" aria-hidden="true" tabindex="-1"></a><span class="fu">## Session Overview</span></span>
<span id="cb17-30"><a href="#cb17-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-31"><a href="#cb17-31" aria-hidden="true" tabindex="-1"></a>**Duration:** 2.5 hours | **Type:** Intensive Hands-On Lab | **Difficulty:** Intermediate-Advanced</span>
<span id="cb17-32"><a href="#cb17-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-33"><a href="#cb17-33" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-34"><a href="#cb17-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-35"><a href="#cb17-35" aria-hidden="true" tabindex="-1"></a>This session transforms CNN theory from Session 3 into working code. You'll build, train, and evaluate real deep learning models for Earth Observation, achieving significantly higher accuracy than the Random Forest models from Sessions 1-2.</span>
<span id="cb17-36"><a href="#cb17-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-37"><a href="#cb17-37" aria-hidden="true" tabindex="-1"></a><span class="fu">## Presentation Slides</span></span>
<span id="cb17-38"><a href="#cb17-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-39"><a href="#cb17-39" aria-hidden="true" tabindex="-1"></a><span class="dt">&lt;</span><span class="kw">iframe</span><span class="ot"> src</span><span class="op">=</span><span class="st">"../presentations/session4_cnn_lab.html"</span><span class="ot"> width</span><span class="op">=</span><span class="st">"100%"</span><span class="ot"> height</span><span class="op">=</span><span class="st">"600"</span><span class="ot"> style</span><span class="op">=</span><span class="st">"border: 1px solid #ccc; border-radius: 4px;"</span><span class="dt">&gt;&lt;/</span><span class="kw">iframe</span><span class="dt">&gt;</span></span>
<span id="cb17-40"><a href="#cb17-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-41"><a href="#cb17-41" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-42"><a href="#cb17-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-43"><a href="#cb17-43" aria-hidden="true" tabindex="-1"></a>::: {.callout-important}</span>
<span id="cb17-44"><a href="#cb17-44" aria-hidden="true" tabindex="-1"></a><span class="fu">## Prerequisites</span></span>
<span id="cb17-45"><a href="#cb17-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-46"><a href="#cb17-46" aria-hidden="true" tabindex="-1"></a>**Technical Requirements:**</span>
<span id="cb17-47"><a href="#cb17-47" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Complete Session 3 (CNN theory and concepts)</span>
<span id="cb17-48"><a href="#cb17-48" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Understand convolution, pooling, activation functions</span>
<span id="cb17-49"><a href="#cb17-49" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Python programming proficiency (NumPy, pandas basics)</span>
<span id="cb17-50"><a href="#cb17-50" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Google Colab account with GPU access</span>
<span id="cb17-51"><a href="#cb17-51" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Stable internet connection (for dataset downloads)</span>
<span id="cb17-52"><a href="#cb17-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-53"><a href="#cb17-53" aria-hidden="true" tabindex="-1"></a>**Conceptual Understanding:**</span>
<span id="cb17-54"><a href="#cb17-54" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Know difference between traditional ML and deep learning</span>
<span id="cb17-55"><a href="#cb17-55" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Understand supervised learning workflow</span>
<span id="cb17-56"><a href="#cb17-56" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Familiar with classification metrics (accuracy, confusion matrix)</span>
<span id="cb17-57"><a href="#cb17-57" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>✓ Basic understanding of gradient descent optimization</span>
<span id="cb17-58"><a href="#cb17-58" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-59"><a href="#cb17-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-60"><a href="#cb17-60" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-61"><a href="#cb17-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-62"><a href="#cb17-62" aria-hidden="true" tabindex="-1"></a><span class="fu">## What You'll Accomplish</span></span>
<span id="cb17-63"><a href="#cb17-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-64"><a href="#cb17-64" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb17-65"><a href="#cb17-65" aria-hidden="true" tabindex="-1"></a><span class="fu">## Learning Outcomes</span></span>
<span id="cb17-66"><a href="#cb17-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-67"><a href="#cb17-67" aria-hidden="true" tabindex="-1"></a>After completing this session, you will be able to:</span>
<span id="cb17-68"><a href="#cb17-68" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-69"><a href="#cb17-69" aria-hidden="true" tabindex="-1"></a><span class="fu">### 1. Implement CNNs in TensorFlow/Keras</span></span>
<span id="cb17-70"><a href="#cb17-70" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Set up GPU-accelerated deep learning environment</span>
<span id="cb17-71"><a href="#cb17-71" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Load and preprocess Earth observation datasets</span>
<span id="cb17-72"><a href="#cb17-72" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Build CNN architectures layer-by-layer from scratch</span>
<span id="cb17-73"><a href="#cb17-73" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Compile models with appropriate loss functions and optimizers</span>
<span id="cb17-74"><a href="#cb17-74" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Train models with advanced callbacks (early stopping, checkpointing)</span>
<span id="cb17-75"><a href="#cb17-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-76"><a href="#cb17-76" aria-hidden="true" tabindex="-1"></a><span class="fu">### 2. Work with EuroSAT Benchmark Dataset</span></span>
<span id="cb17-77"><a href="#cb17-77" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Download and prepare standardized EO dataset</span>
<span id="cb17-78"><a href="#cb17-78" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Understand 10-class land use classification task</span>
<span id="cb17-79"><a href="#cb17-79" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Create efficient data pipelines with tf.data.Dataset</span>
<span id="cb17-80"><a href="#cb17-80" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Apply data augmentation strategies for satellite imagery</span>
<span id="cb17-81"><a href="#cb17-81" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Handle train/validation/test splits properly</span>
<span id="cb17-82"><a href="#cb17-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-83"><a href="#cb17-83" aria-hidden="true" tabindex="-1"></a><span class="fu">### 3. Evaluate Deep Learning Models</span></span>
<span id="cb17-84"><a href="#cb17-84" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Generate and interpret confusion matrices</span>
<span id="cb17-85"><a href="#cb17-85" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Calculate per-class precision, recall, and F1-scores</span>
<span id="cb17-86"><a href="#cb17-86" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Visualize training and validation curves</span>
<span id="cb17-87"><a href="#cb17-87" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Analyze misclassifications and model errors</span>
<span id="cb17-88"><a href="#cb17-88" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Compare CNN performance with Random Forest baseline</span>
<span id="cb17-89"><a href="#cb17-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-90"><a href="#cb17-90" aria-hidden="true" tabindex="-1"></a><span class="fu">### 4. Apply Transfer Learning</span></span>
<span id="cb17-91"><a href="#cb17-91" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Load pre-trained models (ResNet50, VGG16, EfficientNet)</span>
<span id="cb17-92"><a href="#cb17-92" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Understand when and why to use pre-trained weights</span>
<span id="cb17-93"><a href="#cb17-93" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Freeze and fine-tune network layers strategically</span>
<span id="cb17-94"><a href="#cb17-94" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Adapt ImageNet models for Earth observation tasks</span>
<span id="cb17-95"><a href="#cb17-95" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Compare from-scratch vs. transfer learning performance</span>
<span id="cb17-96"><a href="#cb17-96" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-97"><a href="#cb17-97" aria-hidden="true" tabindex="-1"></a><span class="fu">### 5. Optimize and Debug Models</span></span>
<span id="cb17-98"><a href="#cb17-98" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Prevent overfitting with dropout and regularization</span>
<span id="cb17-99"><a href="#cb17-99" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Tune hyperparameters (learning rate, batch size, architecture)</span>
<span id="cb17-100"><a href="#cb17-100" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Diagnose training issues (vanishing gradients, exploding loss)</span>
<span id="cb17-101"><a href="#cb17-101" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Use callbacks for adaptive learning</span>
<span id="cb17-102"><a href="#cb17-102" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Implement best practices for reproducibility</span>
<span id="cb17-103"><a href="#cb17-103" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-104"><a href="#cb17-104" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-105"><a href="#cb17-105" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-106"><a href="#cb17-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-107"><a href="#cb17-107" aria-hidden="true" tabindex="-1"></a><span class="fu">## Why This Matters for Philippine EO</span></span>
<span id="cb17-108"><a href="#cb17-108" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-109"><a href="#cb17-109" aria-hidden="true" tabindex="-1"></a>::: {.feature-grid}</span>
<span id="cb17-110"><a href="#cb17-110" aria-hidden="true" tabindex="-1"></a>::: {.feature-card}</span>
<span id="cb17-111"><a href="#cb17-111" aria-hidden="true" tabindex="-1"></a>**🎯 Accuracy Improvement**</span>
<span id="cb17-112"><a href="#cb17-112" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-113"><a href="#cb17-113" aria-hidden="true" tabindex="-1"></a>CNNs consistently outperform Random Forest:</span>
<span id="cb17-114"><a href="#cb17-114" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**EuroSAT:** 92-98% vs 87-90%</span>
<span id="cb17-115"><a href="#cb17-115" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Palawan:** Estimated +5-10% accuracy</span>
<span id="cb17-116"><a href="#cb17-116" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Critical for:** DRR applications where errors cost lives</span>
<span id="cb17-117"><a href="#cb17-117" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-118"><a href="#cb17-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-119"><a href="#cb17-119" aria-hidden="true" tabindex="-1"></a>::: {.feature-card}</span>
<span id="cb17-120"><a href="#cb17-120" aria-hidden="true" tabindex="-1"></a>**🌍 Spatial Context**</span>
<span id="cb17-121"><a href="#cb17-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-122"><a href="#cb17-122" aria-hidden="true" tabindex="-1"></a>CNNs understand image context:</span>
<span id="cb17-123"><a href="#cb17-123" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**RF:** Treats pixels independently</span>
<span id="cb17-124"><a href="#cb17-124" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**CNN:** Captures spatial patterns</span>
<span id="cb17-125"><a href="#cb17-125" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Benefit:** Better forest boundary detection, fewer misclassifications</span>
<span id="cb17-126"><a href="#cb17-126" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-127"><a href="#cb17-127" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-128"><a href="#cb17-128" aria-hidden="true" tabindex="-1"></a>::: {.feature-card}</span>
<span id="cb17-129"><a href="#cb17-129" aria-hidden="true" tabindex="-1"></a>**⚡ Scalability**</span>
<span id="cb17-130"><a href="#cb17-130" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-131"><a href="#cb17-131" aria-hidden="true" tabindex="-1"></a>Once trained, CNNs scale efficiently:</span>
<span id="cb17-132"><a href="#cb17-132" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Deployment:** Fast inference on new imagery</span>
<span id="cb17-133"><a href="#cb17-133" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Automation:** Process entire Philippines nightly</span>
<span id="cb17-134"><a href="#cb17-134" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Operations:** PhilSA operational monitoring</span>
<span id="cb17-135"><a href="#cb17-135" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-136"><a href="#cb17-136" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-137"><a href="#cb17-137" aria-hidden="true" tabindex="-1"></a>::: {.feature-card}</span>
<span id="cb17-138"><a href="#cb17-138" aria-hidden="true" tabindex="-1"></a>**🔄 Transfer Learning**</span>
<span id="cb17-139"><a href="#cb17-139" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-140"><a href="#cb17-140" aria-hidden="true" tabindex="-1"></a>Pre-trained models accelerate development:</span>
<span id="cb17-141"><a href="#cb17-141" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Small Data:** Works with limited labeled samples</span>
<span id="cb17-142"><a href="#cb17-142" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Time Savings:** Days vs weeks of training</span>
<span id="cb17-143"><a href="#cb17-143" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Philippine Context:** Adapt global models locally</span>
<span id="cb17-144"><a href="#cb17-144" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-145"><a href="#cb17-145" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-146"><a href="#cb17-146" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-147"><a href="#cb17-147" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-148"><a href="#cb17-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-149"><a href="#cb17-149" aria-hidden="true" tabindex="-1"></a><span class="fu">## Session Structure</span></span>
<span id="cb17-150"><a href="#cb17-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-151"><a href="#cb17-151" aria-hidden="true" tabindex="-1"></a><span class="fu">### Part A: Environment Setup &amp; Data Preparation (30 minutes)</span></span>
<span id="cb17-152"><a href="#cb17-152" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-153"><a href="#cb17-153" aria-hidden="true" tabindex="-1"></a>**Setup Google Colab Environment**</span>
<span id="cb17-154"><a href="#cb17-154" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Configure GPU runtime for acceleration</span>
<span id="cb17-155"><a href="#cb17-155" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Install required libraries (TensorFlow, Keras, auxiliary packages)</span>
<span id="cb17-156"><a href="#cb17-156" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Verify GPU detection and availability</span>
<span id="cb17-157"><a href="#cb17-157" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Set random seeds for reproducibility</span>
<span id="cb17-158"><a href="#cb17-158" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-159"><a href="#cb17-159" aria-hidden="true" tabindex="-1"></a>**Download EuroSAT Dataset**</span>
<span id="cb17-160"><a href="#cb17-160" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Understand the benchmark dataset (27,000 Sentinel-2 patches)</span>
<span id="cb17-161"><a href="#cb17-161" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Automated download and extraction</span>
<span id="cb17-162"><a href="#cb17-162" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Verify data integrity with checksums</span>
<span id="cb17-163"><a href="#cb17-163" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Explore directory structure and file formats</span>
<span id="cb17-164"><a href="#cb17-164" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-165"><a href="#cb17-165" aria-hidden="true" tabindex="-1"></a>**Data Loading and Exploration**</span>
<span id="cb17-166"><a href="#cb17-166" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Load images and labels efficiently</span>
<span id="cb17-167"><a href="#cb17-167" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Visualize sample images from each class</span>
<span id="cb17-168"><a href="#cb17-168" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Analyze class distribution and balance</span>
<span id="cb17-169"><a href="#cb17-169" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Calculate dataset statistics (mean, std)</span>
<span id="cb17-170"><a href="#cb17-170" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-171"><a href="#cb17-171" aria-hidden="true" tabindex="-1"></a>**Create Data Pipeline**</span>
<span id="cb17-172"><a href="#cb17-172" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Split data (70% train, 15% validation, 15% test)</span>
<span id="cb17-173"><a href="#cb17-173" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Build tf.data.Dataset for efficient loading</span>
<span id="cb17-174"><a href="#cb17-174" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Apply normalization and preprocessing</span>
<span id="cb17-175"><a href="#cb17-175" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Implement data augmentation for training set</span>
<span id="cb17-176"><a href="#cb17-176" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Configure batching, shuffling, and prefetching</span>
<span id="cb17-177"><a href="#cb17-177" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-178"><a href="#cb17-178" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-179"><a href="#cb17-179" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-180"><a href="#cb17-180" aria-hidden="true" tabindex="-1"></a><span class="fu">### Part B: Building CNN from Scratch (40 minutes)</span></span>
<span id="cb17-181"><a href="#cb17-181" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-182"><a href="#cb17-182" aria-hidden="true" tabindex="-1"></a>**Design CNN Architecture**</span>
<span id="cb17-183"><a href="#cb17-183" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Start with simple 3-block architecture</span>
<span id="cb17-184"><a href="#cb17-184" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Understand layer choices and progression</span>
<span id="cb17-185"><a href="#cb17-185" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Calculate output dimensions at each layer</span>
<span id="cb17-186"><a href="#cb17-186" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Visualize network architecture diagram</span>
<span id="cb17-187"><a href="#cb17-187" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-188"><a href="#cb17-188" aria-hidden="true" tabindex="-1"></a>**Implementation Details:**</span>
<span id="cb17-189"><a href="#cb17-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-190"><a href="#cb17-190" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb17-191"><a href="#cb17-191" aria-hidden="true" tabindex="-1"></a><span class="co"># Example architecture (you'll implement in notebook)</span></span>
<span id="cb17-192"><a href="#cb17-192" aria-hidden="true" tabindex="-1"></a>Model: <span class="st">"eurosat_cnn"</span></span>
<span id="cb17-193"><a href="#cb17-193" aria-hidden="true" tabindex="-1"></a>_________________________________________________________________</span>
<span id="cb17-194"><a href="#cb17-194" aria-hidden="true" tabindex="-1"></a>Layer (<span class="bu">type</span>)                Output Shape              Param <span class="co">#   </span></span>
<span id="cb17-195"><a href="#cb17-195" aria-hidden="true" tabindex="-1"></a><span class="op">=================================================================</span></span>
<span id="cb17-196"><a href="#cb17-196" aria-hidden="true" tabindex="-1"></a>conv2d_1 (Conv2D)          (<span class="va">None</span>, <span class="dv">62</span>, <span class="dv">62</span>, <span class="dv">32</span>)        <span class="dv">896</span>       </span>
<span id="cb17-197"><a href="#cb17-197" aria-hidden="true" tabindex="-1"></a>activation_1 (ReLU)        (<span class="va">None</span>, <span class="dv">62</span>, <span class="dv">62</span>, <span class="dv">32</span>)        <span class="dv">0</span>         </span>
<span id="cb17-198"><a href="#cb17-198" aria-hidden="true" tabindex="-1"></a>max_pooling2d_1            (<span class="va">None</span>, <span class="dv">31</span>, <span class="dv">31</span>, <span class="dv">32</span>)        <span class="dv">0</span>         </span>
<span id="cb17-199"><a href="#cb17-199" aria-hidden="true" tabindex="-1"></a>conv2d_2 (Conv2D)          (<span class="va">None</span>, <span class="dv">29</span>, <span class="dv">29</span>, <span class="dv">64</span>)        <span class="dv">18</span>,<span class="dv">496</span>    </span>
<span id="cb17-200"><a href="#cb17-200" aria-hidden="true" tabindex="-1"></a>activation_2 (ReLU)        (<span class="va">None</span>, <span class="dv">29</span>, <span class="dv">29</span>, <span class="dv">64</span>)        <span class="dv">0</span>         </span>
<span id="cb17-201"><a href="#cb17-201" aria-hidden="true" tabindex="-1"></a>max_pooling2d_2            (<span class="va">None</span>, <span class="dv">14</span>, <span class="dv">14</span>, <span class="dv">64</span>)        <span class="dv">0</span>         </span>
<span id="cb17-202"><a href="#cb17-202" aria-hidden="true" tabindex="-1"></a>conv2d_3 (Conv2D)          (<span class="va">None</span>, <span class="dv">12</span>, <span class="dv">12</span>, <span class="dv">128</span>)       <span class="dv">73</span>,<span class="dv">856</span>    </span>
<span id="cb17-203"><a href="#cb17-203" aria-hidden="true" tabindex="-1"></a>activation_3 (ReLU)        (<span class="va">None</span>, <span class="dv">12</span>, <span class="dv">12</span>, <span class="dv">128</span>)       <span class="dv">0</span>         </span>
<span id="cb17-204"><a href="#cb17-204" aria-hidden="true" tabindex="-1"></a>max_pooling2d_3            (<span class="va">None</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">128</span>)         <span class="dv">0</span>         </span>
<span id="cb17-205"><a href="#cb17-205" aria-hidden="true" tabindex="-1"></a>flatten (Flatten)          (<span class="va">None</span>, <span class="dv">4608</span>)              <span class="dv">0</span>         </span>
<span id="cb17-206"><a href="#cb17-206" aria-hidden="true" tabindex="-1"></a>dropout (Dropout)          (<span class="va">None</span>, <span class="dv">4608</span>)              <span class="dv">0</span>         </span>
<span id="cb17-207"><a href="#cb17-207" aria-hidden="true" tabindex="-1"></a>dense_1 (Dense)            (<span class="va">None</span>, <span class="dv">128</span>)               <span class="dv">589</span>,<span class="dv">952</span>   </span>
<span id="cb17-208"><a href="#cb17-208" aria-hidden="true" tabindex="-1"></a>activation_4 (ReLU)        (<span class="va">None</span>, <span class="dv">128</span>)               <span class="dv">0</span>         </span>
<span id="cb17-209"><a href="#cb17-209" aria-hidden="true" tabindex="-1"></a>dropout_2 (Dropout)        (<span class="va">None</span>, <span class="dv">128</span>)               <span class="dv">0</span>         </span>
<span id="cb17-210"><a href="#cb17-210" aria-hidden="true" tabindex="-1"></a>dense_2 (Dense)            (<span class="va">None</span>, <span class="dv">10</span>)                <span class="dv">1</span>,<span class="dv">290</span>     </span>
<span id="cb17-211"><a href="#cb17-211" aria-hidden="true" tabindex="-1"></a>activation_5 (Softmax)     (<span class="va">None</span>, <span class="dv">10</span>)                <span class="dv">0</span>         </span>
<span id="cb17-212"><a href="#cb17-212" aria-hidden="true" tabindex="-1"></a><span class="op">=================================================================</span></span>
<span id="cb17-213"><a href="#cb17-213" aria-hidden="true" tabindex="-1"></a>Total params: <span class="dv">684</span>,<span class="dv">490</span></span>
<span id="cb17-214"><a href="#cb17-214" aria-hidden="true" tabindex="-1"></a>Trainable params: <span class="dv">684</span>,<span class="dv">490</span></span>
<span id="cb17-215"><a href="#cb17-215" aria-hidden="true" tabindex="-1"></a>Non<span class="op">-</span>trainable params: <span class="dv">0</span></span>
<span id="cb17-216"><a href="#cb17-216" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-217"><a href="#cb17-217" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-218"><a href="#cb17-218" aria-hidden="true" tabindex="-1"></a>**Key Architectural Decisions:**</span>
<span id="cb17-219"><a href="#cb17-219" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Filter progression (32→64→128):** Capture features at multiple scales</span>
<span id="cb17-220"><a href="#cb17-220" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**3×3 convolutions:** Standard choice balancing receptive field and parameters</span>
<span id="cb17-221"><a href="#cb17-221" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**MaxPooling:** Spatial dimension reduction and translation invariance</span>
<span id="cb17-222"><a href="#cb17-222" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Dropout (0.3-0.5):** Regularization to prevent overfitting</span>
<span id="cb17-223"><a href="#cb17-223" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Dense layers:** Final classification from learned features</span>
<span id="cb17-224"><a href="#cb17-224" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Softmax output:** Probability distribution over 10 classes</span>
<span id="cb17-225"><a href="#cb17-225" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-226"><a href="#cb17-226" aria-hidden="true" tabindex="-1"></a>**Model Compilation:**</span>
<span id="cb17-227"><a href="#cb17-227" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Loss function:** Categorical cross-entropy (multi-class classification)</span>
<span id="cb17-228"><a href="#cb17-228" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Optimizer:** Adam (adaptive learning rate, generally robust)</span>
<span id="cb17-229"><a href="#cb17-229" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Metrics:** Accuracy, top-3 accuracy</span>
<span id="cb17-230"><a href="#cb17-230" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Learning rate:** Start with 0.001 (default), tune if needed</span>
<span id="cb17-231"><a href="#cb17-231" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-232"><a href="#cb17-232" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-233"><a href="#cb17-233" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-234"><a href="#cb17-234" aria-hidden="true" tabindex="-1"></a><span class="fu">### Part C: U-Net for Semantic Segmentation (60 minutes)</span></span>
<span id="cb17-235"><a href="#cb17-235" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-236"><a href="#cb17-236" aria-hidden="true" tabindex="-1"></a>**Configure Training Callbacks**</span>
<span id="cb17-237"><a href="#cb17-237" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-238"><a href="#cb17-238" aria-hidden="true" tabindex="-1"></a>::: {.feature-grid}</span>
<span id="cb17-239"><a href="#cb17-239" aria-hidden="true" tabindex="-1"></a>::: {.feature-card}</span>
<span id="cb17-240"><a href="#cb17-240" aria-hidden="true" tabindex="-1"></a>**EarlyStopping**</span>
<span id="cb17-241"><a href="#cb17-241" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-242"><a href="#cb17-242" aria-hidden="true" tabindex="-1"></a>Stop training when validation loss stops improving:</span>
<span id="cb17-243"><a href="#cb17-243" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb17-244"><a href="#cb17-244" aria-hidden="true" tabindex="-1"></a>EarlyStopping(</span>
<span id="cb17-245"><a href="#cb17-245" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_loss'</span>,</span>
<span id="cb17-246"><a href="#cb17-246" aria-hidden="true" tabindex="-1"></a>    patience<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb17-247"><a href="#cb17-247" aria-hidden="true" tabindex="-1"></a>    restore_best_weights<span class="op">=</span><span class="va">True</span></span>
<span id="cb17-248"><a href="#cb17-248" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-249"><a href="#cb17-249" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-250"><a href="#cb17-250" aria-hidden="true" tabindex="-1"></a>*Prevents overfitting, saves time*</span>
<span id="cb17-251"><a href="#cb17-251" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-252"><a href="#cb17-252" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-253"><a href="#cb17-253" aria-hidden="true" tabindex="-1"></a>::: {.feature-card}</span>
<span id="cb17-254"><a href="#cb17-254" aria-hidden="true" tabindex="-1"></a>**ModelCheckpoint**</span>
<span id="cb17-255"><a href="#cb17-255" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-256"><a href="#cb17-256" aria-hidden="true" tabindex="-1"></a>Save best model during training:</span>
<span id="cb17-257"><a href="#cb17-257" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb17-258"><a href="#cb17-258" aria-hidden="true" tabindex="-1"></a>ModelCheckpoint(</span>
<span id="cb17-259"><a href="#cb17-259" aria-hidden="true" tabindex="-1"></a>    <span class="st">'best_model.h5'</span>,</span>
<span id="cb17-260"><a href="#cb17-260" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_accuracy'</span>,</span>
<span id="cb17-261"><a href="#cb17-261" aria-hidden="true" tabindex="-1"></a>    save_best_only<span class="op">=</span><span class="va">True</span></span>
<span id="cb17-262"><a href="#cb17-262" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-263"><a href="#cb17-263" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-264"><a href="#cb17-264" aria-hidden="true" tabindex="-1"></a>*Preserves optimal weights*</span>
<span id="cb17-265"><a href="#cb17-265" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-266"><a href="#cb17-266" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-267"><a href="#cb17-267" aria-hidden="true" tabindex="-1"></a>::: {.feature-card}</span>
<span id="cb17-268"><a href="#cb17-268" aria-hidden="true" tabindex="-1"></a>**ReduceLROnPlateau**</span>
<span id="cb17-269"><a href="#cb17-269" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-270"><a href="#cb17-270" aria-hidden="true" tabindex="-1"></a>Lower learning rate when stuck:</span>
<span id="cb17-271"><a href="#cb17-271" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb17-272"><a href="#cb17-272" aria-hidden="true" tabindex="-1"></a>ReduceLROnPlateau(</span>
<span id="cb17-273"><a href="#cb17-273" aria-hidden="true" tabindex="-1"></a>    monitor<span class="op">=</span><span class="st">'val_loss'</span>,</span>
<span id="cb17-274"><a href="#cb17-274" aria-hidden="true" tabindex="-1"></a>    factor<span class="op">=</span><span class="fl">0.5</span>,</span>
<span id="cb17-275"><a href="#cb17-275" aria-hidden="true" tabindex="-1"></a>    patience<span class="op">=</span><span class="dv">3</span></span>
<span id="cb17-276"><a href="#cb17-276" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-277"><a href="#cb17-277" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-278"><a href="#cb17-278" aria-hidden="true" tabindex="-1"></a>*Helps escape local minima*</span>
<span id="cb17-279"><a href="#cb17-279" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-280"><a href="#cb17-280" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-281"><a href="#cb17-281" aria-hidden="true" tabindex="-1"></a>::: {.feature-card}</span>
<span id="cb17-282"><a href="#cb17-282" aria-hidden="true" tabindex="-1"></a>**TensorBoard**</span>
<span id="cb17-283"><a href="#cb17-283" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-284"><a href="#cb17-284" aria-hidden="true" tabindex="-1"></a>Real-time training visualization:</span>
<span id="cb17-285"><a href="#cb17-285" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb17-286"><a href="#cb17-286" aria-hidden="true" tabindex="-1"></a>TensorBoard(</span>
<span id="cb17-287"><a href="#cb17-287" aria-hidden="true" tabindex="-1"></a>    log_dir<span class="op">=</span><span class="st">'./logs'</span></span>
<span id="cb17-288"><a href="#cb17-288" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-289"><a href="#cb17-289" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-290"><a href="#cb17-290" aria-hidden="true" tabindex="-1"></a>*Monitor metrics live*</span>
<span id="cb17-291"><a href="#cb17-291" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-292"><a href="#cb17-292" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-293"><a href="#cb17-293" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-294"><a href="#cb17-294" aria-hidden="true" tabindex="-1"></a>**Execute Training**</span>
<span id="cb17-295"><a href="#cb17-295" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Train for 20-30 epochs (likely stops early)</span>
<span id="cb17-296"><a href="#cb17-296" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Monitor training/validation metrics in real-time</span>
<span id="cb17-297"><a href="#cb17-297" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Observe learning curves for overfitting signs</span>
<span id="cb17-298"><a href="#cb17-298" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Track GPU utilization and training speed</span>
<span id="cb17-299"><a href="#cb17-299" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-300"><a href="#cb17-300" aria-hidden="true" tabindex="-1"></a>**Interpret Learning Curves**</span>
<span id="cb17-301"><a href="#cb17-301" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-302"><a href="#cb17-302" aria-hidden="true" tabindex="-1"></a>**Healthy Training:**</span>
<span id="cb17-303"><a href="#cb17-303" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Train loss decreases steadily</span>
<span id="cb17-304"><a href="#cb17-304" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Validation loss decreases, plateaus</span>
<span id="cb17-305"><a href="#cb17-305" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Small train-val gap (&lt;5-10%)</span>
<span id="cb17-306"><a href="#cb17-306" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Validation accuracy plateaus at high value</span>
<span id="cb17-307"><a href="#cb17-307" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-308"><a href="#cb17-308" aria-hidden="true" tabindex="-1"></a>**Overfitting Signs:**</span>
<span id="cb17-309"><a href="#cb17-309" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Train accuracy → 100%, val accuracy plateaus low</span>
<span id="cb17-310"><a href="#cb17-310" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Large train-val gap (&gt;15-20%)</span>
<span id="cb17-311"><a href="#cb17-311" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Validation loss increases while train loss decreases</span>
<span id="cb17-312"><a href="#cb17-312" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Solution:** More dropout, stronger regularization, more data</span>
<span id="cb17-313"><a href="#cb17-313" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-314"><a href="#cb17-314" aria-hidden="true" tabindex="-1"></a>**Underfitting Signs:**</span>
<span id="cb17-315"><a href="#cb17-315" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Both train and val accuracy low</span>
<span id="cb17-316"><a href="#cb17-316" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Loss plateaus at high value</span>
<span id="cb17-317"><a href="#cb17-317" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>No improvement with more epochs</span>
<span id="cb17-318"><a href="#cb17-318" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Solution:** More complex model, lower regularization, train longer</span>
<span id="cb17-319"><a href="#cb17-319" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-320"><a href="#cb17-320" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-321"><a href="#cb17-321" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-322"><a href="#cb17-322" aria-hidden="true" tabindex="-1"></a><span class="fu">### Part D: Comprehensive Evaluation (30 minutes)</span></span>
<span id="cb17-323"><a href="#cb17-323" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-324"><a href="#cb17-324" aria-hidden="true" tabindex="-1"></a>**Test Set Performance**</span>
<span id="cb17-325"><a href="#cb17-325" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Load best saved model</span>
<span id="cb17-326"><a href="#cb17-326" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Evaluate on held-out test set</span>
<span id="cb17-327"><a href="#cb17-327" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Calculate final accuracy and loss</span>
<span id="cb17-328"><a href="#cb17-328" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Compare with validation performance</span>
<span id="cb17-329"><a href="#cb17-329" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-330"><a href="#cb17-330" aria-hidden="true" tabindex="-1"></a>**Confusion Matrix Analysis**</span>
<span id="cb17-331"><a href="#cb17-331" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-332"><a href="#cb17-332" aria-hidden="true" tabindex="-1"></a>Generate and visualize 10×10 confusion matrix:</span>
<span id="cb17-333"><a href="#cb17-333" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-334"><a href="#cb17-334" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> True ↓ / Pred → <span class="pp">|</span> AnnualCrop <span class="pp">|</span> Forest <span class="pp">|</span> Herbaceous <span class="pp">|</span> Highway <span class="pp">|</span> ... <span class="pp">|</span></span>
<span id="cb17-335"><a href="#cb17-335" aria-hidden="true" tabindex="-1"></a><span class="pp">|----------------|------------|--------|------------|---------|-----|</span></span>
<span id="cb17-336"><a href="#cb17-336" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> AnnualCrop     <span class="pp">|</span> **450**    <span class="pp">|</span> 12     <span class="pp">|</span> 8          <span class="pp">|</span> 2       <span class="pp">|</span> ... <span class="pp">|</span></span>
<span id="cb17-337"><a href="#cb17-337" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Forest         <span class="pp">|</span> 5          <span class="pp">|</span> **492**<span class="pp">|</span> 3          <span class="pp">|</span> 0       <span class="pp">|</span> ... <span class="pp">|</span></span>
<span id="cb17-338"><a href="#cb17-338" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Herbaceous     <span class="pp">|</span> 18         <span class="pp">|</span> 7      <span class="pp">|</span> **441**    <span class="pp">|</span> 1       <span class="pp">|</span> ... <span class="pp">|</span></span>
<span id="cb17-339"><a href="#cb17-339" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> ...            <span class="pp">|</span> ...        <span class="pp">|</span> ...    <span class="pp">|</span> ...        <span class="pp">|</span> ...     <span class="pp">|</span> ... <span class="pp">|</span></span>
<span id="cb17-340"><a href="#cb17-340" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-341"><a href="#cb17-341" aria-hidden="true" tabindex="-1"></a>**Insights from Confusion:**</span>
<span id="cb17-342"><a href="#cb17-342" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Diagonal values:** Correct classifications (darker = better)</span>
<span id="cb17-343"><a href="#cb17-343" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Off-diagonal:** Common confusions</span>
<span id="cb17-344"><a href="#cb17-344" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Typical EO confusions:**</span>
<span id="cb17-345"><a href="#cb17-345" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>AnnualCrop ↔ Herbaceous (similar vegetation)</span>
<span id="cb17-346"><a href="#cb17-346" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Industrial ↔ Highway (both gray infrastructure)</span>
<span id="cb17-347"><a href="#cb17-347" aria-hidden="true" tabindex="-1"></a><span class="ss">  - </span>Forest ↔ PermanentCrop (tree canopies)</span>
<span id="cb17-348"><a href="#cb17-348" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-349"><a href="#cb17-349" aria-hidden="true" tabindex="-1"></a>**Per-Class Metrics**</span>
<span id="cb17-350"><a href="#cb17-350" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-351"><a href="#cb17-351" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-352"><a href="#cb17-352" aria-hidden="true" tabindex="-1"></a><span class="in">              precision    recall  f1-score   support</span></span>
<span id="cb17-353"><a href="#cb17-353" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-354"><a href="#cb17-354" aria-hidden="true" tabindex="-1"></a><span class="in">  AnnualCrop       0.93      0.94      0.93       478</span></span>
<span id="cb17-355"><a href="#cb17-355" aria-hidden="true" tabindex="-1"></a><span class="in">      Forest       0.96      0.97      0.97       507</span></span>
<span id="cb17-356"><a href="#cb17-356" aria-hidden="true" tabindex="-1"></a><span class="in">  Herbaceous       0.91      0.92      0.92       481</span></span>
<span id="cb17-357"><a href="#cb17-357" aria-hidden="true" tabindex="-1"></a><span class="in">     Highway       0.94      0.92      0.93       453</span></span>
<span id="cb17-358"><a href="#cb17-358" aria-hidden="true" tabindex="-1"></a><span class="in">  Industrial       0.89      0.87      0.88       461</span></span>
<span id="cb17-359"><a href="#cb17-359" aria-hidden="true" tabindex="-1"></a><span class="in">     Pasture       0.90      0.91      0.91       489</span></span>
<span id="cb17-360"><a href="#cb17-360" aria-hidden="true" tabindex="-1"></a><span class="in">PermanentCrop      0.92      0.91      0.92       471</span></span>
<span id="cb17-361"><a href="#cb17-361" aria-hidden="true" tabindex="-1"></a><span class="in"> Residential       0.95      0.96      0.95       498</span></span>
<span id="cb17-362"><a href="#cb17-362" aria-hidden="true" tabindex="-1"></a><span class="in">       River       0.98      0.97      0.98       502</span></span>
<span id="cb17-363"><a href="#cb17-363" aria-hidden="true" tabindex="-1"></a><span class="in">     SeaLake       0.97      0.98      0.98       510</span></span>
<span id="cb17-364"><a href="#cb17-364" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-365"><a href="#cb17-365" aria-hidden="true" tabindex="-1"></a><span class="in">    accuracy                           0.94      4850</span></span>
<span id="cb17-366"><a href="#cb17-366" aria-hidden="true" tabindex="-1"></a><span class="in">   macro avg       0.94      0.94      0.94      4850</span></span>
<span id="cb17-367"><a href="#cb17-367" aria-hidden="true" tabindex="-1"></a><span class="in">weighted avg       0.94      0.94      0.94      4850</span></span>
<span id="cb17-368"><a href="#cb17-368" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-369"><a href="#cb17-369" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-370"><a href="#cb17-370" aria-hidden="true" tabindex="-1"></a>**Error Analysis**</span>
<span id="cb17-371"><a href="#cb17-371" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Identify most confused class pairs</span>
<span id="cb17-372"><a href="#cb17-372" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Visualize misclassified examples</span>
<span id="cb17-373"><a href="#cb17-373" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Understand model failure modes</span>
<span id="cb17-374"><a href="#cb17-374" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Suggest improvements</span>
<span id="cb17-375"><a href="#cb17-375" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-376"><a href="#cb17-376" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-377"><a href="#cb17-377" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-378"><a href="#cb17-378" aria-hidden="true" tabindex="-1"></a><span class="fu">### Part E: Transfer Learning (20 minutes)</span></span>
<span id="cb17-379"><a href="#cb17-379" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-380"><a href="#cb17-380" aria-hidden="true" tabindex="-1"></a>**Why Transfer Learning for EO?**</span>
<span id="cb17-381"><a href="#cb17-381" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-382"><a href="#cb17-382" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb17-383"><a href="#cb17-383" aria-hidden="true" tabindex="-1"></a><span class="fu">## Transfer Learning Benefits</span></span>
<span id="cb17-384"><a href="#cb17-384" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-385"><a href="#cb17-385" aria-hidden="true" tabindex="-1"></a>**ImageNet Pre-training Advantages:**</span>
<span id="cb17-386"><a href="#cb17-386" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Low-level features transfer:** Edges, textures, colors are universal</span>
<span id="cb17-387"><a href="#cb17-387" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Reduced training time:** 80-90% faster convergence</span>
<span id="cb17-388"><a href="#cb17-388" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Better with limited data:** Works with 100s of samples vs 1000s</span>
<span id="cb17-389"><a href="#cb17-389" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Higher accuracy:** +2-5% typical improvement</span>
<span id="cb17-390"><a href="#cb17-390" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Regularization effect:** Pre-trained weights prevent overfitting</span>
<span id="cb17-391"><a href="#cb17-391" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-392"><a href="#cb17-392" aria-hidden="true" tabindex="-1"></a>**When to Use:**</span>
<span id="cb17-393"><a href="#cb17-393" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Limited labeled training data (&lt;5000 samples)</span>
<span id="cb17-394"><a href="#cb17-394" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Similar task to ImageNet (object recognition)</span>
<span id="cb17-395"><a href="#cb17-395" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Time/compute constraints</span>
<span id="cb17-396"><a href="#cb17-396" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Need strong baseline quickly</span>
<span id="cb17-397"><a href="#cb17-397" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-398"><a href="#cb17-398" aria-hidden="true" tabindex="-1"></a>**When NOT to Use:**</span>
<span id="cb17-399"><a href="#cb17-399" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Very different from natural images (SAR, hyperspectral)</span>
<span id="cb17-400"><a href="#cb17-400" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Abundant labeled data (&gt;50K samples)</span>
<span id="cb17-401"><a href="#cb17-401" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Highly specialized task</span>
<span id="cb17-402"><a href="#cb17-402" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-403"><a href="#cb17-403" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-404"><a href="#cb17-404" aria-hidden="true" tabindex="-1"></a>**Load Pre-trained Model**</span>
<span id="cb17-405"><a href="#cb17-405" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-406"><a href="#cb17-406" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb17-407"><a href="#cb17-407" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tensorflow.keras.applications <span class="im">import</span> ResNet50</span>
<span id="cb17-408"><a href="#cb17-408" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-409"><a href="#cb17-409" aria-hidden="true" tabindex="-1"></a><span class="co"># Load ResNet50 with ImageNet weights</span></span>
<span id="cb17-410"><a href="#cb17-410" aria-hidden="true" tabindex="-1"></a>base_model <span class="op">=</span> ResNet50(</span>
<span id="cb17-411"><a href="#cb17-411" aria-hidden="true" tabindex="-1"></a>    include_top<span class="op">=</span><span class="va">False</span>,  <span class="co"># Exclude classification head</span></span>
<span id="cb17-412"><a href="#cb17-412" aria-hidden="true" tabindex="-1"></a>    weights<span class="op">=</span><span class="st">'imagenet'</span>,  <span class="co"># Use pre-trained weights</span></span>
<span id="cb17-413"><a href="#cb17-413" aria-hidden="true" tabindex="-1"></a>    input_shape<span class="op">=</span>(<span class="dv">64</span>, <span class="dv">64</span>, <span class="dv">3</span>),</span>
<span id="cb17-414"><a href="#cb17-414" aria-hidden="true" tabindex="-1"></a>    pooling<span class="op">=</span><span class="st">'avg'</span>  <span class="co"># Global average pooling</span></span>
<span id="cb17-415"><a href="#cb17-415" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb17-416"><a href="#cb17-416" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-417"><a href="#cb17-417" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-418"><a href="#cb17-418" aria-hidden="true" tabindex="-1"></a>**Fine-tuning Strategy**</span>
<span id="cb17-419"><a href="#cb17-419" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-420"><a href="#cb17-420" aria-hidden="true" tabindex="-1"></a>**Option 1: Freeze All Layers (Feature Extraction)**</span>
<span id="cb17-421"><a href="#cb17-421" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb17-422"><a href="#cb17-422" aria-hidden="true" tabindex="-1"></a><span class="co"># Freeze all base model layers</span></span>
<span id="cb17-423"><a href="#cb17-423" aria-hidden="true" tabindex="-1"></a>base_model.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb17-424"><a href="#cb17-424" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-425"><a href="#cb17-425" aria-hidden="true" tabindex="-1"></a><span class="co"># Add custom classification head</span></span>
<span id="cb17-426"><a href="#cb17-426" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Sequential([</span>
<span id="cb17-427"><a href="#cb17-427" aria-hidden="true" tabindex="-1"></a>    base_model,</span>
<span id="cb17-428"><a href="#cb17-428" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">256</span>, activation<span class="op">=</span><span class="st">'relu'</span>),</span>
<span id="cb17-429"><a href="#cb17-429" aria-hidden="true" tabindex="-1"></a>    Dropout(<span class="fl">0.5</span>),</span>
<span id="cb17-430"><a href="#cb17-430" aria-hidden="true" tabindex="-1"></a>    Dense(<span class="dv">10</span>, activation<span class="op">=</span><span class="st">'softmax'</span>)</span>
<span id="cb17-431"><a href="#cb17-431" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb17-432"><a href="#cb17-432" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-433"><a href="#cb17-433" aria-hidden="true" tabindex="-1"></a>*Fast training, use when data is very limited*</span>
<span id="cb17-434"><a href="#cb17-434" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-435"><a href="#cb17-435" aria-hidden="true" tabindex="-1"></a>**Option 2: Freeze Early, Train Late (Partial Fine-tuning)**</span>
<span id="cb17-436"><a href="#cb17-436" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb17-437"><a href="#cb17-437" aria-hidden="true" tabindex="-1"></a><span class="co"># Freeze first 80% of layers</span></span>
<span id="cb17-438"><a href="#cb17-438" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> layer <span class="kw">in</span> base_model.layers[:<span class="bu">int</span>(<span class="fl">0.8</span> <span class="op">*</span> <span class="bu">len</span>(base_model.layers))]:</span>
<span id="cb17-439"><a href="#cb17-439" aria-hidden="true" tabindex="-1"></a>    layer.trainable <span class="op">=</span> <span class="va">False</span></span>
<span id="cb17-440"><a href="#cb17-440" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-441"><a href="#cb17-441" aria-hidden="true" tabindex="-1"></a><span class="co"># Fine-tune top layers + custom head</span></span>
<span id="cb17-442"><a href="#cb17-442" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-443"><a href="#cb17-443" aria-hidden="true" tabindex="-1"></a>*Balanced approach, best for moderate data*</span>
<span id="cb17-444"><a href="#cb17-444" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-445"><a href="#cb17-445" aria-hidden="true" tabindex="-1"></a>**Option 3: Full Fine-tuning**</span>
<span id="cb17-446"><a href="#cb17-446" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb17-447"><a href="#cb17-447" aria-hidden="true" tabindex="-1"></a><span class="co"># All layers trainable</span></span>
<span id="cb17-448"><a href="#cb17-448" aria-hidden="true" tabindex="-1"></a>base_model.trainable <span class="op">=</span> <span class="va">True</span></span>
<span id="cb17-449"><a href="#cb17-449" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-450"><a href="#cb17-450" aria-hidden="true" tabindex="-1"></a><span class="co"># Use lower learning rate (0.0001 instead of 0.001)</span></span>
<span id="cb17-451"><a href="#cb17-451" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> Adam(learning_rate<span class="op">=</span><span class="fl">1e-4</span>)</span>
<span id="cb17-452"><a href="#cb17-452" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-453"><a href="#cb17-453" aria-hidden="true" tabindex="-1"></a>*Slowest, use when data is abundant*</span>
<span id="cb17-454"><a href="#cb17-454" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-455"><a href="#cb17-455" aria-hidden="true" tabindex="-1"></a>**Compare Results:**</span>
<span id="cb17-456"><a href="#cb17-456" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-457"><a href="#cb17-457" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Approach <span class="pp">|</span> Train Time <span class="pp">|</span> Test Accuracy <span class="pp">|</span> Notes <span class="pp">|</span></span>
<span id="cb17-458"><a href="#cb17-458" aria-hidden="true" tabindex="-1"></a><span class="pp">|----------|-----------|---------------|-------|</span></span>
<span id="cb17-459"><a href="#cb17-459" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> From Scratch <span class="pp">|</span> 25 min <span class="pp">|</span> 93.2% <span class="pp">|</span> Baseline <span class="pp">|</span></span>
<span id="cb17-460"><a href="#cb17-460" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Feature Extraction <span class="pp">|</span> 8 min <span class="pp">|</span> 94.1% <span class="pp">|</span> Fast, good boost <span class="pp">|</span></span>
<span id="cb17-461"><a href="#cb17-461" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Partial Fine-tuning <span class="pp">|</span> 15 min <span class="pp">|</span> 95.3% <span class="pp">|</span> Best balance <span class="pp">|</span></span>
<span id="cb17-462"><a href="#cb17-462" aria-hidden="true" tabindex="-1"></a><span class="pp">|</span> Full Fine-tuning <span class="pp">|</span> 30 min <span class="pp">|</span> 95.8% <span class="pp">|</span> Marginal gain <span class="pp">|</span></span>
<span id="cb17-463"><a href="#cb17-463" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-464"><a href="#cb17-464" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-465"><a href="#cb17-465" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-466"><a href="#cb17-466" aria-hidden="true" tabindex="-1"></a><span class="fu">### Part F: Philippine EO Applications (10 minutes)</span></span>
<span id="cb17-467"><a href="#cb17-467" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-468"><a href="#cb17-468" aria-hidden="true" tabindex="-1"></a>**Adapting CNNs for Philippine Contexts**</span>
<span id="cb17-469"><a href="#cb17-469" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-470"><a href="#cb17-470" aria-hidden="true" tabindex="-1"></a>::: {.feature-grid}</span>
<span id="cb17-471"><a href="#cb17-471" aria-hidden="true" tabindex="-1"></a>::: {.feature-card}</span>
<span id="cb17-472"><a href="#cb17-472" aria-hidden="true" tabindex="-1"></a>**Multi-spectral Considerations**</span>
<span id="cb17-473"><a href="#cb17-473" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-474"><a href="#cb17-474" aria-hidden="true" tabindex="-1"></a>**Challenge:** Sentinel-2 has 13 bands, ResNet expects 3</span>
<span id="cb17-475"><a href="#cb17-475" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-476"><a href="#cb17-476" aria-hidden="true" tabindex="-1"></a>**Solutions:**</span>
<span id="cb17-477"><a href="#cb17-477" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Band selection:** Use only RGB (B4, B3, B2)</span>
<span id="cb17-478"><a href="#cb17-478" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Band combinations:** NIR-Red-Green false color</span>
<span id="cb17-479"><a href="#cb17-479" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**PCA:** Reduce 13→3 dimensions</span>
<span id="cb17-480"><a href="#cb17-480" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Architecture modification:** Change input layer to accept 13 channels</span>
<span id="cb17-481"><a href="#cb17-481" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-482"><a href="#cb17-482" aria-hidden="true" tabindex="-1"></a>**Recommendation for Palawan:**</span>
<span id="cb17-483"><a href="#cb17-483" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Start with RGB for transfer learning</span>
<span id="cb17-484"><a href="#cb17-484" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Train custom CNN with all bands for production</span>
<span id="cb17-485"><a href="#cb17-485" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-486"><a href="#cb17-486" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-487"><a href="#cb17-487" aria-hidden="true" tabindex="-1"></a>::: {.feature-card}</span>
<span id="cb17-488"><a href="#cb17-488" aria-hidden="true" tabindex="-1"></a>**Scaling to Operational Use**</span>
<span id="cb17-489"><a href="#cb17-489" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-490"><a href="#cb17-490" aria-hidden="true" tabindex="-1"></a>**PhilSA Production Pipeline:**</span>
<span id="cb17-491"><a href="#cb17-491" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Training:** Palawan pilot (this session)</span>
<span id="cb17-492"><a href="#cb17-492" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Validation:** Other provinces</span>
<span id="cb17-493"><a href="#cb17-493" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Deployment:** Nationwide monitoring</span>
<span id="cb17-494"><a href="#cb17-494" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Updates:** Retrain quarterly</span>
<span id="cb17-495"><a href="#cb17-495" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-496"><a href="#cb17-496" aria-hidden="true" tabindex="-1"></a>**Computational Needs:**</span>
<span id="cb17-497"><a href="#cb17-497" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Training: Cloud GPU (Colab, AWS, Azure)</span>
<span id="cb17-498"><a href="#cb17-498" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Inference: Can run on CPU for deployment</span>
<span id="cb17-499"><a href="#cb17-499" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Storage: Model weights ~50-200 MB</span>
<span id="cb17-500"><a href="#cb17-500" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-501"><a href="#cb17-501" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-502"><a href="#cb17-502" aria-hidden="true" tabindex="-1"></a>::: {.feature-card}</span>
<span id="cb17-503"><a href="#cb17-503" aria-hidden="true" tabindex="-1"></a>**CNN for Disaster Response**</span>
<span id="cb17-504"><a href="#cb17-504" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-505"><a href="#cb17-505" aria-hidden="true" tabindex="-1"></a>**Typhoon Damage Assessment:**</span>
<span id="cb17-506"><a href="#cb17-506" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Input:** Pre/post imagery pairs</span>
<span id="cb17-507"><a href="#cb17-507" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Task:** Binary (damaged/not damaged)</span>
<span id="cb17-508"><a href="#cb17-508" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Architecture:** Siamese network or stacked CNN</span>
<span id="cb17-509"><a href="#cb17-509" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Speed:** Process 1000 km² in hours</span>
<span id="cb17-510"><a href="#cb17-510" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-511"><a href="#cb17-511" aria-hidden="true" tabindex="-1"></a>**Flood Extent Mapping:**</span>
<span id="cb17-512"><a href="#cb17-512" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Advance to Day 3:** U-Net for pixel-level segmentation</span>
<span id="cb17-513"><a href="#cb17-513" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Real-time:** CNN classification during event</span>
<span id="cb17-514"><a href="#cb17-514" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Integration:** Feed into NOAH or Project DOST systems</span>
<span id="cb17-515"><a href="#cb17-515" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-516"><a href="#cb17-516" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-517"><a href="#cb17-517" aria-hidden="true" tabindex="-1"></a>::: {.feature-card}</span>
<span id="cb17-518"><a href="#cb17-518" aria-hidden="true" tabindex="-1"></a>**Accuracy Requirements**</span>
<span id="cb17-519"><a href="#cb17-519" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-520"><a href="#cb17-520" aria-hidden="true" tabindex="-1"></a>**Application-Specific Needs:**</span>
<span id="cb17-521"><a href="#cb17-521" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Land cover monitoring:** 85-90% sufficient</span>
<span id="cb17-522"><a href="#cb17-522" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Forest law enforcement:** 95%+ required</span>
<span id="cb17-523"><a href="#cb17-523" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Disaster response:** Speed &gt; perfect accuracy</span>
<span id="cb17-524"><a href="#cb17-524" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**REDD+ MRV:** High precision needed</span>
<span id="cb17-525"><a href="#cb17-525" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-526"><a href="#cb17-526" aria-hidden="true" tabindex="-1"></a>**Session 4 Achievement:** 93-96% on EuroSAT</span>
<span id="cb17-527"><a href="#cb17-527" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-528"><a href="#cb17-528" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-529"><a href="#cb17-529" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-530"><a href="#cb17-530" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-531"><a href="#cb17-531" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-532"><a href="#cb17-532" aria-hidden="true" tabindex="-1"></a><span class="fu">## Hands-On Notebook</span></span>
<span id="cb17-533"><a href="#cb17-533" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-534"><a href="#cb17-534" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip}</span>
<span id="cb17-535"><a href="#cb17-535" aria-hidden="true" tabindex="-1"></a><span class="fu">## 📓 Interactive Jupyter Notebook</span></span>
<span id="cb17-536"><a href="#cb17-536" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-537"><a href="#cb17-537" aria-hidden="true" tabindex="-1"></a>The complete hands-on lab is available as an executable Jupyter notebook:</span>
<span id="cb17-538"><a href="#cb17-538" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-539"><a href="#cb17-539" aria-hidden="true" tabindex="-1"></a>**Student Version** (with exercises and TODOs):  </span>
<span id="cb17-540"><a href="#cb17-540" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">`session4_cnn_classification_STUDENT.ipynb`</span><span class="co">](../notebooks/session4_cnn_classification_STUDENT.ipynb)</span></span>
<span id="cb17-541"><a href="#cb17-541" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-542"><a href="#cb17-542" aria-hidden="true" tabindex="-1"></a>**Google Colab Direct Link:**  </span>
<span id="cb17-543"><a href="#cb17-543" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="al">![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)</span><span class="co">](https://colab.research.google.com/github/DimitrisKasabalis/EO_trainning/blob/main/course_site/day2/notebooks/session4_cnn_classification_STUDENT.ipynb)</span></span>
<span id="cb17-544"><a href="#cb17-544" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-545"><a href="#cb17-545" aria-hidden="true" tabindex="-1"></a>**What's Included:**</span>
<span id="cb17-546"><a href="#cb17-546" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Complete environment setup (TensorFlow, GPU config)</span>
<span id="cb17-547"><a href="#cb17-547" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>EuroSAT download and preparation scripts</span>
<span id="cb17-548"><a href="#cb17-548" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>CNN architecture implementation (from-scratch and transfer learning)</span>
<span id="cb17-549"><a href="#cb17-549" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Training loops with callbacks</span>
<span id="cb17-550"><a href="#cb17-550" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Comprehensive evaluation code</span>
<span id="cb17-551"><a href="#cb17-551" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Visualization functions</span>
<span id="cb17-552"><a href="#cb17-552" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Interactive exercises</span>
<span id="cb17-553"><a href="#cb17-553" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-554"><a href="#cb17-554" aria-hidden="true" tabindex="-1"></a>**Estimated Execution Time:**</span>
<span id="cb17-555"><a href="#cb17-555" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Setup: 5 minutes</span>
<span id="cb17-556"><a href="#cb17-556" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Data download: 3-5 minutes (90 MB)</span>
<span id="cb17-557"><a href="#cb17-557" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Training from scratch: 15-20 minutes (GPU)</span>
<span id="cb17-558"><a href="#cb17-558" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Transfer learning: 5-10 minutes (GPU)</span>
<span id="cb17-559"><a href="#cb17-559" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Evaluation: 5 minutes</span>
<span id="cb17-560"><a href="#cb17-560" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Total:** ~30-40 minutes with GPU</span>
<span id="cb17-561"><a href="#cb17-561" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-562"><a href="#cb17-562" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-563"><a href="#cb17-563" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-564"><a href="#cb17-564" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-565"><a href="#cb17-565" aria-hidden="true" tabindex="-1"></a><span class="fu">## Expected Outcomes</span></span>
<span id="cb17-566"><a href="#cb17-566" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-567"><a href="#cb17-567" aria-hidden="true" tabindex="-1"></a>By the end of this session, you will have:</span>
<span id="cb17-568"><a href="#cb17-568" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-569"><a href="#cb17-569" aria-hidden="true" tabindex="-1"></a>✅ **Completed Projects:**</span>
<span id="cb17-570"><a href="#cb17-570" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Working EuroSAT CNN classifier (93-96% accuracy)</span>
<span id="cb17-571"><a href="#cb17-571" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Transfer learning model with ResNet50 (94-97% accuracy)</span>
<span id="cb17-572"><a href="#cb17-572" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Comprehensive evaluation report with confusion matrix</span>
<span id="cb17-573"><a href="#cb17-573" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Trained model weights saved for deployment</span>
<span id="cb17-574"><a href="#cb17-574" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-575"><a href="#cb17-575" aria-hidden="true" tabindex="-1"></a>✅ **Technical Skills:**</span>
<span id="cb17-576"><a href="#cb17-576" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>TensorFlow/Keras proficiency for CNNs</span>
<span id="cb17-577"><a href="#cb17-577" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Data pipeline creation with tf.data</span>
<span id="cb17-578"><a href="#cb17-578" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Training with advanced callbacks</span>
<span id="cb17-579"><a href="#cb17-579" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Model evaluation and debugging</span>
<span id="cb17-580"><a href="#cb17-580" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Transfer learning implementation</span>
<span id="cb17-581"><a href="#cb17-581" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-582"><a href="#cb17-582" aria-hidden="true" tabindex="-1"></a>✅ **Practical Deliverables:**</span>
<span id="cb17-583"><a href="#cb17-583" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Executable Jupyter notebook (student version completed)</span>
<span id="cb17-584"><a href="#cb17-584" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Trained models (<span class="in">`.h5`</span> or SavedModel format)</span>
<span id="cb17-585"><a href="#cb17-585" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Learning curve plots</span>
<span id="cb17-586"><a href="#cb17-586" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Confusion matrix visualizations</span>
<span id="cb17-587"><a href="#cb17-587" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Classification report (precision, recall, F1)</span>
<span id="cb17-588"><a href="#cb17-588" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-589"><a href="#cb17-589" aria-hidden="true" tabindex="-1"></a>✅ **Understanding:**</span>
<span id="cb17-590"><a href="#cb17-590" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>When CNNs outperform traditional ML</span>
<span id="cb17-591"><a href="#cb17-591" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>How to choose architecture for EO tasks</span>
<span id="cb17-592"><a href="#cb17-592" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Transfer learning for small datasets</span>
<span id="cb17-593"><a href="#cb17-593" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Hyperparameter tuning strategies</span>
<span id="cb17-594"><a href="#cb17-594" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Deployment considerations</span>
<span id="cb17-595"><a href="#cb17-595" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-596"><a href="#cb17-596" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-597"><a href="#cb17-597" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-598"><a href="#cb17-598" aria-hidden="true" tabindex="-1"></a><span class="fu">## Troubleshooting Guide</span></span>
<span id="cb17-599"><a href="#cb17-599" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-600"><a href="#cb17-600" aria-hidden="true" tabindex="-1"></a><span class="fu">### Common Issues &amp; Solutions</span></span>
<span id="cb17-601"><a href="#cb17-601" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-602"><a href="#cb17-602" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb17-603"><a href="#cb17-603" aria-hidden="true" tabindex="-1"></a><span class="fu">## GPU Not Detected</span></span>
<span id="cb17-604"><a href="#cb17-604" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-605"><a href="#cb17-605" aria-hidden="true" tabindex="-1"></a>**Symptoms:**</span>
<span id="cb17-606"><a href="#cb17-606" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-607"><a href="#cb17-607" aria-hidden="true" tabindex="-1"></a><span class="in">Physical devices: []</span></span>
<span id="cb17-608"><a href="#cb17-608" aria-hidden="true" tabindex="-1"></a><span class="in">WARNING: No GPU available, using CPU</span></span>
<span id="cb17-609"><a href="#cb17-609" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-610"><a href="#cb17-610" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-611"><a href="#cb17-611" aria-hidden="true" tabindex="-1"></a>**Solutions:**</span>
<span id="cb17-612"><a href="#cb17-612" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Colab:** Runtime → Change runtime type → Hardware accelerator → GPU</span>
<span id="cb17-613"><a href="#cb17-613" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Verify:** Run <span class="in">`tf.config.list_physical_devices('GPU')`</span></span>
<span id="cb17-614"><a href="#cb17-614" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Restart runtime:** Runtime → Restart runtime</span>
<span id="cb17-615"><a href="#cb17-615" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Check quota:** Colab has usage limits (reconnect after 12 hours)</span>
<span id="cb17-616"><a href="#cb17-616" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Alternative:** Use Kaggle Notebooks (30 hrs/week GPU free)</span>
<span id="cb17-617"><a href="#cb17-617" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-618"><a href="#cb17-618" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-619"><a href="#cb17-619" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb17-620"><a href="#cb17-620" aria-hidden="true" tabindex="-1"></a><span class="fu">## Out of Memory Error</span></span>
<span id="cb17-621"><a href="#cb17-621" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-622"><a href="#cb17-622" aria-hidden="true" tabindex="-1"></a>**Symptoms:**</span>
<span id="cb17-623"><a href="#cb17-623" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-624"><a href="#cb17-624" aria-hidden="true" tabindex="-1"></a><span class="in">ResourceExhaustedError: OOM when allocating tensor</span></span>
<span id="cb17-625"><a href="#cb17-625" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-626"><a href="#cb17-626" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-627"><a href="#cb17-627" aria-hidden="true" tabindex="-1"></a>**Solutions:**</span>
<span id="cb17-628"><a href="#cb17-628" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Reduce batch size:** 32 → 16 → 8</span>
<span id="cb17-629"><a href="#cb17-629" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Smaller model:** Fewer filters (128→64), fewer layers</span>
<span id="cb17-630"><a href="#cb17-630" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Mixed precision:** <span class="in">`tf.keras.mixed_precision.set_global_policy('mixed_float16')`</span></span>
<span id="cb17-631"><a href="#cb17-631" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Clear memory:** <span class="in">`tf.keras.backend.clear_session()`</span></span>
<span id="cb17-632"><a href="#cb17-632" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Restart runtime:** Fresh start clears memory</span>
<span id="cb17-633"><a href="#cb17-633" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-634"><a href="#cb17-634" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-635"><a href="#cb17-635" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb17-636"><a href="#cb17-636" aria-hidden="true" tabindex="-1"></a><span class="fu">## Training Not Improving</span></span>
<span id="cb17-637"><a href="#cb17-637" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-638"><a href="#cb17-638" aria-hidden="true" tabindex="-1"></a>**Symptoms:**</span>
<span id="cb17-639"><a href="#cb17-639" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Accuracy stuck at ~10% (random guessing)</span>
<span id="cb17-640"><a href="#cb17-640" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Loss = NaN or infinity</span>
<span id="cb17-641"><a href="#cb17-641" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Very slow convergence</span>
<span id="cb17-642"><a href="#cb17-642" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-643"><a href="#cb17-643" aria-hidden="true" tabindex="-1"></a>**Solutions:**</span>
<span id="cb17-644"><a href="#cb17-644" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Learning rate too high:** Reduce to 0.0001</span>
<span id="cb17-645"><a href="#cb17-645" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Check data normalization:** Images should be 0-1 or standardized</span>
<span id="cb17-646"><a href="#cb17-646" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Verify labels:** One-hot encoded correctly (shape: <span class="co">[</span><span class="ot">batch, 10</span><span class="co">]</span>)</span>
<span id="cb17-647"><a href="#cb17-647" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Gradient clipping:** <span class="in">`optimizer = Adam(clipnorm=1.0)`</span></span>
<span id="cb17-648"><a href="#cb17-648" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Simpler model:** Start with 2 conv blocks instead of 3</span>
<span id="cb17-649"><a href="#cb17-649" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>**Check for bugs:** Print shapes, verify data loading</span>
<span id="cb17-650"><a href="#cb17-650" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-651"><a href="#cb17-651" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-652"><a href="#cb17-652" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb17-653"><a href="#cb17-653" aria-hidden="true" tabindex="-1"></a><span class="fu">## Overfitting Severely</span></span>
<span id="cb17-654"><a href="#cb17-654" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-655"><a href="#cb17-655" aria-hidden="true" tabindex="-1"></a>**Symptoms:**</span>
<span id="cb17-656"><a href="#cb17-656" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Train accuracy: 99%, Val accuracy: 75%</span>
<span id="cb17-657"><a href="#cb17-657" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Validation loss increases while train loss decreases</span>
<span id="cb17-658"><a href="#cb17-658" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-659"><a href="#cb17-659" aria-hidden="true" tabindex="-1"></a>**Solutions:**</span>
<span id="cb17-660"><a href="#cb17-660" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**More dropout:** Increase from 0.3 to 0.5</span>
<span id="cb17-661"><a href="#cb17-661" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Data augmentation:** Add rotation, flip, zoom</span>
<span id="cb17-662"><a href="#cb17-662" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**L2 regularization:** <span class="in">`Conv2D(..., kernel_regularizer=l2(0.001))`</span></span>
<span id="cb17-663"><a href="#cb17-663" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Reduce model capacity:** Fewer filters, fewer layers</span>
<span id="cb17-664"><a href="#cb17-664" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Early stopping:** Patience=3-5 epochs</span>
<span id="cb17-665"><a href="#cb17-665" aria-hidden="true" tabindex="-1"></a><span class="ss">6. </span>**More training data:** Use full EuroSAT (27K images)</span>
<span id="cb17-666"><a href="#cb17-666" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-667"><a href="#cb17-667" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-668"><a href="#cb17-668" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb17-669"><a href="#cb17-669" aria-hidden="true" tabindex="-1"></a><span class="fu">## Dataset Download Fails</span></span>
<span id="cb17-670"><a href="#cb17-670" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-671"><a href="#cb17-671" aria-hidden="true" tabindex="-1"></a>**Symptoms:**</span>
<span id="cb17-672"><a href="#cb17-672" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-673"><a href="#cb17-673" aria-hidden="true" tabindex="-1"></a><span class="in">HTTPError: 404 Not Found</span></span>
<span id="cb17-674"><a href="#cb17-674" aria-hidden="true" tabindex="-1"></a><span class="in">Connection timeout</span></span>
<span id="cb17-675"><a href="#cb17-675" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-676"><a href="#cb17-676" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-677"><a href="#cb17-677" aria-hidden="true" tabindex="-1"></a>**Solutions:**</span>
<span id="cb17-678"><a href="#cb17-678" aria-hidden="true" tabindex="-1"></a><span class="ss">1. </span>**Use mirror site:** TensorFlow Datasets, Kaggle</span>
<span id="cb17-679"><a href="#cb17-679" aria-hidden="true" tabindex="-1"></a><span class="ss">2. </span>**Manual download:** Provide local copy</span>
<span id="cb17-680"><a href="#cb17-680" aria-hidden="true" tabindex="-1"></a><span class="ss">3. </span>**Check internet:** Colab connectivity issues</span>
<span id="cb17-681"><a href="#cb17-681" aria-hidden="true" tabindex="-1"></a><span class="ss">4. </span>**Retry:** <span class="in">`wget`</span> with retries</span>
<span id="cb17-682"><a href="#cb17-682" aria-hidden="true" tabindex="-1"></a><span class="ss">5. </span>**Pre-downloaded:** Load from Google Drive</span>
<span id="cb17-683"><a href="#cb17-683" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-684"><a href="#cb17-684" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-685"><a href="#cb17-685" aria-hidden="true" tabindex="-1"></a>::: {.callout-warning}</span>
<span id="cb17-686"><a href="#cb17-686" aria-hidden="true" tabindex="-1"></a><span class="fu">## Augmentation Visualization Error</span></span>
<span id="cb17-687"><a href="#cb17-687" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-688"><a href="#cb17-688" aria-hidden="true" tabindex="-1"></a>**Symptoms:**</span>
<span id="cb17-689"><a href="#cb17-689" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-690"><a href="#cb17-690" aria-hidden="true" tabindex="-1"></a><span class="in">TypeError: only integer scalar arrays can be converted to a scalar index</span></span>
<span id="cb17-691"><a href="#cb17-691" aria-hidden="true" tabindex="-1"></a><span class="in"># OR</span></span>
<span id="cb17-692"><a href="#cb17-692" aria-hidden="true" tabindex="-1"></a><span class="in">IndexError: invalid index to scalar variable</span></span>
<span id="cb17-693"><a href="#cb17-693" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-694"><a href="#cb17-694" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-695"><a href="#cb17-695" aria-hidden="true" tabindex="-1"></a>**When:** In the "Visualize Augmentation" cell when trying to display augmented images</span>
<span id="cb17-696"><a href="#cb17-696" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-697"><a href="#cb17-697" aria-hidden="true" tabindex="-1"></a>**Root Cause:**</span>
<span id="cb17-698"><a href="#cb17-698" aria-hidden="true" tabindex="-1"></a>The code uses <span class="in">`class_names[sample_label.numpy()]`</span> but <span class="in">`sample_label.numpy()`</span> returns a numpy scalar (e.g., <span class="in">`numpy.int64(3)`</span>) which some Python versions don't accept as a list index.</span>
<span id="cb17-699"><a href="#cb17-699" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-700"><a href="#cb17-700" aria-hidden="true" tabindex="-1"></a>**Solutions:**</span>
<span id="cb17-701"><a href="#cb17-701" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-702"><a href="#cb17-702" aria-hidden="true" tabindex="-1"></a>**Quick Fix (Add one line):**</span>
<span id="cb17-703"><a href="#cb17-703" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb17-704"><a href="#cb17-704" aria-hidden="true" tabindex="-1"></a><span class="co"># After: sample_image, sample_label = next(iter(ds_train))</span></span>
<span id="cb17-705"><a href="#cb17-705" aria-hidden="true" tabindex="-1"></a><span class="co"># Add this line:</span></span>
<span id="cb17-706"><a href="#cb17-706" aria-hidden="true" tabindex="-1"></a>label_idx <span class="op">=</span> <span class="bu">int</span>(sample_label.numpy())</span>
<span id="cb17-707"><a href="#cb17-707" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-708"><a href="#cb17-708" aria-hidden="true" tabindex="-1"></a><span class="co"># Then change plt.suptitle line to use label_idx:</span></span>
<span id="cb17-709"><a href="#cb17-709" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="ss">f'Data Augmentation Examples</span><span class="ch">\n</span><span class="ss">Class: </span><span class="sc">{</span>class_names[label_idx]<span class="sc">}</span><span class="ss">'</span>,</span>
<span id="cb17-710"><a href="#cb17-710" aria-hidden="true" tabindex="-1"></a>             fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb17-711"><a href="#cb17-711" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-712"><a href="#cb17-712" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-713"><a href="#cb17-713" aria-hidden="true" tabindex="-1"></a>**Complete Fixed Cell:**</span>
<span id="cb17-714"><a href="#cb17-714" aria-hidden="true" tabindex="-1"></a><span class="in">```python</span></span>
<span id="cb17-715"><a href="#cb17-715" aria-hidden="true" tabindex="-1"></a><span class="co"># Show original vs augmented</span></span>
<span id="cb17-716"><a href="#cb17-716" aria-hidden="true" tabindex="-1"></a>sample_image, sample_label <span class="op">=</span> <span class="bu">next</span>(<span class="bu">iter</span>(ds_train))</span>
<span id="cb17-717"><a href="#cb17-717" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-718"><a href="#cb17-718" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert label to integer for indexing</span></span>
<span id="cb17-719"><a href="#cb17-719" aria-hidden="true" tabindex="-1"></a>label_idx <span class="op">=</span> <span class="bu">int</span>(sample_label.numpy())  <span class="co"># &lt;-- ADD THIS LINE</span></span>
<span id="cb17-720"><a href="#cb17-720" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-721"><a href="#cb17-721" aria-hidden="true" tabindex="-1"></a>fig, axes <span class="op">=</span> plt.subplots(<span class="dv">2</span>, <span class="dv">4</span>, figsize<span class="op">=</span>(<span class="dv">14</span>, <span class="dv">7</span>))</span>
<span id="cb17-722"><a href="#cb17-722" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-723"><a href="#cb17-723" aria-hidden="true" tabindex="-1"></a><span class="co"># Original</span></span>
<span id="cb17-724"><a href="#cb17-724" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].imshow(sample_image.numpy())</span>
<span id="cb17-725"><a href="#cb17-725" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].set_title(<span class="st">'Original'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb17-726"><a href="#cb17-726" aria-hidden="true" tabindex="-1"></a>axes[<span class="dv">0</span>, <span class="dv">0</span>].axis(<span class="st">'off'</span>)</span>
<span id="cb17-727"><a href="#cb17-727" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-728"><a href="#cb17-728" aria-hidden="true" tabindex="-1"></a><span class="co"># Augmented versions</span></span>
<span id="cb17-729"><a href="#cb17-729" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">8</span>):</span>
<span id="cb17-730"><a href="#cb17-730" aria-hidden="true" tabindex="-1"></a>    row <span class="op">=</span> idx <span class="op">//</span> <span class="dv">4</span></span>
<span id="cb17-731"><a href="#cb17-731" aria-hidden="true" tabindex="-1"></a>    col <span class="op">=</span> idx <span class="op">%</span> <span class="dv">4</span></span>
<span id="cb17-732"><a href="#cb17-732" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb17-733"><a href="#cb17-733" aria-hidden="true" tabindex="-1"></a>    augmented <span class="op">=</span> data_augmentation(tf.expand_dims(sample_image, <span class="dv">0</span>), training<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]</span>
<span id="cb17-734"><a href="#cb17-734" aria-hidden="true" tabindex="-1"></a>    axes[row, col].imshow(augmented.numpy())</span>
<span id="cb17-735"><a href="#cb17-735" aria-hidden="true" tabindex="-1"></a>    axes[row, col].set_title(<span class="ss">f'Augmented </span><span class="sc">{</span>idx<span class="sc">}</span><span class="ss">'</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb17-736"><a href="#cb17-736" aria-hidden="true" tabindex="-1"></a>    axes[row, col].axis(<span class="st">'off'</span>)</span>
<span id="cb17-737"><a href="#cb17-737" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-738"><a href="#cb17-738" aria-hidden="true" tabindex="-1"></a><span class="co"># Use label_idx instead of sample_label.numpy()</span></span>
<span id="cb17-739"><a href="#cb17-739" aria-hidden="true" tabindex="-1"></a>plt.suptitle(<span class="ss">f'Data Augmentation Examples</span><span class="ch">\n</span><span class="ss">Class: </span><span class="sc">{</span>class_names[label_idx]<span class="sc">}</span><span class="ss">'</span>,  <span class="co"># &lt;-- CHANGED</span></span>
<span id="cb17-740"><a href="#cb17-740" aria-hidden="true" tabindex="-1"></a>             fontsize<span class="op">=</span><span class="dv">14</span>, fontweight<span class="op">=</span><span class="st">'bold'</span>)</span>
<span id="cb17-741"><a href="#cb17-741" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb17-742"><a href="#cb17-742" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb17-743"><a href="#cb17-743" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-744"><a href="#cb17-744" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">✓ Augmentation creates realistic variations"</span>)</span>
<span id="cb17-745"><a href="#cb17-745" aria-hidden="true" tabindex="-1"></a><span class="in">```</span></span>
<span id="cb17-746"><a href="#cb17-746" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-747"><a href="#cb17-747" aria-hidden="true" tabindex="-1"></a>**Why This Works:**</span>
<span id="cb17-748"><a href="#cb17-748" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`int()`</span> explicitly converts numpy scalar to Python integer</span>
<span id="cb17-749"><a href="#cb17-749" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Python lists accept native integers as indices reliably</span>
<span id="cb17-750"><a href="#cb17-750" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Prevents type mismatch between numpy and Python types</span>
<span id="cb17-751"><a href="#cb17-751" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-752"><a href="#cb17-752" aria-hidden="true" tabindex="-1"></a>**Note:** A fixed version of the notebook is available: <span class="in">`session4_cnn_classification_STUDENT_FIXED.ipynb`</span></span>
<span id="cb17-753"><a href="#cb17-753" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-754"><a href="#cb17-754" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-755"><a href="#cb17-755" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-756"><a href="#cb17-756" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-757"><a href="#cb17-757" aria-hidden="true" tabindex="-1"></a><span class="fu">## Key Concepts Recap</span></span>
<span id="cb17-758"><a href="#cb17-758" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-759"><a href="#cb17-759" aria-hidden="true" tabindex="-1"></a><span class="fu">### Convolutional Layers</span></span>
<span id="cb17-760"><a href="#cb17-760" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-761"><a href="#cb17-761" aria-hidden="true" tabindex="-1"></a>**What they do:**</span>
<span id="cb17-762"><a href="#cb17-762" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Apply learnable filters to extract features</span>
<span id="cb17-763"><a href="#cb17-763" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Preserve spatial relationships</span>
<span id="cb17-764"><a href="#cb17-764" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Translation invariant (feature detected anywhere in image)</span>
<span id="cb17-765"><a href="#cb17-765" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-766"><a href="#cb17-766" aria-hidden="true" tabindex="-1"></a>**Parameters:**</span>
<span id="cb17-767"><a href="#cb17-767" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`filters`</span>: Number of feature maps (32, 64, 128, ...)</span>
<span id="cb17-768"><a href="#cb17-768" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`kernel_size`</span>: Filter dimensions (3×3, 5×5, ...)</span>
<span id="cb17-769"><a href="#cb17-769" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`strides`</span>: Step size (usually 1)</span>
<span id="cb17-770"><a href="#cb17-770" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`padding`</span>: 'valid' (shrinks) or 'same' (maintains size)</span>
<span id="cb17-771"><a href="#cb17-771" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`activation`</span>: Usually ReLU</span>
<span id="cb17-772"><a href="#cb17-772" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-773"><a href="#cb17-773" aria-hidden="true" tabindex="-1"></a><span class="fu">### Pooling Layers</span></span>
<span id="cb17-774"><a href="#cb17-774" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-775"><a href="#cb17-775" aria-hidden="true" tabindex="-1"></a>**Purpose:**</span>
<span id="cb17-776"><a href="#cb17-776" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Reduce spatial dimensions</span>
<span id="cb17-777"><a href="#cb17-777" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Add translation invariance</span>
<span id="cb17-778"><a href="#cb17-778" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Reduce parameters and computation</span>
<span id="cb17-779"><a href="#cb17-779" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-780"><a href="#cb17-780" aria-hidden="true" tabindex="-1"></a>**MaxPooling vs AveragePooling:**</span>
<span id="cb17-781"><a href="#cb17-781" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**MaxPooling:** Keeps strongest activation (most common)</span>
<span id="cb17-782"><a href="#cb17-782" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**AveragePooling:** Smooths response</span>
<span id="cb17-783"><a href="#cb17-783" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Typically 2×2 with stride 2 (halves dimensions)</span>
<span id="cb17-784"><a href="#cb17-784" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-785"><a href="#cb17-785" aria-hidden="true" tabindex="-1"></a><span class="fu">### Activation Functions</span></span>
<span id="cb17-786"><a href="#cb17-786" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-787"><a href="#cb17-787" aria-hidden="true" tabindex="-1"></a>**ReLU (Rectified Linear Unit):**</span>
<span id="cb17-788"><a href="#cb17-788" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="in">`f(x) = max(0, x)`</span></span>
<span id="cb17-789"><a href="#cb17-789" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Most common in hidden layers</span>
<span id="cb17-790"><a href="#cb17-790" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Addresses vanishing gradient problem</span>
<span id="cb17-791"><a href="#cb17-791" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Fast to compute</span>
<span id="cb17-792"><a href="#cb17-792" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-793"><a href="#cb17-793" aria-hidden="true" tabindex="-1"></a>**Softmax:**</span>
<span id="cb17-794"><a href="#cb17-794" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Converts logits to probabilities</span>
<span id="cb17-795"><a href="#cb17-795" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Sum to 1.0</span>
<span id="cb17-796"><a href="#cb17-796" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Used in output layer for multi-class classification</span>
<span id="cb17-797"><a href="#cb17-797" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-798"><a href="#cb17-798" aria-hidden="true" tabindex="-1"></a><span class="fu">### Loss Functions</span></span>
<span id="cb17-799"><a href="#cb17-799" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-800"><a href="#cb17-800" aria-hidden="true" tabindex="-1"></a>**Categorical Cross-Entropy:**</span>
<span id="cb17-801"><a href="#cb17-801" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>For multi-class classification (&gt;2 classes)</span>
<span id="cb17-802"><a href="#cb17-802" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Requires one-hot encoded labels</span>
<span id="cb17-803"><a href="#cb17-803" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Formula: <span class="in">`-Σ y_true * log(y_pred)`</span></span>
<span id="cb17-804"><a href="#cb17-804" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Penalizes confident wrong predictions heavily</span>
<span id="cb17-805"><a href="#cb17-805" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-806"><a href="#cb17-806" aria-hidden="true" tabindex="-1"></a><span class="fu">### Optimizers</span></span>
<span id="cb17-807"><a href="#cb17-807" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-808"><a href="#cb17-808" aria-hidden="true" tabindex="-1"></a>**Adam (Adaptive Moment Estimation):**</span>
<span id="cb17-809"><a href="#cb17-809" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Adaptive learning rate per parameter</span>
<span id="cb17-810"><a href="#cb17-810" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Combines momentum + RMSprop</span>
<span id="cb17-811"><a href="#cb17-811" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Generally robust, good default choice</span>
<span id="cb17-812"><a href="#cb17-812" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Learning rate: 0.001 (default) to 0.0001 (fine-tuning)</span>
<span id="cb17-813"><a href="#cb17-813" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-814"><a href="#cb17-814" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-815"><a href="#cb17-815" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-816"><a href="#cb17-816" aria-hidden="true" tabindex="-1"></a><span class="fu">## Resources</span></span>
<span id="cb17-817"><a href="#cb17-817" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-818"><a href="#cb17-818" aria-hidden="true" tabindex="-1"></a><span class="fu">### Documentation &amp; Tutorials</span></span>
<span id="cb17-819"><a href="#cb17-819" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">TensorFlow Keras Guide</span><span class="co">](https://www.tensorflow.org/guide/keras)</span></span>
<span id="cb17-820"><a href="#cb17-820" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Deep Learning for Computer Vision</span><span class="co">](https://cs231n.github.io/)</span></span>
<span id="cb17-821"><a href="#cb17-821" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">EuroSAT Dataset Paper</span><span class="co">](https://github.com/phelber/EuroSAT)</span></span>
<span id="cb17-822"><a href="#cb17-822" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Transfer Learning Guide</span><span class="co">](https://www.tensorflow.org/tutorials/images/transfer_learning)</span></span>
<span id="cb17-823"><a href="#cb17-823" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-824"><a href="#cb17-824" aria-hidden="true" tabindex="-1"></a><span class="fu">### Pre-trained Models</span></span>
<span id="cb17-825"><a href="#cb17-825" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Keras Applications</span><span class="co">](https://keras.io/api/applications/)</span></span>
<span id="cb17-826"><a href="#cb17-826" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">TensorFlow Hub</span><span class="co">](https://tfhub.dev/)</span></span>
<span id="cb17-827"><a href="#cb17-827" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">Model Zoo</span><span class="co">](https://modelzoo.co/)</span></span>
<span id="cb17-828"><a href="#cb17-828" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-829"><a href="#cb17-829" aria-hidden="true" tabindex="-1"></a><span class="fu">### Philippine EO Resources</span></span>
<span id="cb17-830"><a href="#cb17-830" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">PhilSA Space+ Data</span><span class="co">](https://data.philsa.gov.ph/)</span></span>
<span id="cb17-831"><a href="#cb17-831" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">DOST-ASTI Panda</span><span class="co">](https://panda.stamina4space.upd.edu.ph/)</span></span>
<span id="cb17-832"><a href="#cb17-832" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="co">[</span><span class="ot">NAMRIA Geoportal</span><span class="co">](https://www.namria.gov.ph/geoportal.html)</span></span>
<span id="cb17-833"><a href="#cb17-833" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-834"><a href="#cb17-834" aria-hidden="true" tabindex="-1"></a><span class="fu">### Course Materials</span></span>
<span id="cb17-835"><a href="#cb17-835" aria-hidden="true" tabindex="-1"></a>::: {.quick-links}</span>
<span id="cb17-836"><a href="#cb17-836" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">← Back to Session 3</span><span class="co">](session3.qmd)</span>{.quick-link}</span>
<span id="cb17-837"><a href="#cb17-837" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Day 2 Overview</span><span class="co">](../index.qmd)</span>{.quick-link}</span>
<span id="cb17-838"><a href="#cb17-838" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Lab Notebook</span><span class="co">](../notebooks/session4_cnn_classification_STUDENT.ipynb)</span>{.quick-link}</span>
<span id="cb17-839"><a href="#cb17-839" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Setup Guide</span><span class="co">](../../resources/setup.qmd)</span>{.quick-link}</span>
<span id="cb17-840"><a href="#cb17-840" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">FAQ</span><span class="co">](../../resources/faq.qmd)</span>{.quick-link}</span>
<span id="cb17-841"><a href="#cb17-841" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-842"><a href="#cb17-842" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-843"><a href="#cb17-843" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-844"><a href="#cb17-844" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-845"><a href="#cb17-845" aria-hidden="true" tabindex="-1"></a><span class="fu">## Next Steps</span></span>
<span id="cb17-846"><a href="#cb17-846" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-847"><a href="#cb17-847" aria-hidden="true" tabindex="-1"></a>::: {.callout-note}</span>
<span id="cb17-848"><a href="#cb17-848" aria-hidden="true" tabindex="-1"></a><span class="fu">## What Comes After Session 4?</span></span>
<span id="cb17-849"><a href="#cb17-849" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-850"><a href="#cb17-850" aria-hidden="true" tabindex="-1"></a>**Immediate:**</span>
<span id="cb17-851"><a href="#cb17-851" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Complete all exercises in the notebook</span>
<span id="cb17-852"><a href="#cb17-852" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Experiment with different architectures</span>
<span id="cb17-853"><a href="#cb17-853" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Try your own hyperparameter combinations</span>
<span id="cb17-854"><a href="#cb17-854" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Apply to Philippine imagery (optional challenge)</span>
<span id="cb17-855"><a href="#cb17-855" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-856"><a href="#cb17-856" aria-hidden="true" tabindex="-1"></a>**Day 3 Preview:**</span>
<span id="cb17-857"><a href="#cb17-857" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**U-Net for Semantic Segmentation:** Pixel-level land cover classification</span>
<span id="cb17-858"><a href="#cb17-858" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Flood Mapping Case Study:** Central Luzon with Sentinel-1 SAR</span>
<span id="cb17-859"><a href="#cb17-859" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Object Detection:** Metro Manila building/settlement detection</span>
<span id="cb17-860"><a href="#cb17-860" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Advanced Architectures:** Deeper networks, attention mechanisms</span>
<span id="cb17-861"><a href="#cb17-861" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-862"><a href="#cb17-862" aria-hidden="true" tabindex="-1"></a>**Preparation for Day 3:**</span>
<span id="cb17-863"><a href="#cb17-863" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Ensure you understand CNN fundamentals</span>
<span id="cb17-864"><a href="#cb17-864" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Be comfortable with TensorFlow/Keras syntax</span>
<span id="cb17-865"><a href="#cb17-865" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Know how to debug training issues</span>
<span id="cb17-866"><a href="#cb17-866" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Understand when to use different architectures</span>
<span id="cb17-867"><a href="#cb17-867" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-868"><a href="#cb17-868" aria-hidden="true" tabindex="-1"></a><span class="co">[</span><span class="ot">Preview Day 3 →</span><span class="co">](../../day3/index.qmd)</span>{.btn .btn-outline-primary}</span>
<span id="cb17-869"><a href="#cb17-869" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-870"><a href="#cb17-870" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-871"><a href="#cb17-871" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-872"><a href="#cb17-872" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-873"><a href="#cb17-873" aria-hidden="true" tabindex="-1"></a><span class="fu">## Assessment &amp; Exercises</span></span>
<span id="cb17-874"><a href="#cb17-874" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-875"><a href="#cb17-875" aria-hidden="true" tabindex="-1"></a><span class="fu">### Formative Assessment (In-Notebook)</span></span>
<span id="cb17-876"><a href="#cb17-876" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> Successfully configure GPU environment</span>
<span id="cb17-877"><a href="#cb17-877" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> Load and visualize EuroSAT dataset</span>
<span id="cb17-878"><a href="#cb17-878" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> Build CNN architecture from scratch</span>
<span id="cb17-879"><a href="#cb17-879" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> Train model to &gt;90% accuracy</span>
<span id="cb17-880"><a href="#cb17-880" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> Generate confusion matrix</span>
<span id="cb17-881"><a href="#cb17-881" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> Implement transfer learning with ResNet50</span>
<span id="cb17-882"><a href="#cb17-882" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span><span class="va">[ ]</span> Compare results from-scratch vs transfer learning</span>
<span id="cb17-883"><a href="#cb17-883" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-884"><a href="#cb17-884" aria-hidden="true" tabindex="-1"></a><span class="fu">### Challenge Exercises</span></span>
<span id="cb17-885"><a href="#cb17-885" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-886"><a href="#cb17-886" aria-hidden="true" tabindex="-1"></a>**Exercise 1: Architecture Design**</span>
<span id="cb17-887"><a href="#cb17-887" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Modify the CNN to have 4 convolutional blocks instead of 3</span>
<span id="cb17-888"><a href="#cb17-888" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Add batch normalization after each convolution</span>
<span id="cb17-889"><a href="#cb17-889" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Compare training speed and final accuracy</span>
<span id="cb17-890"><a href="#cb17-890" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-891"><a href="#cb17-891" aria-hidden="true" tabindex="-1"></a>**Exercise 2: Hyperparameter Tuning**</span>
<span id="cb17-892"><a href="#cb17-892" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Test learning rates: <span class="co">[</span><span class="ot">0.001, 0.0001, 0.00001</span><span class="co">]</span></span>
<span id="cb17-893"><a href="#cb17-893" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Test batch sizes: <span class="co">[</span><span class="ot">16, 32, 64</span><span class="co">]</span></span>
<span id="cb17-894"><a href="#cb17-894" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Find optimal combination for fastest convergence</span>
<span id="cb17-895"><a href="#cb17-895" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-896"><a href="#cb17-896" aria-hidden="true" tabindex="-1"></a>**Exercise 3: Advanced Augmentation**</span>
<span id="cb17-897"><a href="#cb17-897" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Add RandomBrightness and RandomContrast</span>
<span id="cb17-898"><a href="#cb17-898" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Implement mixup augmentation</span>
<span id="cb17-899"><a href="#cb17-899" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Measure impact on validation accuracy</span>
<span id="cb17-900"><a href="#cb17-900" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-901"><a href="#cb17-901" aria-hidden="true" tabindex="-1"></a>**Exercise 4: Multi-spectral CNN** (Advanced)</span>
<span id="cb17-902"><a href="#cb17-902" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Load EuroSAT 13-band version</span>
<span id="cb17-903"><a href="#cb17-903" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Modify input layer to accept all bands</span>
<span id="cb17-904"><a href="#cb17-904" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Compare RGB vs multi-spectral performance</span>
<span id="cb17-905"><a href="#cb17-905" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-906"><a href="#cb17-906" aria-hidden="true" tabindex="-1"></a>**Exercise 5: Philippine Application** (Capstone)</span>
<span id="cb17-907"><a href="#cb17-907" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Apply trained model to Palawan Sentinel-2 patches</span>
<span id="cb17-908"><a href="#cb17-908" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Compare predictions with Session 2 Random Forest</span>
<span id="cb17-909"><a href="#cb17-909" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Identify areas where CNN performs better/worse</span>
<span id="cb17-910"><a href="#cb17-910" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-911"><a href="#cb17-911" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-912"><a href="#cb17-912" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-913"><a href="#cb17-913" aria-hidden="true" tabindex="-1"></a>::: {.callout-tip collapse="true"}</span>
<span id="cb17-914"><a href="#cb17-914" aria-hidden="true" tabindex="-1"></a><span class="fu">## 💡 Instructor Notes</span></span>
<span id="cb17-915"><a href="#cb17-915" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-916"><a href="#cb17-916" aria-hidden="true" tabindex="-1"></a>**Timing Management:**</span>
<span id="cb17-917"><a href="#cb17-917" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Part A (Setup &amp; Data):** Can take 35-40 min if students unfamiliar with Colab GPU setup</span>
<span id="cb17-918"><a href="#cb17-918" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Part B (Build CNN):** Usually 40-45 min, architecture design is tricky for beginners</span>
<span id="cb17-919"><a href="#cb17-919" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Part C (Training):** 30-40 min including watching training live</span>
<span id="cb17-920"><a href="#cb17-920" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Part D (Evaluation):** 25-30 min, confusion matrix analysis takes time</span>
<span id="cb17-921"><a href="#cb17-921" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Part E (Transfer Learning):** 15-20 min, can be shortened if running behind</span>
<span id="cb17-922"><a href="#cb17-922" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Part F (Philippine Context):** 10-15 min discussion</span>
<span id="cb17-923"><a href="#cb17-923" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-924"><a href="#cb17-924" aria-hidden="true" tabindex="-1"></a>**Common Student Questions:**</span>
<span id="cb17-925"><a href="#cb17-925" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"Why is my GPU not detected?" → Check runtime type, may need reconnect</span>
<span id="cb17-926"><a href="#cb17-926" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"Training is very slow on CPU" → Emphasize GPU requirement, show how to enable</span>
<span id="cb17-927"><a href="#cb17-927" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"What batch size should I use?" → Start with 32, reduce if OOM errors</span>
<span id="cb17-928"><a href="#cb17-928" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"Why transfer learning?" → Explain data efficiency, show time savings</span>
<span id="cb17-929"><a href="#cb17-929" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>"Can I use PyTorch instead?" → Yes, but maintain focus; TensorFlow for consistency</span>
<span id="cb17-930"><a href="#cb17-930" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-931"><a href="#cb17-931" aria-hidden="true" tabindex="-1"></a>**Teaching Tips:**</span>
<span id="cb17-932"><a href="#cb17-932" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Live demo:** Train a model while explaining (use simple architecture for speed)</span>
<span id="cb17-933"><a href="#cb17-933" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Show failures:** Demonstrate overfitting, then fix it</span>
<span id="cb17-934"><a href="#cb17-934" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Visualize:** Use TensorBoard or matplotlib for learning curves in real-time</span>
<span id="cb17-935"><a href="#cb17-935" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Pause for training:** Use 5-10 min training time for Q&amp;A or breaks</span>
<span id="cb17-936"><a href="#cb17-936" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>**Compare with RF:** Reinforce why we learned both approaches</span>
<span id="cb17-937"><a href="#cb17-937" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-938"><a href="#cb17-938" aria-hidden="true" tabindex="-1"></a>**Technical Preparation:**</span>
<span id="cb17-939"><a href="#cb17-939" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Pre-download EuroSAT to Google Drive as backup</span>
<span id="cb17-940"><a href="#cb17-940" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Test notebook 24 hours before session</span>
<span id="cb17-941"><a href="#cb17-941" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Have pre-trained models ready in case training fails</span>
<span id="cb17-942"><a href="#cb17-942" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Prepare troubleshooting guide printout</span>
<span id="cb17-943"><a href="#cb17-943" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Test on both GPU and CPU for comparison</span>
<span id="cb17-944"><a href="#cb17-944" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-945"><a href="#cb17-945" aria-hidden="true" tabindex="-1"></a>**Extension Activities for Fast Finishers:**</span>
<span id="cb17-946"><a href="#cb17-946" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Implement ensemble of multiple CNNs</span>
<span id="cb17-947"><a href="#cb17-947" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Try different pre-trained models (EfficientNet, MobileNet)</span>
<span id="cb17-948"><a href="#cb17-948" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Explore GradCAM for visualization</span>
<span id="cb17-949"><a href="#cb17-949" aria-hidden="true" tabindex="-1"></a><span class="ss">- </span>Start Day 3 preview material</span>
<span id="cb17-950"><a href="#cb17-950" aria-hidden="true" tabindex="-1"></a>:::</span>
<span id="cb17-951"><a href="#cb17-951" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-952"><a href="#cb17-952" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb17-953"><a href="#cb17-953" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-954"><a href="#cb17-954" aria-hidden="true" tabindex="-1"></a>*This session is part of the CoPhil 4-Day Advanced Training on AI/ML for Earth Observation, funded by the European Union under the Global Gateway initiative and delivered in partnership with PhilSA and DOST.*</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></div>
</div></div></div></div></div>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
<p>CoPhil EO AI/ML Training Programme</p>
</div>   
    <div class="nav-footer-center">
<p>Funded by the European Union - Global Gateway Initiative</p>
</div>
    <div class="nav-footer-right">
      <ul class="footer-items list-unstyled">
    <li class="nav-item compact">
    <a class="nav-link" href="mailto:info@philsa.gov.ph">
      <i class="bi bi-envelope" role="img">
</i> 
    </a>
  </li>  
    <li class="nav-item compact">
    <a class="nav-link" href="https://philsa.gov.ph">
      <i class="bi bi-globe" role="img">
</i> 
    </a>
  </li>  
</ul>
    </div>
  </div>
</footer>




<script src="../../site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>