{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4, Session 1: LSTMs for Earth Observation Time Series\n",
    "## INSTRUCTOR VERSION - Complete Solutions\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this session, you will be able to:\n",
    "1. **Understand** the importance of time series analysis in Earth Observation\n",
    "2. **Explain** why RNNs face challenges with long sequences (vanishing/exploding gradients)\n",
    "3. **Describe** LSTM architecture and how gates solve RNN limitations\n",
    "4. **Implement** an LSTM model for drought prediction using NDVI time series\n",
    "5. **Apply** LSTMs to Philippine EO challenges (Mindanao drought monitoring)\n",
    "\n",
    "## üìã Session Overview\n",
    "\n",
    "- **Duration**: 1.5 hours\n",
    "- **Prerequisites**: Basic understanding of neural networks (from Day 3)\n",
    "- **Application Focus**: Drought monitoring in Mindanao agricultural regions\n",
    "- **Key Dataset**: Simulated Sentinel-2 NDVI time series (2019-2024)\n",
    "\n",
    "---\n",
    "\n",
    "## üåç Philippine Context\n",
    "\n",
    "The Philippines experiences significant climate variability, with El Ni√±o events causing severe droughts, particularly affecting Mindanao's agricultural regions. PAGASA reports that drought events have increased in frequency and intensity, making early warning systems critical for:\n",
    "- **Food security** in Bukidnon and South Cotabato\n",
    "- **Water resource management** for irrigation systems\n",
    "- **Agricultural planning** and crop insurance programs\n",
    "\n",
    "Time series analysis of satellite-derived vegetation indices enables us to detect early drought signals and predict future conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Module 1: Introduction to Time Series in Earth Observation\n",
    "\n",
    "### What are EO Time Series?\n",
    "\n",
    "Earth Observation time series are sequences of measurements taken at regular intervals from the same location. Common examples include:\n",
    "\n",
    "1. **NDVI (Normalized Difference Vegetation Index)**: Measures vegetation health\n",
    "   - Range: -1 to +1 (higher values = healthier vegetation)\n",
    "   - Sentinel-2 provides 5-day revisit time\n",
    "   \n",
    "2. **SAR Backscatter**: Radar signal strength indicating surface properties\n",
    "   - Sentinel-1 provides 6-12 day revisit\n",
    "   - Sensitive to soil moisture and vegetation structure\n",
    "\n",
    "3. **Land Surface Temperature**: Thermal measurements from satellites\n",
    "   - Critical for drought and heat stress monitoring\n",
    "\n",
    "### Why Time Series Matter for Philippine EO Applications\n",
    "\n",
    "- **Phenology Tracking**: Monitor rice cropping calendars in Central Luzon\n",
    "- **Drought Detection**: Early warning for Mindanao agricultural zones\n",
    "- **Land Change Detection**: Urban expansion in Metro Manila\n",
    "- **Disaster Impact Assessment**: Pre/post typhoon vegetation analysis\n",
    "\n",
    "### üí≠ Think-Through Discussion\n",
    "\n",
    "**Question**: How might seasonal patterns in NDVI differ between irrigated rice fields in Nueva Ecija and rainfed corn farms in Bukidnon? What implications does this have for drought monitoring?\n",
    "\n",
    "**Answer**: Irrigated rice fields show consistent NDVI patterns following cropping calendars, while rainfed farms are more sensitive to precipitation variability. This means drought detection thresholds must be location-specific and consider irrigation infrastructure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Setup and Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# TensorFlow and Keras imports\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Scikit-learn for preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure matplotlib for better visualizations\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(\"Setup complete! üöÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Data Generation: Simulating Realistic NDVI Time Series\n",
    "\n",
    "We'll create a synthetic but realistic NDVI time series that mimics conditions in Bukidnon, Mindanao:\n",
    "- Normal seasonal patterns (wet/dry seasons)\n",
    "- El Ni√±o drought events (2019, 2023)\n",
    "- Random variations and noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mindanao_ndvi_timeseries(start_date='2019-01-01', end_date='2024-12-31', \n",
    "                                      location='Bukidnon'):\n",
    "    \"\"\"\n",
    "    Generate synthetic NDVI time series mimicking Mindanao agricultural patterns.\n",
    "    Includes seasonal variations, drought events, and realistic noise.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    start_date : str\n",
    "        Start date of the time series\n",
    "    end_date : str\n",
    "        End date of the time series\n",
    "    location : str\n",
    "        Location name for reference\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with date, NDVI, precipitation, and drought index\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create date range (10-day composites, similar to Sentinel-2)\n",
    "    dates = pd.date_range(start=start_date, end=end_date, freq='10D')\n",
    "    n_samples = len(dates)\n",
    "    \n",
    "    # Initialize arrays\n",
    "    ndvi = np.zeros(n_samples)\n",
    "    precipitation = np.zeros(n_samples)\n",
    "    \n",
    "    # Base NDVI for healthy vegetation in Mindanao\n",
    "    base_ndvi = 0.75\n",
    "    \n",
    "    for i, date in enumerate(dates):\n",
    "        # Seasonal component (wet season: Nov-Apr, dry season: May-Oct)\n",
    "        month = date.month\n",
    "        if month in [11, 12, 1, 2, 3, 4]:  # Wet season\n",
    "            seasonal_factor = 0.85 + 0.1 * np.sin(2 * np.pi * month / 12)\n",
    "            precip_base = 250 + 50 * np.random.randn()  # mm/month\n",
    "        else:  # Dry season\n",
    "            seasonal_factor = 0.7 + 0.05 * np.sin(2 * np.pi * month / 12)\n",
    "            precip_base = 100 + 30 * np.random.randn()  # mm/month\n",
    "        \n",
    "        # El Ni√±o drought events (2019 Q2-Q3, 2023 Q1-Q2)\n",
    "        drought_factor = 1.0\n",
    "        if (date.year == 2019 and 4 <= month <= 9) or \\\n",
    "           (date.year == 2023 and 2 <= month <= 7):\n",
    "            drought_factor = 0.6 + 0.2 * np.random.random()\n",
    "            precip_base *= 0.4  # Reduced precipitation during drought\n",
    "        \n",
    "        # Calculate NDVI with noise\n",
    "        ndvi[i] = base_ndvi * seasonal_factor * drought_factor\n",
    "        ndvi[i] += np.random.normal(0, 0.03)  # Add noise\n",
    "        ndvi[i] = np.clip(ndvi[i], 0.1, 0.95)  # Realistic bounds\n",
    "        \n",
    "        # Calculate precipitation\n",
    "        precipitation[i] = max(0, precip_base)\n",
    "    \n",
    "    # Smooth the time series (moving average)\n",
    "    window = 3\n",
    "    ndvi_smooth = pd.Series(ndvi).rolling(window=window, center=True).mean()\n",
    "    ndvi_smooth = ndvi_smooth.fillna(method='bfill').fillna(method='ffill')\n",
    "    \n",
    "    # Calculate drought index (simplified: based on NDVI deviation from normal)\n",
    "    ndvi_mean = ndvi_smooth.rolling(window=36, center=True).mean().fillna(method='bfill').fillna(method='ffill')\n",
    "    drought_index = (ndvi_smooth - ndvi_mean) / ndvi_mean.std()\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'ndvi': ndvi_smooth.values,\n",
    "        'precipitation': precipitation,\n",
    "        'drought_index': drought_index.values,\n",
    "        'location': location\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate data for Bukidnon, Mindanao\n",
    "df_mindanao = generate_mindanao_ndvi_timeseries()\n",
    "print(f\"Generated {len(df_mindanao)} time points of NDVI data\")\n",
    "print(f\"Date range: {df_mindanao['date'].min()} to {df_mindanao['date'].max()}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df_mindanao.head())\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(df_mindanao[['ndvi', 'precipitation', 'drought_index']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Visualizing the Time Series Data\n",
    "\n",
    "Let's visualize our NDVI time series to understand the patterns, including the drought events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "# Plot 1: NDVI Time Series\n",
    "ax1 = axes[0]\n",
    "ax1.plot(df_mindanao['date'], df_mindanao['ndvi'], 'g-', linewidth=1.5, label='NDVI')\n",
    "ax1.axhline(y=df_mindanao['ndvi'].mean(), color='gray', linestyle='--', alpha=0.5, label='Mean NDVI')\n",
    "\n",
    "# Highlight drought periods\n",
    "drought_periods = [\n",
    "    ('2019-04-01', '2019-09-30', '2019 El Ni√±o'),\n",
    "    ('2023-02-01', '2023-07-31', '2023 El Ni√±o')\n",
    "]\n",
    "for start, end, label in drought_periods:\n",
    "    ax1.axvspan(pd.to_datetime(start), pd.to_datetime(end), alpha=0.2, color='orange', label=label)\n",
    "\n",
    "ax1.set_ylabel('NDVI', fontsize=11)\n",
    "ax1.set_title('NDVI Time Series for Bukidnon, Mindanao (2019-2024)', fontsize=12, fontweight='bold')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.set_ylim([0.2, 0.9])\n",
    "\n",
    "# Plot 2: Precipitation\n",
    "ax2 = axes[1]\n",
    "ax2.bar(df_mindanao['date'], df_mindanao['precipitation'], color='blue', alpha=0.6, width=8)\n",
    "ax2.set_ylabel('Precipitation (mm)', fontsize=11)\n",
    "ax2.set_title('Precipitation Patterns', fontsize=11)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Drought Index\n",
    "ax3 = axes[2]\n",
    "colors = ['red' if x < -1 else 'orange' if x < 0 else 'green' for x in df_mindanao['drought_index']]\n",
    "ax3.scatter(df_mindanao['date'], df_mindanao['drought_index'], c=colors, alpha=0.6, s=10)\n",
    "ax3.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax3.axhline(y=-1, color='red', linestyle='--', alpha=0.5, label='Drought threshold')\n",
    "ax3.set_ylabel('Drought Index', fontsize=11)\n",
    "ax3.set_xlabel('Date', fontsize=11)\n",
    "ax3.set_title('Drought Index (Negative values indicate drought stress)', fontsize=11)\n",
    "ax3.legend(loc='upper right')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print drought statistics\n",
    "drought_days = (df_mindanao['drought_index'] < -1).sum()\n",
    "print(f\"\\nüìä Drought Statistics:\")\n",
    "print(f\"Total days with severe drought (index < -1): {drought_days}\")\n",
    "print(f\"Percentage of time in drought: {drought_days/len(df_mindanao)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Module 2: Understanding RNNs and Their Limitations\n",
    "\n",
    "### Recurrent Neural Networks (RNNs) Basics\n",
    "\n",
    "RNNs are designed to work with sequential data by maintaining a **hidden state** that acts as memory:\n",
    "\n",
    "$$h_t = \\tanh(W_{hh} \\cdot h_{t-1} + W_{xh} \\cdot x_t + b_h)$$\n",
    "$$y_t = W_{hy} \\cdot h_t + b_y$$\n",
    "\n",
    "Where:\n",
    "- $h_t$: hidden state at time $t$\n",
    "- $x_t$: input at time $t$\n",
    "- $W_{hh}, W_{xh}, W_{hy}$: weight matrices\n",
    "- $b_h, b_y$: bias terms\n",
    "\n",
    "### The Vanishing Gradient Problem\n",
    "\n",
    "During backpropagation through time, gradients are multiplied repeatedly:\n",
    "\n",
    "**Example**: If gradient = 0.5 at each step:\n",
    "- After 10 steps: $0.5^{10} ‚âà 0.001$\n",
    "- After 50 steps: $0.5^{50} ‚âà 8.9 \\times 10^{-16}$ (essentially zero!)\n",
    "\n",
    "This means the network **cannot learn long-term dependencies**.\n",
    "\n",
    "### The Exploding Gradient Problem\n",
    "\n",
    "Conversely, if gradient = 1.5 at each step:\n",
    "- After 10 steps: $1.5^{10} ‚âà 58$\n",
    "- After 50 steps: $1.5^{50} ‚âà 6.4 \\times 10^{8}$ (numerical overflow!)\n",
    "\n",
    "This causes **unstable training** and NaN values.\n",
    "\n",
    "### üéØ Mini-Challenge 1 - SOLUTION\n",
    "\n",
    "**Task**: Calculate how many time steps it takes for a gradient of 0.9 to shrink below 0.01. What does this mean for analyzing a year of monthly NDVI data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Mini-Challenge 1 - Calculate gradient vanishing\n",
    "gradient_factor = 0.9\n",
    "threshold = 0.01\n",
    "\n",
    "# Method 1: Using a loop\n",
    "steps = 0\n",
    "current_gradient = gradient_factor\n",
    "while current_gradient >= threshold:\n",
    "    current_gradient *= gradient_factor\n",
    "    steps += 1\n",
    "\n",
    "print(f\"Gradient shrinks below {threshold} after {steps} steps\")\n",
    "print(f\"For monthly data, this means we can only learn patterns from the last {steps} months\")\n",
    "print(f\"\\nüìä Implications:\")\n",
    "print(f\"  - A vanilla RNN would struggle to connect a drought event to conditions {steps} months earlier\")\n",
    "print(f\"  - This is why LSTMs are crucial for long-term time series analysis\")\n",
    "\n",
    "# Method 2: Using logarithm (more elegant)\n",
    "import math\n",
    "steps_math = math.ceil(math.log(threshold) / math.log(gradient_factor))\n",
    "print(f\"\\n‚úì Verification using logarithm: {steps_math} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèóÔ∏è Module 3: LSTM Architecture - The Solution\n",
    "\n",
    "### The LSTM Cell: A Smart Memory System\n",
    "\n",
    "LSTMs solve the gradient problems through a sophisticated gating mechanism. Think of an LSTM as a **smart student taking notes during a lecture**:\n",
    "\n",
    "1. **Forget Gate**: Decides what old information to discard\n",
    "2. **Input Gate**: Determines what new information to store\n",
    "3. **Output Gate**: Controls what information to pass forward\n",
    "4. **Cell State**: The \"notebook\" carrying information through time\n",
    "\n",
    "### Mathematical Formulation\n",
    "\n",
    "The LSTM operations at time step $t$:\n",
    "\n",
    "**Forget Gate**: $f_t = \\sigma(W_f \\cdot [h_{t-1}, x_t] + b_f)$\n",
    "\n",
    "**Input Gate**: $i_t = \\sigma(W_i \\cdot [h_{t-1}, x_t] + b_i)$\n",
    "\n",
    "**Candidate Values**: $\\tilde{C}_t = \\tanh(W_C \\cdot [h_{t-1}, x_t] + b_C)$\n",
    "\n",
    "**Cell State Update**: $C_t = f_t * C_{t-1} + i_t * \\tilde{C}_t$\n",
    "\n",
    "**Output Gate**: $o_t = \\sigma(W_o \\cdot [h_{t-1}, x_t] + b_o)$\n",
    "\n",
    "**Hidden State**: $h_t = o_t * \\tanh(C_t)$\n",
    "\n",
    "Where $\\sigma$ is the sigmoid function (outputs 0-1) and $*$ is element-wise multiplication.\n",
    "\n",
    "### Why LSTMs Work\n",
    "\n",
    "The **cell state** $C_t$ acts as a \"conveyor belt\" that can carry information unchanged across many time steps. The gates (using sigmoid activation) produce values between 0 and 1, acting as \"valves\" that control information flow without causing gradient explosion or vanishing.\n",
    "\n",
    "### üí≠ Think-Through Discussion - ANSWER\n",
    "\n",
    "**Question**: In drought monitoring, what kind of information might the \"forget gate\" discard and what might the \"input gate\" preserve? Think about seasonal patterns vs. anomalies.\n",
    "\n",
    "**Answer**: The forget gate might discard routine seasonal variations once they're learned, while the input gate would preserve anomalous drought signals. During a drought event, the input gate opens wide to capture the unusual low NDVI values, and the output gate ensures this critical information is propagated forward for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize LSTM Architecture Conceptually\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "def visualize_lstm_concept():\n",
    "    \"\"\"\n",
    "    Create a conceptual visualization of LSTM information flow.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Left plot: RNN vs LSTM gradient flow\n",
    "    time_steps = np.arange(0, 50)\n",
    "    rnn_gradient = 0.9 ** time_steps\n",
    "    lstm_gradient = 0.95 ** time_steps  # LSTMs maintain gradients better\n",
    "    \n",
    "    ax1.plot(time_steps, rnn_gradient, 'r-', label='Vanilla RNN', linewidth=2)\n",
    "    ax1.plot(time_steps, lstm_gradient, 'b-', label='LSTM', linewidth=2)\n",
    "    ax1.axhline(y=0.01, color='gray', linestyle='--', alpha=0.5, label='Effective threshold')\n",
    "    ax1.set_xlabel('Time Steps', fontsize=11)\n",
    "    ax1.set_ylabel('Gradient Magnitude', fontsize=11)\n",
    "    ax1.set_title('Gradient Flow: RNN vs LSTM', fontsize=12, fontweight='bold')\n",
    "    ax1.set_yscale('log')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Right plot: LSTM gates behavior simulation\n",
    "    time = np.linspace(0, 24, 100)  # 24 months\n",
    "    \n",
    "    # Simulate gate activations during drought event\n",
    "    normal_period = (time < 6) | (time > 18)\n",
    "    drought_period = (time >= 6) & (time <= 18)\n",
    "    \n",
    "    forget_gate = np.where(normal_period, 0.8, 0.3)  # Forget more during normal times\n",
    "    input_gate = np.where(drought_period, 0.9, 0.4)   # Store more during drought\n",
    "    output_gate = np.where(drought_period, 0.95, 0.6) # Output more during drought\n",
    "    \n",
    "    # Add some smooth transitions\n",
    "    forget_gate = gaussian_filter1d(forget_gate, sigma=2)\n",
    "    input_gate = gaussian_filter1d(input_gate, sigma=2)\n",
    "    output_gate = gaussian_filter1d(output_gate, sigma=2)\n",
    "    \n",
    "    ax2.plot(time, forget_gate, 'r-', label='Forget Gate', linewidth=2)\n",
    "    ax2.plot(time, input_gate, 'g-', label='Input Gate', linewidth=2)\n",
    "    ax2.plot(time, output_gate, 'b-', label='Output Gate', linewidth=2)\n",
    "    ax2.axvspan(6, 18, alpha=0.2, color='orange', label='Drought Period')\n",
    "    ax2.set_xlabel('Time (months)', fontsize=11)\n",
    "    ax2.set_ylabel('Gate Activation (0-1)', fontsize=11)\n",
    "    ax2.set_title('LSTM Gates During Drought Monitoring', fontsize=12, fontweight='bold')\n",
    "    ax2.legend(loc='right')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_ylim([0, 1])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_lstm_concept()\n",
    "\n",
    "print(\"üîç Key Insights:\")\n",
    "print(\"1. LSTMs maintain gradient flow much better than vanilla RNNs\")\n",
    "print(\"2. During drought events, the input and output gates open more to capture and propagate anomaly information\")\n",
    "print(\"3. The forget gate reduces during drought to preserve important drought signals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîß Data Preparation for LSTM\n",
    "\n",
    "LSTMs require data in a specific format: sequences of fixed length. We'll create sliding windows from our time series.\n",
    "\n",
    "### Sliding Window Approach\n",
    "\n",
    "For drought prediction, we'll use:\n",
    "- **Input**: 12 months of historical NDVI values\n",
    "- **Output**: Next month's NDVI value\n",
    "\n",
    "Example:\n",
    "```\n",
    "Window 1: Months 1-12 ‚Üí Predict Month 13\n",
    "Window 2: Months 2-13 ‚Üí Predict Month 14\n",
    "Window 3: Months 3-14 ‚Üí Predict Month 15\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length=12, prediction_horizon=1):\n",
    "    \"\"\"\n",
    "    Create sequences for LSTM training.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : np.array\n",
    "        Time series data\n",
    "    seq_length : int\n",
    "        Number of time steps to use as input\n",
    "    prediction_horizon : int\n",
    "        Number of time steps ahead to predict\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    X, y : np.arrays\n",
    "        Input sequences and targets\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(data) - seq_length - prediction_horizon + 1):\n",
    "        # Input sequence\n",
    "        X.append(data[i:i + seq_length])\n",
    "        # Target value\n",
    "        y.append(data[i + seq_length + prediction_horizon - 1])\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Prepare NDVI data\n",
    "ndvi_values = df_mindanao['ndvi'].values.reshape(-1, 1)\n",
    "\n",
    "# Normalize data (important for neural networks)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "ndvi_scaled = scaler.fit_transform(ndvi_values)\n",
    "\n",
    "# Create sequences\n",
    "SEQ_LENGTH = 12  # Use 12 time steps (120 days) to predict next time step\n",
    "X, y = create_sequences(ndvi_scaled, seq_length=SEQ_LENGTH)\n",
    "\n",
    "print(f\"üì¶ Data Shape:\")\n",
    "print(f\"Input sequences (X): {X.shape}\")\n",
    "print(f\"Target values (y): {y.shape}\")\n",
    "print(f\"\\nExample:\")\n",
    "print(f\"First input sequence (scaled): {X[0].flatten()[:5]}... (showing first 5 values)\")\n",
    "print(f\"Corresponding target: {y[0]}\")\n",
    "\n",
    "# Split into training and validation sets\n",
    "split_index = int(0.8 * len(X))\n",
    "X_train, X_val = X[:split_index], X[split_index:]\n",
    "y_train, y_val = y[:split_index], y[split_index:]\n",
    "\n",
    "print(f\"\\nüìä Dataset Split:\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Mini-Challenge 2 - SOLUTION: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Mini-Challenge 2 - Analyze the sequences\n",
    "# Task: Find and visualize a sequence that leads to a drought (low NDVI) prediction\n",
    "\n",
    "drought_indices = np.where(y_train < 0.3)[0]\n",
    "if len(drought_indices) > 0:\n",
    "    drought_idx = drought_indices[0]\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Plot the sequence leading to drought\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(SEQ_LENGTH), X_train[drought_idx], 'b-o', label='Input sequence', linewidth=2)\n",
    "    plt.axvline(x=SEQ_LENGTH-0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "    plt.plot(SEQ_LENGTH, y_train[drought_idx], 'ro', markersize=12, label='Predicted drought', zorder=5)\n",
    "    plt.xlabel('Time Step')\n",
    "    plt.ylabel('Scaled NDVI')\n",
    "    plt.title('Sequence Leading to Drought Prediction')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot distribution of target values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(y_train, bins=50, alpha=0.7, color='green', edgecolor='black')\n",
    "    plt.axvline(x=0.3, color='red', linestyle='--', linewidth=2, label='Drought threshold')\n",
    "    plt.axvline(x=y_train[drought_idx], color='orange', linestyle='--', linewidth=2, label='Example drought value')\n",
    "    plt.xlabel('Scaled NDVI')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Target NDVI Values')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nüìä Analysis:\")\n",
    "    print(f\"Found {len(drought_indices)} sequences leading to drought\")\n",
    "    print(f\"Drought threshold (scaled): 0.3\")\n",
    "    print(f\"Example drought prediction: {y_train[drought_idx][0]:.4f}\")\n",
    "    print(f\"Mean of input sequence: {X_train[drought_idx].mean():.4f}\")\n",
    "    print(f\"Trend (last - first): {(X_train[drought_idx][-1] - X_train[drought_idx][0])[0]:.4f}\")\n",
    "else:\n",
    "    print(\"No severe drought events found in training data (threshold: 0.3)\")\n",
    "    print(\"Try a higher threshold (e.g., 0.4) to find drought examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèõÔ∏è Building the LSTM Model\n",
    "\n",
    "Now let's build our LSTM model for drought prediction. We'll use an architecture suitable for time series forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(seq_length, n_features=1, lstm_units=[64, 32], \n",
    "                    dropout_rate=0.2, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Build an LSTM model for time series prediction.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    seq_length : int\n",
    "        Length of input sequences\n",
    "    n_features : int\n",
    "        Number of features per time step\n",
    "    lstm_units : list\n",
    "        Number of units in each LSTM layer\n",
    "    dropout_rate : float\n",
    "        Dropout rate for regularization\n",
    "    learning_rate : float\n",
    "        Learning rate for Adam optimizer\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    model : keras.Model\n",
    "        Compiled LSTM model\n",
    "    \"\"\"\n",
    "    \n",
    "    model = Sequential([\n",
    "        # First LSTM layer with return sequences\n",
    "        LSTM(lstm_units[0], \n",
    "             activation='tanh',\n",
    "             return_sequences=True,  # Return full sequence for next LSTM\n",
    "             input_shape=(seq_length, n_features),\n",
    "             name='lstm_1'),\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        Dropout(dropout_rate, name='dropout_1'),\n",
    "        \n",
    "        # Second LSTM layer\n",
    "        LSTM(lstm_units[1], \n",
    "             activation='tanh',\n",
    "             return_sequences=False,  # Only return last output\n",
    "             name='lstm_2'),\n",
    "        \n",
    "        # Dropout\n",
    "        Dropout(dropout_rate, name='dropout_2'),\n",
    "        \n",
    "        # Dense layer for final prediction\n",
    "        Dense(16, activation='relu', name='dense_1'),\n",
    "        \n",
    "        # Output layer\n",
    "        Dense(1, activation='linear', name='output')\n",
    "    ])\n",
    "    \n",
    "    # Compile model\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='mse',\n",
    "        metrics=['mae']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_lstm_model(\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    n_features=1,\n",
    "    lstm_units=[64, 32],\n",
    "    dropout_rate=0.2,\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "# Display model architecture\n",
    "model.summary()\n",
    "\n",
    "print(\"\\n‚úÖ Model built successfully!\")\n",
    "print(f\"Total parameters: {model.count_params():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Training the LSTM Model - COMPLETE SOLUTION\n",
    "\n",
    "We'll train our model with early stopping to prevent overfitting and learning rate reduction for better convergence.\n",
    "\n",
    "### Training Best Practices\n",
    "\n",
    "1. **Early Stopping**: Stop training when validation loss stops improving\n",
    "2. **Learning Rate Reduction**: Reduce LR when loss plateaus\n",
    "3. **Batch Size**: Balance between stability (large) and generalization (small)\n",
    "4. **Monitoring**: Track both training and validation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# SOLUTION: Complete training code\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "print(\"üèãÔ∏è Training LSTM model...\")\n",
    "print(f\"Epochs: {EPOCHS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Training samples: {len(X_train)}\")\n",
    "print(f\"Validation samples: {len(X_val)}\\n\")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Training Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    \"\"\"\n",
    "    Visualize training and validation metrics.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # Plot loss\n",
    "    ax1.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss (MSE)')\n",
    "    ax1.set_title('Model Loss During Training')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot MAE\n",
    "    ax2.plot(history.history['mae'], label='Training MAE', linewidth=2)\n",
    "    ax2.plot(history.history['val_mae'], label='Validation MAE', linewidth=2)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('MAE')\n",
    "    ax2.set_title('Mean Absolute Error During Training')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print final metrics\n",
    "    final_train_loss = history.history['loss'][-1]\n",
    "    final_val_loss = history.history['val_loss'][-1]\n",
    "    final_train_mae = history.history['mae'][-1]\n",
    "    final_val_mae = history.history['val_mae'][-1]\n",
    "    \n",
    "    print(\"üìà Final Training Metrics:\")\n",
    "    print(f\"Training Loss: {final_train_loss:.6f}\")\n",
    "    print(f\"Validation Loss: {final_val_loss:.6f}\")\n",
    "    print(f\"Training MAE: {final_train_mae:.6f}\")\n",
    "    print(f\"Validation MAE: {final_val_mae:.6f}\")\n",
    "    \n",
    "    if final_val_loss > final_train_loss * 1.5:\n",
    "        print(\"\\n‚ö†Ô∏è Warning: Model might be overfitting!\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ Model generalization looks good!\")\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÆ Model Evaluation and Predictions - COMPLETE SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Complete prediction code\n",
    "# Make predictions on validation set\n",
    "y_pred_scaled = model.predict(X_val, verbose=0)\n",
    "\n",
    "# Inverse transform to get actual NDVI values\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "y_val_actual = scaler.inverse_transform(y_val)\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_val_actual, y_pred)\n",
    "mae = mean_absolute_error(y_val_actual, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_val_actual, y_pred)\n",
    "\n",
    "print(\"üìä Validation Set Performance:\")\n",
    "print(f\"Mean Squared Error: {mse:.6f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.6f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.6f}\")\n",
    "print(f\"R¬≤ Score: {r2:.4f}\")\n",
    "print(f\"\\nIn NDVI terms:\")\n",
    "print(f\"Average prediction error: ¬±{mae:.3f} NDVI units\")\n",
    "print(f\"\\nüìà Interpretation:\")\n",
    "print(f\"  - The model explains {r2*100:.1f}% of the variance in NDVI values\")\n",
    "print(f\"  - For drought detection (NDVI < 0.4), an error of ¬±{mae:.3f} is {'acceptable' if mae < 0.05 else 'moderate'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìà Visualizing Predictions - COMPLETE SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(y_true, y_pred, dates=None, n_points=100):\n",
    "    \"\"\"\n",
    "    Visualize actual vs predicted NDVI values.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "    \n",
    "    # Plot 1: Time series comparison\n",
    "    ax1 = axes[0]\n",
    "    x_axis = range(len(y_true[:n_points]))\n",
    "    \n",
    "    ax1.plot(x_axis, y_true[:n_points], 'g-', label='Actual NDVI', linewidth=2, alpha=0.7)\n",
    "    ax1.plot(x_axis, y_pred[:n_points], 'b--', label='Predicted NDVI', linewidth=2, alpha=0.7)\n",
    "    \n",
    "    # Highlight areas with large errors\n",
    "    errors = np.abs(y_true[:n_points].flatten() - y_pred[:n_points].flatten())\n",
    "    large_errors = errors > 0.1\n",
    "    if np.any(large_errors):\n",
    "        ax1.scatter(np.where(large_errors)[0], y_true[:n_points][large_errors], \n",
    "                   color='red', s=30, alpha=0.5, label='Large errors (>0.1)')\n",
    "    \n",
    "    ax1.set_xlabel('Time Steps', fontsize=11)\n",
    "    ax1.set_ylabel('NDVI', fontsize=11)\n",
    "    ax1.set_title('LSTM Predictions vs Actual NDVI Values', fontsize=12, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Scatter plot\n",
    "    ax2 = axes[1]\n",
    "    ax2.scatter(y_true, y_pred, alpha=0.5, s=10)\n",
    "    \n",
    "    # Add perfect prediction line\n",
    "    min_val = min(y_true.min(), y_pred.min())\n",
    "    max_val = max(y_true.max(), y_pred.max())\n",
    "    ax2.plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.5, label='Perfect prediction', linewidth=2)\n",
    "    \n",
    "    ax2.set_xlabel('Actual NDVI', fontsize=11)\n",
    "    ax2.set_ylabel('Predicted NDVI', fontsize=11)\n",
    "    ax2.set_title('Prediction Accuracy Scatter Plot', fontsize=12, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "visualize_predictions(y_val_actual, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåæ Module 4: LSTM Applications in Philippine Earth Observation\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "1. **Drought Forecasting (Mindanao)**\n",
    "   - Predict drought 1-3 months ahead\n",
    "   - Enable early warning for farmers\n",
    "   - Support irrigation planning\n",
    "\n",
    "2. **Crop Yield Prediction**\n",
    "   - Combine NDVI with weather data\n",
    "   - Forecast rice/corn yields\n",
    "   - Support food security planning\n",
    "\n",
    "3. **Phenology Analysis**\n",
    "   - Track cropping calendars\n",
    "   - Detect planting/harvest dates\n",
    "   - Monitor seasonal shifts due to climate change\n",
    "\n",
    "4. **Land Cover Change Detection**\n",
    "   - Identify deforestation patterns\n",
    "   - Monitor urban expansion\n",
    "   - Track agricultural conversion\n",
    "\n",
    "### Practical Deployment Considerations\n",
    "\n",
    "For operational use in Philippine agencies:\n",
    "\n",
    "1. **Data Requirements**\n",
    "   - Minimum 2-3 years of historical data\n",
    "   - Regular updates (weekly/bi-weekly)\n",
    "   - Cloud-free observations critical\n",
    "\n",
    "2. **Model Updates**\n",
    "   - Retrain quarterly with new data\n",
    "   - Validate against ground truth\n",
    "   - Account for seasonal variations\n",
    "\n",
    "3. **Integration with Existing Systems**\n",
    "   - DOST-ASTI DATOS platform\n",
    "   - PAGASA seasonal forecasts\n",
    "   - PhilSA Space+ Dashboard\n",
    "\n",
    "### üí≠ Think-Through Discussion - ANSWER\n",
    "\n",
    "**Question**: How would you modify this LSTM approach to integrate multiple data sources (e.g., Sentinel-1 SAR, Sentinel-2 optical, weather data) for improved drought prediction? What challenges might arise?\n",
    "\n",
    "**Answer**: \n",
    "- **Architecture Modification**: Change input shape from (seq_length, 1) to (seq_length, n_features) to accommodate multiple variables\n",
    "- **Normalization**: Each variable must be normalized separately as they have different scales\n",
    "- **Temporal Alignment**: Ensure all data sources have the same temporal resolution or use interpolation\n",
    "- **Missing Data**: SAR data may be more consistently available than optical data (cloud-independent)\n",
    "- **Feature Engineering**: Could include derived indices like NDWI, EVI, VH/VV ratio\n",
    "- **Challenges**: Different revisit times, data volume increases significantly, increased model complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Mini-Challenge 3 - SOLUTION: Drought Alert System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Mini-Challenge 3 - Implement drought alert system\n",
    "def drought_alert_system(predicted_ndvi, historical_mean=0.7, threshold_mild=0.6, \n",
    "                         threshold_severe=0.4):\n",
    "    \"\"\"\n",
    "    Generate drought alerts based on predicted NDVI values.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    predicted_ndvi : float\n",
    "        Predicted NDVI value\n",
    "    historical_mean : float\n",
    "        Historical mean NDVI for the location\n",
    "    threshold_mild : float\n",
    "        Threshold for mild drought alert\n",
    "    threshold_severe : float\n",
    "        Threshold for severe drought alert\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Alert information\n",
    "    \"\"\"\n",
    "    \n",
    "    deviation = ((predicted_ndvi - historical_mean) / historical_mean) * 100\n",
    "    \n",
    "    if predicted_ndvi < threshold_severe:\n",
    "        alert_level = \"SEVERE\"\n",
    "        color = \"üî¥\"\n",
    "        message = \"SEVERE DROUGHT ALERT: Immediate action required\"\n",
    "        recommendations = [\n",
    "            \"Activate emergency irrigation systems\",\n",
    "            \"Consider crop insurance claims\",\n",
    "            \"Monitor daily for further deterioration\",\n",
    "            \"Coordinate with PAGASA and DA for support\"\n",
    "        ]\n",
    "    elif predicted_ndvi < threshold_mild:\n",
    "        alert_level = \"MODERATE\"\n",
    "        color = \"üü°\"\n",
    "        message = \"MODERATE DROUGHT WARNING: Monitor closely and prepare interventions\"\n",
    "        recommendations = [\n",
    "            \"Optimize irrigation schedules\",\n",
    "            \"Monitor soil moisture levels\",\n",
    "            \"Prepare drought-resistant crop varieties\",\n",
    "            \"Update contingency plans\"\n",
    "        ]\n",
    "    elif predicted_ndvi < historical_mean * 0.9:\n",
    "        alert_level = \"MILD\"\n",
    "        color = \"üü†\"\n",
    "        message = \"MILD STRESS DETECTED: Continue monitoring\"\n",
    "        recommendations = [\n",
    "            \"Maintain regular monitoring\",\n",
    "            \"Check weather forecasts\",\n",
    "            \"Ensure irrigation systems are functional\"\n",
    "        ]\n",
    "    else:\n",
    "        alert_level = \"NORMAL\"\n",
    "        color = \"üü¢\"\n",
    "        message = \"NORMAL CONDITIONS: No drought detected\"\n",
    "        recommendations = [\n",
    "            \"Continue routine monitoring\",\n",
    "            \"Maintain preparedness for future events\"\n",
    "        ]\n",
    "    \n",
    "    return {\n",
    "        'alert_level': alert_level,\n",
    "        'message': f\"{color} {message}\",\n",
    "        'ndvi_value': predicted_ndvi,\n",
    "        'deviation_percent': deviation,\n",
    "        'recommendations': recommendations\n",
    "    }\n",
    "\n",
    "# Test the alert system with various NDVI values\n",
    "test_values = [0.3, 0.45, 0.55, 0.65, 0.75]\n",
    "\n",
    "print(\"üö® DROUGHT ALERT SYSTEM TEST\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for val in test_values:\n",
    "    alert = drought_alert_system(val)\n",
    "    print(f\"\\nNDVI: {val:.2f}\")\n",
    "    print(f\"Alert: {alert['message']}\")\n",
    "    print(f\"Deviation from normal: {alert['deviation_percent']:.1f}%\")\n",
    "    print(f\"Recommendations:\")\n",
    "    for i, rec in enumerate(alert['recommendations'], 1):\n",
    "        print(f\"  {i}. {rec}\")\n",
    "    print(\"-\"*70)\n",
    "\n",
    "# Test with actual predictions from our model\n",
    "print(\"\\n\\nüîç ANALYZING MODEL PREDICTIONS\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Find the lowest predicted NDVI (potential drought)\n",
    "min_pred_idx = y_pred.argmin()\n",
    "min_ndvi = y_pred[min_pred_idx][0]\n",
    "\n",
    "print(f\"\\nLowest predicted NDVI in validation set: {min_ndvi:.3f}\")\n",
    "alert = drought_alert_system(min_ndvi)\n",
    "print(f\"\\n{alert['message']}\")\n",
    "print(f\"\\nRecommended Actions:\")\n",
    "for i, rec in enumerate(alert['recommendations'], 1):\n",
    "    print(f\"  {i}. {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Advanced: Multi-Step Ahead Prediction - COMPLETE SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_step_prediction(model, initial_sequence, n_steps=3, scaler=None):\n",
    "    \"\"\"\n",
    "    Predict multiple time steps into the future.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : keras.Model\n",
    "        Trained LSTM model\n",
    "    initial_sequence : np.array\n",
    "        Initial sequence to start predictions from\n",
    "    n_steps : int\n",
    "        Number of steps to predict ahead\n",
    "    scaler : MinMaxScaler\n",
    "        Scaler to inverse transform predictions\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    predictions : list\n",
    "        List of predictions for each time step\n",
    "    \"\"\"\n",
    "    \n",
    "    current_sequence = initial_sequence.copy()\n",
    "    predictions = []\n",
    "    \n",
    "    for step in range(n_steps):\n",
    "        # Predict next time step\n",
    "        next_pred = model.predict(current_sequence.reshape(1, -1, 1), verbose=0)\n",
    "        predictions.append(next_pred[0, 0])\n",
    "        \n",
    "        # Update sequence: remove first element, add prediction\n",
    "        current_sequence = np.append(current_sequence[1:], next_pred)\n",
    "    \n",
    "    # Inverse transform if scaler provided\n",
    "    if scaler is not None:\n",
    "        predictions = scaler.inverse_transform(np.array(predictions).reshape(-1, 1)).flatten()\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "# SOLUTION: Test multi-step prediction\n",
    "print(\"üîÆ MULTI-STEP AHEAD PREDICTION TEST\\n\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Select a test sequence from validation set\n",
    "test_sequence = X_val[0]\n",
    "actual_future = y_val[:3]  # Next 3 actual values\n",
    "\n",
    "# Make multi-step predictions\n",
    "n_steps_ahead = 3\n",
    "multi_predictions_scaled = multi_step_prediction(model, test_sequence, n_steps=n_steps_ahead)\n",
    "multi_predictions = scaler.inverse_transform(np.array(multi_predictions_scaled).reshape(-1, 1)).flatten()\n",
    "\n",
    "# Also get actual values\n",
    "actual_values = scaler.inverse_transform(actual_future[:n_steps_ahead]).flatten()\n",
    "\n",
    "# Print results\n",
    "print(f\"\\nPredicting {n_steps_ahead} time steps ahead (approx. {n_steps_ahead*10} days)\\n\")\n",
    "\n",
    "for i, (pred, actual) in enumerate(zip(multi_predictions, actual_values), 1):\n",
    "    error = abs(pred - actual)\n",
    "    error_pct = (error / actual) * 100\n",
    "    \n",
    "    print(f\"Step {i} (Day {i*10}):\")\n",
    "    print(f\"  Predicted NDVI: {pred:.3f}\")\n",
    "    print(f\"  Actual NDVI:    {actual:.3f}\")\n",
    "    print(f\"  Error:          {error:.3f} ({error_pct:.1f}%)\")\n",
    "    \n",
    "    # Check drought status\n",
    "    if pred < 0.4:\n",
    "        print(f\"  ‚ö†Ô∏è  Drought conditions predicted!\")\n",
    "    print()\n",
    "\n",
    "# Visualize multi-step predictions\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Historical sequence\n",
    "hist_sequence = scaler.inverse_transform(test_sequence).flatten()\n",
    "time_historical = range(len(hist_sequence))\n",
    "time_future = range(len(hist_sequence), len(hist_sequence) + n_steps_ahead)\n",
    "\n",
    "plt.plot(time_historical, hist_sequence, 'b-o', label='Historical NDVI', linewidth=2)\n",
    "plt.plot(time_future, multi_predictions, 'r--o', label='Predicted NDVI', linewidth=2, markersize=8)\n",
    "plt.plot(time_future, actual_values, 'g-s', label='Actual NDVI', linewidth=2, markersize=8)\n",
    "\n",
    "# Add drought threshold\n",
    "plt.axhline(y=0.4, color='orange', linestyle=':', alpha=0.7, linewidth=2, label='Drought threshold')\n",
    "\n",
    "plt.axvline(x=len(hist_sequence)-0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "plt.xlabel('Time Steps (10-day periods)', fontsize=11)\n",
    "plt.ylabel('NDVI', fontsize=11)\n",
    "plt.title('Multi-Step LSTM Forecast for Drought Monitoring', fontsize=12, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display overall accuracy\n",
    "mae_multistep = mean_absolute_error(actual_values, multi_predictions)\n",
    "print(f\"\\nüìä Multi-step Prediction Performance:\")\n",
    "print(f\"Mean Absolute Error: {mae_multistep:.4f}\")\n",
    "print(f\"\\nüí° Insight: Prediction accuracy typically decreases with longer forecasting horizons.\")\n",
    "print(f\"For operational drought early warning, 1-3 step ahead predictions are most reliable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Key Takeaways\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "1. **Time Series in EO**: Critical for monitoring environmental changes and predicting future conditions\n",
    "\n",
    "2. **RNN Limitations**: Vanilla RNNs suffer from vanishing/exploding gradients, limiting their ability to learn long-term dependencies\n",
    "\n",
    "3. **LSTM Architecture**: Gates (forget, input, output) and cell state enable learning of both short and long-term patterns\n",
    "\n",
    "4. **Implementation**: \n",
    "   - Data preparation with sliding windows\n",
    "   - Normalization is crucial\n",
    "   - Early stopping prevents overfitting\n",
    "   - Multi-step predictions for operational forecasting\n",
    "\n",
    "5. **Philippine Applications**: Drought monitoring in Mindanao is a critical use case with immediate practical value\n",
    "\n",
    "### Best Practices\n",
    "\n",
    "‚úÖ **DO:**\n",
    "- Normalize your data before training\n",
    "- Use sufficient historical data (2+ years)\n",
    "- Validate predictions against ground truth\n",
    "- Consider ensemble approaches for operational systems\n",
    "- Account for data gaps and cloud cover\n",
    "- Implement proper error handling and alerts\n",
    "\n",
    "‚ùå **DON'T:**\n",
    "- Ignore seasonal patterns in your data\n",
    "- Use too short sequences (< 6 time steps)\n",
    "- Deploy without thorough validation\n",
    "- Forget to retrain with new data periodically\n",
    "- Over-rely on multi-step predictions without validation\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Experiment**: Try different sequence lengths and LSTM architectures\n",
    "2. **Enhance**: Add weather data and other indices (EVI, NDWI)\n",
    "3. **Scale**: Apply to your area of interest using Google Earth Engine\n",
    "4. **Integrate**: Connect with Philippine EO platforms (DATOS, Space+)\n",
    "5. **Deploy**: Build operational systems with alert mechanisms\n",
    "\n",
    "### üöÄ Extension Ideas\n",
    "\n",
    "- **Bidirectional LSTMs**: Learn from past and future contexts\n",
    "- **Attention Mechanisms**: Focus on most important time steps\n",
    "- **Multi-variate Inputs**: Combine NDVI, temperature, precipitation, SAR\n",
    "- **Ensemble Models**: Combine multiple LSTM models for robust predictions\n",
    "- **Real-time Integration**: Connect to Google Earth Engine for live data streams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö References and Further Reading\n",
    "\n",
    "### Scientific Papers\n",
    "1. Hochreiter, S., & Schmidhuber, J. (1997). \"Long Short-Term Memory.\" Neural Computation.\n",
    "2. Ru√üwurm, M., & K√∂rner, M. (2020). \"Self-attention for raw optical Satellite Time Series Classification.\" ISPRS.\n",
    "3. Interdonato, R., et al. (2019). \"DuPLO: A DUal view Point deep Learning architecture for time series classificatiOn.\" ISPRS.\n",
    "4. Nguyen, L. H., et al. (2020). \"Monitoring agriculture areas with satellite images and deep learning.\" Applied Soft Computing.\n",
    "\n",
    "### Philippine EO Resources\n",
    "- PhilSA Space+ Dashboard: [https://space.philsa.gov.ph](https://space.philsa.gov.ph)\n",
    "- DOST-ASTI DATOS: [https://datos.asti.dost.gov.ph](https://datos.asti.dost.gov.ph)\n",
    "- PAGASA Drought Monitoring: [https://www.pagasa.dost.gov.ph](https://www.pagasa.dost.gov.ph)\n",
    "\n",
    "### Tutorials and Documentation\n",
    "- TensorFlow Time Series Tutorial: [https://www.tensorflow.org/tutorials/structured_data/time_series](https://www.tensorflow.org/tutorials/structured_data/time_series)\n",
    "- Understanding LSTM Networks (Colah's Blog): [https://colah.github.io/posts/2015-08-Understanding-LSTMs/](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "- Google Earth Engine Time Series Guide: [https://developers.google.com/earth-engine/guides/reducers_reduce_region](https://developers.google.com/earth-engine/guides/reducers_reduce_region)\n",
    "\n",
    "---\n",
    "\n",
    "**End of Session 1: LSTMs for Earth Observation Time Series**\n",
    "\n",
    "**INSTRUCTOR VERSION - Complete with all solutions**\n",
    "\n",
    "Proceed to Session 2: Foundation Models and Transfer Learning üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}