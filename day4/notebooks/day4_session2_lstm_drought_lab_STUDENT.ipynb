{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 4, Session 2: LSTM Drought Monitoring Lab\n",
    "## Hands-on Implementation for Mindanao Agricultural Regions\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. **Acquire and preprocess** multi-year Sentinel-2 NDVI time series for a study area\n",
    "2. **Create training sequences** using sliding window approach for time series forecasting\n",
    "3. **Build LSTM models** using TensorFlow/Keras with appropriate architecture\n",
    "4. **Train and validate** models with proper temporal data splitting\n",
    "5. **Evaluate forecast accuracy** using RMSE, MAE, and visual diagnostics\n",
    "6. **Interpret predictions** in the context of drought monitoring\n",
    "7. **Deploy** models for operational early warning systems\n",
    "\n",
    "---\n",
    "\n",
    "## 📋 Session Overview\n",
    "\n",
    "- **Duration**: 2.5 hours (150 minutes)\n",
    "- **Format**: Hands-on Lab\n",
    "- **Difficulty**: Intermediate to Advanced\n",
    "- **Application**: Drought forecasting for Bukidnon and South Cotabato, Mindanao\n",
    "\n",
    "---\n",
    "\n",
    "## 🌾 Case Study: Mindanao Drought Monitoring\n",
    "\n",
    "### Why Mindanao?\n",
    "\n",
    "**Bukidnon and South Cotabato** are critical agricultural provinces producing:\n",
    "- Corn (major crop)\n",
    "- Rice\n",
    "- Coffee, Pineapple, Vegetables\n",
    "\n",
    "**Climate Challenges:**\n",
    "- Pronounced dry season (November-April)\n",
    "- Strong El Niño impacts\n",
    "- 2015-2016 El Niño: Severe drought affecting 2.5 million people\n",
    "\n",
    "**Objective:** Predict drought conditions **1-3 months ahead** to enable:\n",
    "- Adjust planting calendars\n",
    "- Activate irrigation systems\n",
    "- Distribute drought-resistant seeds\n",
    "- Pre-position crop insurance programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Setup and Data Loading (20 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Configure matplotlib\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
    "print(\"Setup complete! 🚀\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Synthetic Mindanao NDVI Data\n",
    "\n",
    "For this lab, we'll use synthetic but realistic data. In production, you would load actual Sentinel-2 NDVI from Google Earth Engine or pre-processed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mindanao_drought_data(start_date='2015-01-01', end_date='2021-12-31'):\n",
    "    \"\"\"\n",
    "    Generate synthetic NDVI time series for Mindanao with realistic drought patterns.\n",
    "    \"\"\"\n",
    "    # Create monthly date range\n",
    "    dates = pd.date_range(start=start_date, end=end_date, freq='MS')\n",
    "    n_months = len(dates)\n",
    "    \n",
    "    # Initialize arrays\n",
    "    ndvi = np.zeros(n_months)\n",
    "    rainfall = np.zeros(n_months)\n",
    "    temperature = np.zeros(n_months)\n",
    "    oni = np.zeros(n_months)  # El Niño index\n",
    "    \n",
    "    base_ndvi = 0.70\n",
    "    \n",
    "    for i, date in enumerate(dates):\n",
    "        month = date.month\n",
    "        year = date.year\n",
    "        \n",
    "        # Seasonal patterns\n",
    "        if month in [11, 12, 1, 2, 3]:  # Wet season\n",
    "            seasonal_factor = 0.85 + 0.10 * np.sin(2 * np.pi * month / 12)\n",
    "            rain_base = 250\n",
    "            temp_base = 26\n",
    "        else:  # Dry season\n",
    "            seasonal_factor = 0.75 + 0.05 * np.sin(2 * np.pi * month / 12)\n",
    "            rain_base = 80\n",
    "            temp_base = 28\n",
    "        \n",
    "        # El Niño drought events (2015-2016)\n",
    "        drought_factor = 1.0\n",
    "        if year == 2015 and month >= 6:\n",
    "            drought_factor = 0.60\n",
    "            oni[i] = 2.5 + np.random.randn() * 0.3  # Strong El Niño\n",
    "            rain_base *= 0.4\n",
    "            temp_base += 2\n",
    "        elif year == 2016 and month <= 6:\n",
    "            drought_factor = 0.65\n",
    "            oni[i] = 2.0 + np.random.randn() * 0.3\n",
    "            rain_base *= 0.5\n",
    "            temp_base += 1.5\n",
    "        else:\n",
    "            oni[i] = np.random.randn() * 0.5  # Normal conditions\n",
    "        \n",
    "        # Calculate values\n",
    "        ndvi[i] = base_ndvi * seasonal_factor * drought_factor + np.random.normal(0, 0.03)\n",
    "        ndvi[i] = np.clip(ndvi[i], 0.2, 0.9)\n",
    "        \n",
    "        rainfall[i] = max(0, rain_base + np.random.normal(0, 40))\n",
    "        temperature[i] = temp_base + np.random.normal(0, 1.5)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame({\n",
    "        'date': dates,\n",
    "        'ndvi': ndvi,\n",
    "        'rainfall': rainfall,\n",
    "        'temperature': temperature,\n",
    "        'oni': oni\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate data\n",
    "df = generate_mindanao_drought_data()\n",
    "print(f\"Generated {len(df)} months of data\")\n",
    "print(f\"Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nBasic statistics:\")\n",
    "print(df[['ndvi', 'rainfall', 'temperature', 'oni']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Exploratory Data Analysis (25 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize NDVI time series\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 10), sharex=True)\n",
    "\n",
    "# Plot 1: NDVI\n",
    "axes[0].plot(df['date'], df['ndvi'], 'g-', linewidth=2, label='NDVI')\n",
    "axes[0].axhline(y=df['ndvi'].mean(), color='gray', linestyle='--', alpha=0.5, label='Mean')\n",
    "# Highlight 2015-2016 drought\n",
    "axes[0].axvspan(pd.Timestamp('2015-06-01'), pd.Timestamp('2016-06-01'), \n",
    "                alpha=0.2, color='red', label='2015-16 El Niño Drought')\n",
    "axes[0].set_ylabel('NDVI', fontsize=12)\n",
    "axes[0].set_title('Mindanao NDVI Time Series (2015-2021)', fontsize=14, fontweight='bold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Rainfall\n",
    "axes[1].bar(df['date'], df['rainfall'], color='blue', alpha=0.6, width=20)\n",
    "axes[1].set_ylabel('Rainfall (mm)', fontsize=12)\n",
    "axes[1].set_title('Monthly Rainfall', fontsize=12)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: ONI (El Niño Index)\n",
    "colors = ['red' if x > 0.5 else 'blue' if x < -0.5 else 'gray' for x in df['oni']]\n",
    "axes[2].bar(df['date'], df['oni'], color=colors, alpha=0.7, width=20)\n",
    "axes[2].axhline(y=0.5, color='red', linestyle='--', alpha=0.5, label='El Niño threshold')\n",
    "axes[2].axhline(y=-0.5, color='blue', linestyle='--', alpha=0.5, label='La Niña threshold')\n",
    "axes[2].set_ylabel('ONI Index', fontsize=12)\n",
    "axes[2].set_xlabel('Date', fontsize=12)\n",
    "axes[2].set_title('Oceanic Niño Index (ONI)', fontsize=12)\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Exercise 1: Data Exploration\n",
    "\n",
    "**Tasks:**\n",
    "1. Calculate the mean NDVI for dry season (May-Oct) vs. wet season (Nov-Apr)\n",
    "2. Identify the month with the lowest NDVI value\n",
    "3. Calculate the correlation between NDVI and rainfall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete Exercise 1\n",
    "\n",
    "# Task 1: Seasonal NDVI means\n",
    "df['month'] = df['date'].dt.month\n",
    "# dry_season_ndvi = ...\n",
    "# wet_season_ndvi = ...\n",
    "\n",
    "# Task 2: Lowest NDVI month\n",
    "# lowest_ndvi_idx = ...\n",
    "\n",
    "# Task 3: Correlation\n",
    "# correlation = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Sequence Creation (30 minutes)\n",
    "\n",
    "### Create Sliding Window Sequences for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "LOOKBACK_WINDOW = 12  # Use 12 months of history\n",
    "FORECAST_HORIZON = 1   # Predict 1 month ahead\n",
    "\n",
    "# Features to use\n",
    "feature_columns = ['ndvi', 'rainfall', 'temperature', 'oni']\n",
    "target_column = 'ndvi'\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_scaled = df.copy()\n",
    "df_scaled[feature_columns] = scaler.fit_transform(df[feature_columns])\n",
    "\n",
    "print(f\"Lookback window: {LOOKBACK_WINDOW} months\")\n",
    "print(f\"Forecast horizon: {FORECAST_HORIZON} month(s)\")\n",
    "print(f\"Features: {feature_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, features, target, lookback, horizon):\n",
    "    \"\"\"\n",
    "    Create input-output sequences for LSTM training.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame with features\n",
    "        features: List of feature column names\n",
    "        target: Target column name\n",
    "        lookback: Number of time steps to look back\n",
    "        horizon: Number of time steps to forecast ahead\n",
    "    \n",
    "    Returns:\n",
    "        X: Input sequences (samples, lookback, n_features)\n",
    "        y: Target values (samples,)\n",
    "        dates: Corresponding dates for sequences\n",
    "    \"\"\"\n",
    "    X, y, dates = [], [], []\n",
    "    \n",
    "    feature_data = data[features].values\n",
    "    target_data = data[target].values\n",
    "    date_data = data['date'].values\n",
    "    \n",
    "    for i in range(lookback, len(data) - horizon + 1):\n",
    "        # Input sequence: [i-lookback : i]\n",
    "        X.append(feature_data[i - lookback:i])\n",
    "        \n",
    "        # Target value: i + horizon - 1\n",
    "        y.append(target_data[i + horizon - 1])\n",
    "        \n",
    "        # Date of prediction\n",
    "        dates.append(date_data[i + horizon - 1])\n",
    "    \n",
    "    return np.array(X), np.array(y), np.array(dates)\n",
    "\n",
    "# Create sequences\n",
    "X, y, dates = create_sequences(\n",
    "    df_scaled,\n",
    "    feature_columns,\n",
    "    target_column,\n",
    "    LOOKBACK_WINDOW,\n",
    "    FORECAST_HORIZON\n",
    ")\n",
    "\n",
    "print(f\"X shape: {X.shape} (samples, time_steps, features)\")\n",
    "print(f\"y shape: {y.shape} (samples,)\")\n",
    "print(f\"Total sequences: {len(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporal Train-Validation-Test Split\n",
    "\n",
    "**CRITICAL:** Use temporal splits (not random) to avoid data leakage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete the temporal split\n",
    "\n",
    "# Define split points\n",
    "train_end = pd.Timestamp('2019-12-31')\n",
    "val_end = pd.Timestamp('2020-12-31')\n",
    "\n",
    "# Get indices\n",
    "train_mask = dates <= train_end\n",
    "val_mask = (dates > train_end) & (dates <= val_end)\n",
    "test_mask = dates > val_end\n",
    "\n",
    "# Split data\n",
    "X_train, y_train = X[train_mask], y[train_mask]\n",
    "X_val, y_val = X[val_mask], y[val_mask]\n",
    "X_test, y_test = X[test_mask], y[test_mask]\n",
    "\n",
    "dates_train = dates[train_mask]\n",
    "dates_val = dates[val_mask]\n",
    "dates_test = dates[test_mask]\n",
    "\n",
    "print(\"Data Split:\")\n",
    "print(f\"  Train: {len(X_train)} sequences ({dates_train[0]} to {dates_train[-1]})\")\n",
    "print(f\"  Val:   {len(X_val)} sequences ({dates_val[0]} to {dates_val[-1]})\")\n",
    "print(f\"  Test:  {len(X_test)} sequences ({dates_test[0]} to {dates_test[-1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: LSTM Model Building (30 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Build LSTM model\n",
    "\n",
    "def build_lstm_model(input_shape, lstm_units=[64, 32], dropout=0.2, learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Build LSTM model for drought forecasting.\n",
    "    \n",
    "    Complete the architecture below.\n",
    "    \"\"\"\n",
    "    model = Sequential(name='LSTM_Drought_Forecaster')\n",
    "    \n",
    "    # TODO: Add LSTM layers\n",
    "    # Hint: First LSTM should have return_sequences=True if stacking layers\n",
    "    # model.add(LSTM(...))\n",
    "    # model.add(Dropout(...))\n",
    "    \n",
    "    # TODO: Add output layers\n",
    "    # model.add(Dense(...))\n",
    "    # model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    # TODO: Compile model\n",
    "    # optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    # model.compile(...)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build model\n",
    "input_shape = (LOOKBACK_WINDOW, len(feature_columns))\n",
    "# model = build_lstm_model(input_shape)\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Model Training (20 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Configure callbacks and train\n",
    "\n",
    "# callbacks = [\n",
    "#     EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True),\n",
    "#     ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
    "# ]\n",
    "\n",
    "# BATCH_SIZE = 32\n",
    "# EPOCHS = 100\n",
    "\n",
    "# history = model.fit(\n",
    "#     X_train, y_train,\n",
    "#     validation_data=(X_val, y_val),\n",
    "#     epochs=EPOCHS,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     callbacks=callbacks,\n",
    "#     verbose=1\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6: Model Evaluation (30 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make predictions and evaluate\n",
    "\n",
    "# y_test_pred = model.predict(X_test).flatten()\n",
    "\n",
    "# # Inverse transform to original scale\n",
    "# def inverse_transform_ndvi(values, scaler, feature_columns):\n",
    "#     dummy = np.zeros((len(values), len(feature_columns)))\n",
    "#     ndvi_idx = feature_columns.index('ndvi')\n",
    "#     dummy[:, ndvi_idx] = values\n",
    "#     inverse = scaler.inverse_transform(dummy)\n",
    "#     return inverse[:, ndvi_idx]\n",
    "\n",
    "# y_test_actual = inverse_transform_ndvi(y_test, scaler, feature_columns)\n",
    "# y_test_pred_original = inverse_transform_ndvi(y_test_pred, scaler, feature_columns)\n",
    "\n",
    "# # Calculate metrics\n",
    "# rmse = np.sqrt(mean_squared_error(y_test_actual, y_test_pred_original))\n",
    "# mae = mean_absolute_error(y_test_actual, y_test_pred_original)\n",
    "# r2 = r2_score(y_test_actual, y_test_pred_original)\n",
    "\n",
    "# print(f\"\\nTest Set Performance:\")\n",
    "# print(f\"  RMSE: {rmse:.4f}\")\n",
    "# print(f\"  MAE:  {mae:.4f}\")\n",
    "# print(f\"  R²:   {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create visualization\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(15, 6))\n",
    "# ax.plot(dates_test, y_test_actual, 'g-', linewidth=2, marker='o', label='Actual NDVI')\n",
    "# ax.plot(dates_test, y_test_pred_original, 'r--', linewidth=2, marker='x', label='Predicted NDVI')\n",
    "# ax.set_xlabel('Date', fontsize=12)\n",
    "# ax.set_ylabel('NDVI', fontsize=12)\n",
    "# ax.set_title('LSTM Drought Forecasting: Test Set Predictions', fontsize=14, fontweight='bold')\n",
    "# ax.legend(fontsize=11)\n",
    "# ax.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎯 Final Exercise: Operational Deployment\n",
    "\n",
    "**Task:** Design a simple operational forecast system\n",
    "\n",
    "1. Define drought threshold (e.g., NDVI < 0.4)\n",
    "2. Identify when model predicts drought\n",
    "3. Calculate lead time (months before actual drought)\n",
    "4. Assess false alarm rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete operational analysis\n",
    "\n",
    "# DROUGHT_THRESHOLD = 0.4\n",
    "# predicted_drought = ...\n",
    "# actual_drought = ...\n",
    "# Calculate true positives, false positives, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌾 Key Takeaways\n",
    "\n",
    "In this lab, you:\n",
    "- ✅ Built end-to-end LSTM drought forecasting system\n",
    "- ✅ Processed multi-year time series data\n",
    "- ✅ Implemented proper temporal validation\n",
    "- ✅ Evaluated operational forecast accuracy\n",
    "- ✅ Designed deployment considerations for Philippine agencies\n",
    "\n",
    "**Next:** Session 3 explores emerging AI trends (Foundation Models, XAI) to further enhance these systems!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
